a comparison of eleven static heuristics for mapping a class of independent tasks onto heterogeneous distributed computing systems	Mixed-machine heterogeneous computing (HC) environments utilize a distributed suite of different high-performance machines, interconnected with high-speed links, to perform different computationally intensive applications that have diverse computational requirements. HC environments are well suited to meet the computational demands of large, diverse groups of tasks. The problem of optimally mapping (defined as matching and scheduling) these tasks onto the machines of a distributed HC environment has been shown, in general, to be NP-complete, requiring the development of heuristic techniques. Selecting the best heuristic to use in a given environment, however, remains a difficult problem, because comparisons are often clouded by different underlying assumptions in the original study of each heuristic. Therefore, a collection of 11 heuristics from the literature has been selected, adapted, implemented, and analyzed under one set of common assumptions. It is assumed that the heuristics derive a mapping statically (i.e., off-line). It is also assumed that a metatask (i.e., a set of independent, noncommunicating tasks) is being mapped and that the goal is to minimize the total execution time of the metatask. The 11 heuristics examined are Opportunistic Load Balancing, Minimum Execution Time, Minimum Completion Time, Min?min, Max?min, Duplex, Genetic Algorithm, Simulated Annealing, Genetic Simulated Annealing, Tabu, and A*. This study provides one even basis for comparison and insights into circumstances where one technique will out-perform another. The evaluation procedure is specified, the heuristics are defined, and then comparison results are discussed. It is shown that for the cases studied here, the relatively simple Min?min heuristic performs well in comparison to the other techniques.
a grid task scheduling algorithm based on qos priority grouping	As the research of grid goes on, users demand increasingly high quality of task completion and high-quality scientific computing tasks continue to increase. This renders QoS a new problem that is to be considered in the grid scheduling algorithm. In this paper, a grid tasks scheduling strategy based on QoS priority grouping is proposed. In this algorithm, the deadline property of task, acceptation rate of tasks and makespan of systems are comprehensively considered. And QD-Sufferage, a grid task scheduling based on task priority grouping and deadline, is presented subsequently. The experiments show that the algorithm overweighs traditional algorithms a lot in makespan, throughout parameters
decentralized resource scheduling in grid cloud computing	
olap query evaluation in a database cluster a performance study on intra query parallelism	While cluster computing is well established, it is not clear how to coordinate clusters consisting of many database components in order to process high workloads. In this paper, we focus on Online Analytical Processing (OLAP) queries, i.e., relatively complex queries whose evaluation tends to be time-consuming, and we report on some observations and preliminary results of our PowerDB project in this context. We investigate how many cluster nodes should be used to evaluate an OLAP query in parallel. Moreover, we provide a classification of OLAP queries, which is used to decide, whether and how a query should be parallelized. We run extensive experiments to evaluate these query classes in quantitative terms. Our results are an important step towards a two-phase query optimizer. In the first phase, the coordination infrastructure decomposes a query into subqueries and ships them to appropriate cluster nodes. In the second phase, each cluster node optimizes and evaluates its subquery locally.
A new dominance rule for the total weighted tardiness problem	We present a new dominance rule for the single machine total weighted tardiness problem with job dependent penalties. The proposed dominance rule provides a suA cient condition for local optimality. We show that if any sequence violates the dominance rule, then switching the violating jobs either lowers the total weighted tardiness or leaves it unchanged. We also develop a new algorithm based on the dominance rule, which is compared to a number of competing heuristics for a set of randomly generated problems. Our com- putational results of over 40000 problems indicate that the proposed algorithm dominates the competing heuristics in all runs.
a new lower bounding scheme for the total weighted tardiness problem	"This is the author's version of the work. It is posted here by permission of Elsevier for personal use, not for redistribution.  Accepted for publications to Computers and Operations Research,Vol. 25, No. 4, April 1, 1998   doi>10.1016/S0305-0548(97)00073-7  .WSU users can access the article via commercial databases licensed by University Libraries: http://libcat.wichita.edu/vwebv/holdingsInfo?bibId=1375035"
energy efficient algorithms	
on multi processor speed scaling with migration	We investigate a very basic problem in dynamic speed scaling where a sequence of jobs, each specified by an arrival time, a deadline and a processing volume, has to be processed so as to minimize energy consumption. We study multi-processor environments with m parallel variable-speed processors assuming that job migration is allowed, i.e. whenever a job is preempted it may be moved to a different processor. We first study the offline problem and show that optimal schedules can be computed efficiently in polynomial time, given any convex non-decreasing power function. In contrast to a previously known strategy, our algorithm does not resort to linear programming. For the online problem, we extend two algorithms Optimal Available and Average Rate proposed by Yao et al. 15] for the single processor setting. Here we concentrate on power functions P ( s ) = s α , where s is the processor speed and α 1 is a constant.
a note on the equivalence of two heuristics to minimize total tardiness	Abstract   Over the last thirty years, many researchers have studied single machine static and deterministic scheduling with the objective of minimizing total tardiness. It has been established that the tardiness problem is NP-hard. So it is unlikely that a polynomial time algorithm can be found for developing optimal solutions to this problem. The Modified Due Date rule (MDD) is generally considered to be an efficient heuristic that deals with the tardiness problem. Recently, Panwalkar et al. have proposed the PSK rule as effective in dealing with tardiness. The purpose of this paper is to show that the PSK rule is an implementation of the MDD rule. Furthermore, the relationship between the MDD rule and the WI (Wilkeson and Irwin) rule is clarified.
analyzing market based resource allocation strategies for the computational grid	In this paper, the authors investigate G-commerce--computational economies for controlling resource allocation in computational Grid settings. They define hypothetical resource consumers (representing users and Grid-aware applications) and resource producers (representing resource owners who "sell" their resources to the Grid). The authors then measure the efficiency of resource allocation under two different market conditions--commodities markets and auctions--and compare both market strategies in terms of price stability, market equilibrium, consumer efficiency, and producer efficiency. The results indicate that commodities markets are a better choice for controlling Grid resources than previously defined auction strategies.
trace based performance analysis of scheduling bags of tasks in grids	Grid computing promises large scale computing facilities based on distributed systems. Much research has been done on the subject of increasing the performance of grids. We believe that an adequate performance analysis of grids requires knowledge of the workload and the architecture of the grid. Currently, researchers assume that grids are similar to other distributed systems, such as massively parallel computers. However, workloads in grids differ from other distributed systems, because they consist for a significant part of bags-of-tasks. This research presents a method to model the workload of grids realistically, which enables us to analyze the performance of those systems. We have created a flexible workload model that is specifically tailed for grids. The model explicitly handles bag-of-tasks, which comprise the majority of grid workloads. This workload model has been built using a vast amount of workload trace data from seven real-world grids. The workload model enables us to conduct a performance analysis in which we analyze the impact of several workload characteristics, task selection and scheduling policies, and resource management architectures on system performance. We use simulations to systematically and realistically investigate the system performance in various scenarios. This research has resulted in a grid performance analysis toolbox, a software package that allows researchers to analyze, model, and generate workloads of grids. In addition, we have contributed trace data and analysis to the community by means of the Grid Workloads Archive, an on-line archive of trace data analyzed with our toolbox.
a resource management architecture for metacomputing systems	Metacomputing systems are intended to support remote and/or concurrent use of geographically distributed computational resources. Resource management in such systems is complicated by five concerns that do not typically arise in other situations: site autonomy and heterogeneous substrates at the resources, and application requirements for policy extensibility, co-allocation, and online control. We describe a resource management architecture that addresses these concerns. This architecture distributes the resource management problem among distinct local manager, resource broker, and resource co-allocator components and defines an extensible resource specification language to exchange information about requirements. We describe how these techniques have been implemented in the context of the Globus metacomputing toolkit and used to implement a variety of different resource management strategies. We report on our experiences applying our techniques in a large testbed, GUSTO, incorporating 15 sites, 330 computers, and 3600 processors.
a study of deadline scheduling for client server systems on the computational grid	The Computational Grid is a promising platform for the deployment of various high-performance computing applications. A number of projects have addressed the idea of software as a service on the network. These systems usually implement client-server architectures with many servers running on distributed Grid resources and have commonly been referred to as network-enabled servers (NES). An important question is that of scheduling in this multi-client multi-server scenario. Note that in this context most requests are computationally intensive as they are generated by high-performance computing applications. The Bricks simulation framework has been developed and extensively used to evaluate scheduling strategies for NES systems. The authors first present recent developments and extensions to the Bricks simulation models. They discuss a deadline scheduling strategy that is appropriate for the multi-client multi-server case, and augment it with "Load Correction" and "Fallback" mechanisms which could improve the performance of the algorithm. We then give Bricks simulation results. The results show that future NES systems should use deadline scheduling with multiple fallbacks and it is possible to allow users to make a trade-off between failure-rate and cost by adjusting the level of conservatism of deadline scheduling algorithms.
a taxonomy and survey of energy efficient data centers and cloud computing systems	Abstract   Traditionally, the development of computing systems has been focused on performance improvements driven by the demand of applications from consumer, scientific, and business domains. However, the ever-increasing energy consumption of computing systems has started to limit further performance growth due to overwhelming electricity bills and carbon dioxide footprints. Therefore, the goal of the computer system design has been shifted to power and energy efficiency. To identify open challenges in the area and facilitate future advancements, it is essential to synthesize and classify the research on power- and energy-efficient design conducted to date. In this study, we discuss causes and problems of high power/energy consumption, and present a taxonomy of energy-efficient design of computing systems covering the hardware, operating system, virtualization, and data center levels. We survey various key works in the area and map them onto our taxonomy to guide future design and development efforts. This chapter concludes with a discussion on advancements identified in energy-efficient computing and our vision for future research directions.
a dynamic subgradient based branch and bound procedure for set covering	We discuss a branch and bound algorithm for set covering, whose centerpiece is a new integrated upper bounding/lower bounding procedure called dynamic subgradient optimization DYNSGRAD. This new procedure, applied to a Lagrangean dual at every node of the search tree, combines the standard subgradient method with primal and dual heuristics that interact to change the Lagrange multipliers and tighten the upper and lower bounds, fix variables, and periodically restate the Lagrangean itself. Extensive computational testing is reported. As a stand-alone heuristic, DYNSGRAD performs significantly better than other procedures in terms of the quality of solutions obtainable with a certain computational effort. When incorporated into a branch-and-bound algorithm, DYNSGRAD considerably advances the state of the art in solving set covering problems.
set covering algorithms using cutting planes heuristics and subgradient optimization a computational study	We report on the implementation and computational testing of several versions of a set covering algorithm, based on the family of cutting planes from conditional bounds discussed in the companion paper [2]. The algorithm uses a set of heuristics to find prime covers, another set of heuristics to find feasible solutions to the dual linear program which are needed to generate cuts, and subgradient optimization to find lower bounds. It also uses implicit enumeration with some new branching rules. Each of the ingredients was implemented and tested in several versions. The variant of the algorithm that emerged as best was run on 55 randomly generated test problems (20 of them from the literature), with up to 200 constraints and 2000 variables. The results show the algorithm to be more reliable and efficient than earlier procedures on large, sparse set covering problems.
algorithmic and scheduling techniques for heterogeneous and distributed computing	The computing and communication resources of high performance computing systems are becoming heterogeneous, are exhibiting performance fluctuations and are failing in an unforeseeable manner. The M ...
average rate speed scaling	Speed scaling is a power management technique that involves dynamically changing the speed of a processor. This gives rise to dual-objective scheduling problems, where the operating system both wants to conserve energy and optimize some Quality of Service (QoS) measure of the resulting schedule. Yao, Demers, and Shenker (Proc. IEEE Symp. Foundations of Computer Science, pp. 374–382, 1995) considered the problem where the QoS constraint is deadline feasibility and the objective is to minimize the energy used. They proposed an online speed scaling algorithm Average Rate (AVR) that runs each job at a constant speed between its release and its deadline. They showed that the competitive ratio of AVR is at most (2α)α /2 if a processor running at speed s uses power s α . We show the competitive ratio of AVR is at least ((2−δ)α)α /2, where δ is a function of α that approaches zero as α approaches infinity. This shows that the competitive analysis of AVR by Yao, Demers, and Shenker is essentially tight, at least for large α. We also give an alternative proof that the competitive ratio of AVR is at most (2α)α /2 using a potential function argument. We believe that this analysis is significantly simpler and more elementary than the original analysis of AVR in Yao et al. (Proc. IEEE Symp. Foundations of Computer Science, pp. 374–382, 1995).
polynomial time algorithms for minimum energy scheduling	The aim of power management policies is to reduce the amount of energy consumed by computer systems while maintaining satisfactory level of performance. One common method for saving energy is to simply suspend the system during the idle times. No energy is consumed in the suspend mode. However, the process of waking up the system itself requires a certain fixed amount of energy, and thus suspending the system is beneficial only if the idle time is long enough to compensate for this additional energy expenditure. In the specific problem studied in the paper, we have a set of jobs with release times and deadlines that need to be executed on a single processor. Preemptions are allowed. The processor requires energy L to be woken up and, when it is on, it uses the energy at a rate of R units per unit of time. It has been an open problem whether a schedule minimizing the overall energy consumption can be computed in polynomial time. We solve this problem in positive, by providing an O(n5)-time  algorithm. In addition we provide an O(n4)-time algorithm for computing the minimum energy schedule when all jobs have unit length.
multiprocessor speed scaling for jobs with arbitrary sizes and deadlines	In this paper we study energy efficient deadline scheduling on multiprocessors in which the processors consumes power at a rate of $$s^\alpha $$ s ? when running at speed $$s$$ s , where $$\alpha \ge 2$$ ? ? 2 . The problem is to dispatch jobs to processors and determine the speed and jobs to run for each processor so as to complete all jobs by their deadlines using the minimum energy. The problem has been well studied for the single processor case. For the multiprocessor setting, constant competitive online algorithms for special cases of unit size jobs or arbitrary size jobs with agreeable deadlines have been proposed by Albers et al. (2007). A randomized algorithm has been proposed for jobs of arbitrary sizes and arbitrary deadlines by Greiner et al. (2009). We propose a deterministic online algorithm for the general setting and show that it is $$O(\log ^\alpha P)$$ O ( log ? P ) -competitive, where $$P$$ P is the ratio of the maximum and minimum job size.
high performance schedulers	
power and energy management for server systems	This survey shows that heterogeneous server clusters can be made more efficient by conserving power and energy while exploiting information from the service level, such as request priorities established by service-level agreements.
gridsim a toolkit for the modeling and simulation of distributed resource management and scheduling for grid computing	SUMMARY Clusters, Grids, and peer-to-peer (P2P) networks have emerged as popular paradigms for next generation parallel and distributed computing. They enable aggregation of distributed resources for solving largescale problems in science, engineering, and commerce. In Grid and P2P computing environments, the resources are usually geographically distributed in multiple administrative domains, managed and owned by different organizations with different policies, and interconnected by wide-area networks or the Internet. This introduces a number of resource management and application scheduling challenges in the domain of security, resource and policy heterogeneity, fault tolerance, continuously changing resource conditions, and politics. The resource management and scheduling systems for Grid computing need to manage resources and application execution depending on either resource consumers’ or owners’ requirements, and continuously adapt to changes in resource availability. The management of resources and scheduling of applications in such large-scale distributed systems is a complex undertaking. In order to prove the effectiveness of resource brokers and associated scheduling algorithms, their performance needs to be evaluated under different scenarios such as varying number of resources and users with different requirements. In a Grid environment, it is hard and even impossible to perform scheduler performance evaluation in a repeatable and controllable manner as resources and users are distributed across multiple organizations with their own policies. To overcome this limitation, we have developed a Java-based discrete-event Grid simulation toolkit called GridSim. The toolkit supports modeling and simulation of heterogeneous Grid resources (both time- and space-shared), users and application models. It provides primitives for creation of application tasks, mapping of tasks to resources, and their management. To demonstrate suitability of the GridSim toolkit, we have simulated a Nimrod-G
economic based distributed resource management and scheduling for grid computing	Computational Grids, emerging as an infrastructure for next generation computing, enable the sharing, selection, and aggregation of geographically distributed resources for solving large-scale problems in science, engineering, and commerce. As the resources in the Grid are heterogeneous and geographically distributed with varying availability and a variety of usage and cost policies for diverse users at different times and, priorities as well as goals that vary with time. The management of resources and application scheduling in such a large and distributed environment is a complex task. This thesis proposes a distributed computational economy as an effective metaphor for the management of resources and application scheduling. It proposes an architectural framework that supports resource trading and quality of services based scheduling. It enables the regulation of supply and demand for resources and provides an incentive for resource owners for participating in the Grid and motives the users to trade-off between the deadline, budget, and the required level of quality of service. The thesis demonstrates the capability of economic-based systems for peer-to-peer distributed computing by developing users' quality-of-service requirements driven scheduling strategies and algorithms. It demonstrates their effectiveness by performing scheduling experiments on the World-Wide Grid for solving parameter sweep applications.
a heuristic method for the set covering problem	We present a Lagrangian-based heuristic for the well-known Set Covering Problem (SCP). The algorithm was initially designed for solving very large scale SCP instances, involving up to 5,000 rows and 1,000,000 columns, arising from crew scheduling in the Italian Railway Company, Ferrovie dello Stato SpA. In 1994 Ferrovie dello Stato SpA, jointly with the Italian Operational Research Society, organized a competition, called FASTER, intended to promote the development of algorithms capable of producing good solutions for these instances, since the classical approaches meet with considerable difficulties in tackling them. The main characteristics of the algorithm we propose are (1) a dynamic pricing scheme for the variables, akin to that used for solving large-scale LPs, to be coupled with subgradient optimization and greedy algorithms, and (2) the systematic use of column fixing to obtain improved solutions. Moreover, we propose a number of improvements on the standard way of defining the step-size and the ascent direction within the subgradient optimization procedure, and the scores within the greedy algorithms. Finally, an effective refining procedure is proposed. Our code won the first prize in the FASTER competition, giving the best solution value for all the proposed instances. The algorithm was also tested on the test instances from the literature: in 92 out of the 94 instances in our test bed we found, within short computing time, the optimal (or the best known) solution. Moreover, among the 18 instances for which the optimum is not known, in 6 cases our solution is better than any other solution found by previous techniques.
conserving disk energy in network servers	In this paper we study four approaches to conserving disk energy in high-performance network servers. The first approach is to leverage the extensive work on laptop disks and power disks down during periods of idleness. The second approach is to replace high-performance disks with a set of lower power disks that can achieve the same performance and reliability. The third approach is to combine high-performance and laptop disks, such that only one of these two sets of disks is powered on at a time. This approach requires the mirroring (and coherence) of all disk data on the two sets of disks. Finally, the fourth approach is to use multi-speed disks, such that each disk is slowed down for lower energy consumption during periods of light load. We demonstrate that the fourth approach is the only one that can actually provide energy savings for network servers. In fact, our results for Web and proxy servers show that the fourth approach can provide energy savings of up to 23%, in comparison to conventional servers, without any degradation in server performance.
a taxonomy of scheduling in general purpose distributed computing systems	One measure of the usefulness of a general-purpose distributed computing system is the system's ability to provide a level of performance commensurate to the degree of multiplicity of resources present in the system. A taxonomy of approaches to the resource management problem is presented in an attempt to provide a common terminology and classification mechanism necessary in addressing this problem. The taxonomy, while presented and discussed in terms of distributed scheduling, is also applicable to most types of resource management. >
energy efficient online deadline scheduling	This paper extends the study of online algorithms for energy-efficient deadline scheduling to the overloaded setting. Specifically, we consider a processor that can vary its speed between 0 and a maximum speed  T  to minimize its energy usage (of which the rate is roughly a cubic function of the speed). As the speed is upper bounded, the system may be overloaded with jobs and no scheduling algorithms can meet the deadlines of all jobs. An optimal schedule is expected to maximize the throughput, and furthermore, its energy usage should be the smallest among all schedules that achieve the maximum throughput. In designing a scheduling algorithm, one has to face the dilemma of selecting more jobs and being conservative in energy usage. Even if we ignore energy usage, the best possible online algorithm is 4-competitive on throughput [12]. On the other hand, existing work on energy-efficient scheduling focuses on minimizing the energy to complete all jobs on a processor with unbounded speed, giving several  O (1)-competitive algorithms with respect to the energy usage [2, 20]. This paper presents the first online algorithm for the more realistic setting where processor speed is bounded and the system may be overloaded; the algorithm is  O (1)-competitive on both throughput and energy usage. If the maximum speed of the online scheduler is relaxed slightly to (1 + e) T  for some e > 0, we can improve the competitive ratio on throughput to arbitrarily close to one, while maintaining  O (1)-competitive on energy usage.
low power cmos digital design	Motivated by emerging battery-operated applications that demand intensive computation in portable environments, techniques are investigated which reduce power consumption in CMOS digital circuits while maintaining computational throughput. Techniques for low-power operation are shown which use the lowest possible supply voltage coupled with architectural, logic style, circuit, and technology optimizations. An architecturally based scaling strategy is presented which indicates that the optimum voltage is much lower than that determined by other scaling considerations. This optimum is achieved by trading increased silicon area for reduced power consumption. >
job scheduling techniques for distributed systems with heterogeneous processor cardinality	This paper proposes scheduling algorithms for assigning jobs with different release time and execution time, to machines with heterogeneous processor cardinality. We show that this scheduling problem is NP-complete, and propose dynamic programming to find the optimal schedules. Since the dynamic programming is time-consuming we propose techniques that improve the efficiency of the dynamic programming. We also propose heuristic algorithms for this scheduling problem. Experimental results suggest that some of the heuristics not only compute the answer efficiently but also provide good solution
scheduling and dynamic management of applications over grids	The work presented in this Thesis is about scheduling applications in computational Grids. We study how to better manage jobs in a grid middleware in order to improve the performance of the platform. Our solutions are designed to work at the middleware layer, thus allowing to keep the underlying architecture unmodified. First, we propose a reallocation mechanism to dynamically tackle errors that occur during the scheduling. Indeed, it is often necessary to provide a runtime estimation when submitting on a parallel computer so that it can compute a schedule. However, estimations are inherently inaccurate and scheduling decisions are based on incorrect data, and are therefore wrong. The reallocation mechanism we propose tackles this problem by moving waiting jobs between several parallel machines in order to reduce the scheduling errors due to inaccurate runtime estimates. Our second interest in the Thesis is the study of the scheduling of a climatology application on the Grid. To provide the best possible performances, we modeled the application as a Directed Acyclic Graph (DAG) and then proposed specific scheduling heuristics. To execute the application on the Grid, the middleware uses the knowledge of the application to find thebest schedule.
qos guided heuristic algorithms for grid task scheduling	Due to the heterogeneity and geographically distribution of Grid resources, effective and efficient task scheduling algorithms are required. Resource load balancing and minimizing makespan are the fundamental goals of effective and efficient task scheduling. It becomes more complicated when various QoS demands arise from users. In this paper, we have presented two algorithms, QoS Guided Weighted Mean Time-min and QoS Guided Weighted Mean Time Min-Min Max-Min Selective, for QoS based Grid task scheduling. Both algorithms consider the resource performance and QoS demands of tasks for scheduling. The algorithms are simulated using GridSim. The results show that the proposed algorithms outperform in makespan, resource utilization and load balancing than other algorithms such as, Weighted Mean Time-min, Weighted Mean Time Min-Min Max-Min Selective, Min-Min, Max-Min and QoS Guided Min-Min.
energy minimization for periodic real time tasks on heterogeneous processing units	Adopting multiple processing units to enhance the computing capability or reduce the power consumption has been widely accepted for designing modern computing systems. Such configurations impose challenges on energy efficiency in hardware and software implementations. This work targets power-aware and energy-efficient task partitioning and processing unit allocation for periodic real-time tasks on a platform with a library of applicable processing unit types. Each processing unit type has its own power consumption characteristics for maintaining its activeness and executing jobs. This paper proposes polynomial-time algorithms for energy-aware task partitioning and processing unit allocation. The proposed algorithms first decide how to assign tasks onto processing unit types to minimize the energy consumption, and then allocate processing units to fit the demands. The proposed algorithms for systems without limitation on the allocated processing units are shown with an (m+1)-approximation factor, where mis the number of the available processing unit types. For systems with limitation on the number of the allocated processing units, the proposed algorithm is shown with bounded resource augmentation on the limited number of allocated units. Experimental results show that the proposed algorithms are effective for the minimization of the overall energy consumption.
efficient heuristics to minimize total flow time with release dates	This paper addresses the one machine scheduling problem to minimize total flow time with different release dates. This problem is known to be strongly NP-hard. We prove a sufficient and necessary condition for local optimality which can also be considered as a priority rule and propose some efficient heuristics using this condition. The algorithm performances are evaluated with respect to classical heuristics. The worst-case performances are also provided.
a greedy heuristic for the set covering problem	Let A be a binary matrix of size m × n, let cT be a positive row vector of length n and let e be the column vector, all of whose m components are ones. The set-covering problem is to minimize cTx subject to Ax ≥ e and x binary. We compare the value of the objective function at a feasible solution found by a simple greedy heuristic to the true optimum. It turns out that the ratio between the two grows at most logarithmically in the largest column sum of A. When all the components of cT are the same, our result reduces to a theorem established previously by Johnson and Lovasz.
an analysis of technology choices for data grids in a spatial data infrastructure	The concept of grid computing has permeated all areas of distributed computing, changing the way in which distributed systems are designed, developed and implemented. Data grids enable the sharing of data in a virtual organisation and are typically implemented for data federation in data-intensive environments. So far, they have been applied to traditional data (text, image, sound). We present a scenario that describes for the first time how data grids can be applied to enable the sharing of address data in a spatial data infrastructure (SDI). Consolidating spatial data from distributed heterogeneous sources into a single centralised dataset requires, amongst others, a considerable human coordination effort. A data grid consolidates data directly from the distributed sources, thereby eliminating the effort. We present a reference model called Compartimos (Spanish for ‘we share’), that is based on the Open Grid Services Architecture (OGSA) but is customised for sharing address data in an SDI, and we analyse existing technologies, such as the Globus Toolkit, ISO 19100 standards and Open Geospatial Consortium (OGC) web service implementation specifications, for Compartimos. This article advances the mutual understanding between data grids and SDIs and sheds light on a future technological solution that could overcome some of the data sharing impediments that are experienced in SDIs today. Finally, results from the analysis and future directions for research are discussed.
reference model for a data grid approach to address data in a dynamic sdi	A grid is concerned with the integration, virtualization, and management of services and resources in a distributed, heterogeneous environment that supports virtual organizations across traditional administrative and organizational domains. Spatial data infrastructures (SDI) aim to make spatial data from multiple sources available and usable to as wide an audience as possible. The first SDIs of the 1990s followed a top---down approach with the focus on data production and centralization. In recent years, SDIs have seen a huge increase in the number of participants, necessitating a more dynamic bottom-up approach. While much research has been done on web services and SDIs, research on the use of data grids for SDIs is limited. In this paper an emergency response scenario is presented to illustrate how the data grid approach can be used as a decentralized platform for address data in a dynamic SDI. Next, Compartimos (Spanish for `we share') is presented, a reference model for an address data grid in an SDI based on the Open Grid Services Architecture (OGSA). Compartimos identifies the essential components and their capabilities required for a decentralized address data grid in a dynamic SDI. It deviates from the current centralized approach, allows data resources to come and go and node hosts to grow and shrink as necessary. An address data grid in an SDI is both a novel application for data grids as well as a novel technology in SDI environments and thus advances the mutual understanding between data grids and SDIs. In conclusion, additional research required for address data grids in SDIs is discussed.
integrating job parallelism in real time scheduling theory	We investigate the global scheduling of sporadic, implicit deadline, real-time task systems on multiprocessor platforms. We provide a task model which integrates job parallelism. We prove that the time-complexity of the feasibility problem of these systems is linear relatively to the number of (sporadic) tasks for a fixed number of processors. We propose a scheduling algorithm theoretically optimal (i.e., preemptions and migrations neglected). Moreover, we provide an exact feasibility utilization bound. Lastly, we propose a technique to limit the number of migrations and preemptions.
comparison of multi criteria scheduling techniques	We propose a novel schedule-based approach for scheduling a continuous stream of batch jobs on the machines of a computational Grid. Our new solutions represented by dispatching rule Earliest Gap-Earliest Deadline First (EG-EDF) and Tabu search are based on the idea of filling gaps in the existing schedule. EG-EDF rule is able to build the schedule for all jobs incrementally by applying technique which fills earliest existing gaps in the schedule with newly arriving jobs. If no gap for a coming job is available EG-EDF rule uses Earliest Deadline First (EDF) strategy for including new job into the existing schedule. Such schedule is then optimized using the Tabu search algorithm moving jobs into earliest gaps again. Scheduling choices are taken to meet the Quality of Service (QoS) requested by the submitted jobs, and to optimize the usage of hardware resources. Proposed solution is compared with FCFS, EASY backfilling, and Flexible backfilling. Experiments shows that EG-EDF rule is able to compute good assignments, often with shorter algorithm runtime w.r.t. the other queue-based algorithms. Further Tabu search optimization results in higher QoS and machine usage.
condor a distributed job scheduler	
designing a resource broker for heterogeneous grids	Grids provide uniform access to aggregations of heterogeneous resources and services such as computers, networks and storage owned by multiple organizations. However, such a dynamic environment poses many challenges for application composition and deployment. In this paper, we present the design of the Gridbus Grid resource broker that allows users to create applications and specify different objectives through different interfaces without having to deal with the complexity of Grid infrastructure. We present the unique requirements that motivated our design and discuss how these provide flexibility in extending the functionality of the broker to support different low-level middlewares and user interfaces. We evaluate the broker with different job profiles and Grid middleware and conclude with the lessons learnt from our development experience. Copyright © 2007 John Wiley & Sons, Ltd.
online prediction of the running time of tasks	We describe and evaluate the Running Time Advisor (RTA), a system that can predict the running time of a compute-bound task on a typical shared, unreserved commodity host. The prediction is computed from linear time series predictions of host load and takes the form of a confidence interval that neatly expresses the error associated with the measurement and prediction processes – error that must be captured to make statistically valid decisions based on the predictions. Adaptive applications make such decisions in pursuit of consistent high performance, choosing, for example, the host where a task is most likely to meet its deadline. We begin by describing the system and summarizing the results of our previously published work on host load prediction. We then describe our algorithm for computing predictions of running time from host load predictions. We next evaluate the system using over 100,000 randomized testcases run on 39 different hosts, finding that is indeed capable of computing correct and useful confidence intervals. Finally, we report on our experience with using the RTA in application-oriented real-time scheduling in distributed systems.
distributed job scheduling on computational grids using multiple simultaneous requests	Even though middleware support for grid computing has been the subject of extensive research, scheduling policies for the grid context have not been much studied. In addition to processor utilization, it is important to consider the response times of jobs in evaluating the performance of grid scheduling strategies. In this paper we propose distributed scheduling algorithms that use multiple simultaneous requests at different sites. Trace-based simulations show that the use of multiple simultaneous requests provides significant performance benefits. We also show how this scheme can be adapted to provide priority to local jobs, without much loss of performance.
Dominance-based heuristics for one-machine total cost scheduling problems	We study the one-machine scheduling problem with release dates and we look at several objective functions including total (weighted) tardiness and total (weighted) completion time. We describe dominance rules for these criteria, as well as techniques for using these dominance rules to build heuristic solutions. We use them to improve certain well-known greedy heuristic algorithms from the literature. Finally, we introduce a Tabu Search method with a neighborhood based on our dominance rules. Experiments show the effectiveness of our techniques in obtaining very good solutions for all studied criteria.
Scheduling for Fast Turnaround Time on Institutional Desktop grid	Institutional  desktop grids,  that is, grids  comprised by the desktop machines of  an institution (academic or corporate) can act as an important source of computing power for local user, if the high volatility of such resources is properly harnessed. In this paper, we focus on cheduling techniques that can improve turnaround time of bag-of-tasks  applications.  For  that  purpose,  we  combine  shared-checkpoint  management  with  several  scheduling methods like FCFS, adaptive timeout, simple replication and short-term availability predictions. The main goal is to minimize turnaround time by reducing negative effects of resources volatility on the executions of bag-of-tasks applications. We present and assess several scheduling policies oriented toward fast turnaround times, and assess them  through  trace-based  simulations  over  the  resources  of  32  machines  of  two  classrooms  of  an  academic environment
workflow scheduling algorithms in the grid	The development of wide-area networks and the availability of powerful computers as low-cost commodity components are changing the face of computation. These progresses in technology make it possible to utilize geographically distributed resources in multiple owner domains to solve large-scale problems in science, engineering and commerce. Research on this topic has led to the emergence of Grid computing. To achieve the promising potentials of tremendous distributed resources in the Grid, effective and efficient scheduling algorithms are fundamentally important.   However, scheduling problems are well known for their intractability, and many of instances are in fact NP-Complete. The situation becomes even more challenging in the Grid circumstances due to some unique characteristics of the Grid. Scheduling algorithms in traditional parallel and distributed systems, which usually run on homogeneous and dedicated resources, cannot work well in the new environments.   This work focuses on workflow scheduling algorithms in the Grid scenario. New challenges are discussed, previous research in this realm is surveyed, and novel heuristic algorithms addressing the challenges are proposed and tested.   The proposed algorithms contribute to the literature by taking the following factors into account when a schedule for a DAG-based workflow is produced: predictable performance fluctuation and non-deterministic performance model of Grid resources, the computation and data staging co-scheduling, the clustering characteristic of Grid resource distribution, and the ability to reschedule according to performance change after the initial schedule is made. The performance of proposed algorithms are tested and analyzed by simulation under different workflow and resource configurations.
scheduling multiprocessor tasks an overview	Abstract   Multiprocessor tasks require more than one processor at the same moment of time. This relatively new concept in scheduling theory emerged with the advent of parallel computing systems. In this work we present the state of the art for multiprocessor task scheduling. We show the rationale behind the concept of multiprocessor tasks. The standard three-field notation is extended to accommodate multiprocessor tasks. The main part of the work is presentation of the results in multiprocessor tasks scheduling both for parallel and for dedicated processors.
minimizing total tardiness on one machine is np hard	The problem of minimizing the total tardiness for a set of independent jobs on one machine is considered. Lawler has given a pseudo-polynomial-time algorithm to solve this problem. In spite of extensive research efforts for more than a decade, the question of whether it can be solved in polynomial time or it is NP-hard in the ordinary sense remained open. In this paper the problem is shown to be NP-hard in the ordinary sense.
survey of approximation algorithms for set cover problem	In this thesis, I survey 11 approximation algorithms for unweighted set cover problem. I have also implemented the three algorithms and created a software library that stores the code I have written. The algorithms I survey are: 1. Johnson's standard greedy; 2. f-frequency greedy; 3. Goldsmidt, Hochbaum and Yu's modified greedy; 4. Halldorsson's local optimization; 5. Dur and Furer semi local optimization; 6. Asaf Levin's improvement to Dur and Furer; 7. Simple rounding; 8. Randomized rounding; 9. LP duality; 10. Primal-dual schema; and 11. Network flow technique.  Most of the algorithms surveyed are refinements of standard greedy algorithm.
dynamic mapping of a class of independent tasks onto heterogeneous computing systems	Dynamic mapping (matching and scheduling) heuristics for a class of independent tasks using heterogeneous distributed computing systems are studied. Two types of mapping heuristics are considered, immediate mode and batch mode heuristics. Three new heuristics, one for batch mode and two for immediate mode, are introduced as part of this research. Simulation studies are performed to compare these heuristics with some existing ones. In total five immediate mode heuristics and three batch mode heuristics are examined. The immediate mode dynamic heuristics consider, to varying degrees and in different ways, task affinity for different machines and machine ready times. The batch mode dynamic heuristics consider these factors, as well as aging of tasks waiting to execute. The simulation results reveal that the choice of which dynamic mapping heuristic to use in a given heterogeneous environment depends on parameters such as (a) the structure of the heterogeneity among tasks and machines and (b) the arrival rate of the tasks.
dynamic matching and scheduling of a class of independent tasks onto heterogeneous computing systems	Dynamic mapping (matching and scheduling) heuristics for a class of independent tasks using heterogeneous distributed computing systems are studied. Two types of mapping heuristics are considered: on-line and batch mode heuristics. Three new heuristics, one for batch and two for on-line, are introduced as part of this research. Simulation studies are performed to compare these heuristics with some existing ones. In total, five on-line heuristics and three batch heuristics are examined. The on-line heuristics consider; to varying degrees and in different ways, task affinity for different machines and machine ready times. The batch heuristics consider these factors, as well as aging of tasks waiting to execute. The simulation results reveal that the choice of mapping heuristic depends on parameters such as: (a) the structure of the heterogeneity among tasks and machines, (b) the optimization requirements, and (c) the arrival rate of the tasks.
dynamic meta scheduling architecture based on monitoring in distributed systems	The scheduling process in large scale distributed systems (LSDS) became more important due to increases in the number of users and applications. This paper presents a dynamic meta-scheduling architecture model for LSDS based on monitoring. The dynamic scheduling process tries to perform task allocation on the fly as the application executes. The monitoring has an important role in this process because it can offer a full view of nodes in distributed systems. The proposed architecture is an agent framework and contains a grid monitoring service, an execution service and a discovery service. The performance of the used monitoring system, MonALISA, is very important for dynamic scheduling because it ensures the real-time process. The experimental results validate our architecture and scheduling model.
economic models for resource management and scheduling in grid computing	The accelerated development in peer-to-peer and Grid computing has positioned them as promising next-generation computing platforms. They enable the creation of virtual enterprises for sharing resources distributed across the world. However, resource management, application development and usage models in these environments is a complex undertaking. This is due to the geographic distribution of resources that are owned by different organizations or peers. The resource owners of each of these resources have different usage or access policies and cost models, and varying loads and availability. In order to address complex resource management issues, we have proposed a computational economy framework for resource allocation and for regulating supply and demand in Grid computing environments. This framework provides mechanisms for optimizing resource provider and consumer objective functions through trading and brokering services. In a real world market, there exist various economic models for setting the price of services based on supply-and-demand and their value to the user. They include commodity market, posted price, tender and auction models. In this paper, we discuss the use of these models for interaction between Grid components to decide resource service value, and the necessary infrastructure to realize each model. In addition to usual services offered by Grid computing systems, we need an infrastructure to support interaction protocols, allocation mechanisms, currency, secure banking and enforcement services. We briefly discuss existing technologies that provide some of these services and show their usage in developing the Nimrod-G grid resource broker. Furthermore, we demonstrate the effectiveness of some of the economic models in resource trading and scheduling using the Nimrod/G resource broker, with deadline and cost constrained scheduling for two different optimization strategies, on the World-Wide Grid testbed that has resources distributed across five continents. Copyright © 2002 John Wiley & Sons, Ltd.
paths trees and flowers	A graph G for purposes here is a finite set of elements called vertices and a finite set of elements called edges such that each edge meets exactly two vertices, called the end-points of the edge. An edge is said to join its end-points.
	
efficient batch job scheduling in grids using cellular memetic algorithms	Computational grids are an important emerging paradigm for large-scale distributed computing. As grid systems become more wide-spread, techniques for efficiently exploiting the large amount of grid computing resources become increasingly indispensable. A key aspect in order to benefit from these resources is the scheduling of jobs to grid resources. Due to the complex nature of grid systems, the design of efficient grid schedulers becomes challenging since such schedulers have to be able to optimize many conflicting criteria in very short periods of time. This problem has been tackled in the literature by several different metaheuristics, and our main focus in this work is to develop a new highly competitive technique with respect to the existing ones. For that, we exploit the capabilities of cellular memetic algorithms (cMAs), a kind of memetic algorithm with structured population, for obtaining efficient batch schedulers for grid systems, and the obtained results will be compared versus the state of the art. A careful design of the cMA methods and operators for the problem yielded to an efficient and robust implementation. Our experimental study, based on a known static benchmark for the problem, shows that this heuristic approach is able to deliver very high quality planning of jobs to grid nodes and thus it can be used to design efficient dynamic schedulers for real grid systems. Such dynamic schedulers can be obtained by running the cMA-based scheduler in batch mode for a very short time to schedule jobs arriving in the system since the last activation of the cMA scheduler.
a survey of heterogeneous computing concepts and systems	This survey of heterogeneous computing concepts and systems is based on the recently proposed by the authors "EM/sup 3/ " (Execution Modes/Machine Models) taxonomy of computer systems in general. The taxonomy is based on two criteria: the number of execution modes supported by the system and the number of machine models present in the system. Since these two criteria are orthogonal, four classes exist: Single Execution mode/Single machine Model (SESM), Single Execution modes/Multiple machine Models (SEMM), Multiple Execution modes/Single machine Model (MESM), and Multiple Execution modes/Multiple machine Models (MEMM). In Section II, heterogeneous computing concepts are viewed through three phases of the compilation and execution of any heterogeneous application: parallelism detection, parallelism characterization and resource allocation. Parallelism detection phase discovers fine-grain parallelism inside every task. This phase is not an exclusive feature of heterogeneous computing, so it will not be dealt with in greater detail. The assignment of parallelism characterization phase is to estimate the behavior of each task in the application on every architecture in the heterogeneous system. In the parallelism characterization domain, one original taxonomy is given. This taxonomy contains scheme classes such as vector and matrix static and dynamic, implicit and explicit, algorithmic and heuristic and numeric and symbolic. Resource allocation phase determines the place and the moment for execution of every task to optimize certain performance measure related to some criteria. In the resource allocation domain, the existing Casavant-Kuhl taxonomy is extended and used. This well known taxonomy is supplemented with scheme classes such as noncooperative competitive, noncooperative noncompetitive, and load sharing. In Section III, heterogeneous systems characterized with multiple execution modes ("fully" heterogeneous systems falling in the MESM and the MEMM class) are surveyed. The MESM class systems are described and illustrated with three case studies, two of which support SIMD/MIMD and one supports scalar/vector combination of execution modes. The MEMM class systems are described and illustrated with two representative examples of fully heterogeneous networks supporting multiple execution modes. The system software for heterogeneous computing systems is presented according to an original three-dimensional (3-D) taxonomy whose criteria rely on the level of heterogeneity support implementation, the programming approach, and the data access technique applied. In Section III, several representative heterogeneous applications are described with their computation requirements and the systems used for their execution. Each topic covered in the paper contains several concise examples.
The one machine scheduling problem with delay costs	
energy efficient server clusters	This paper evaluates five policies for cluster-wide power management in server farms. The policies employ various combinations of dynamic voltage scaling and node vary-on/vary-off (VOVO) to reduce the aggregate power consumption of a server cluster during periods of reduced workload. We evaluate the policies using a validated simulator that calculates the energy usage and response times of a Web server cluster serving traces culled from real-life Web server workloads. Our results show that a relatively simple policy of independent dynamic voltage scaling on each server node can achieve savings ranging up to 29% and is competitive with more complex schemes for some workloads. A policy that brings nodes online and takes them offline depending on the workload intensity also produces significant savings up to 42%. The largest savings are obtained by using a coordinated voltage scaling policy in conjunction with VOVO. This policy provides up to 18% more savings than just using VOVO in isolation. All five policies maintain server response times within acceptable norms.
one machine sequencing to minimize certain functions of job tardiness	This paper first considers the problem of sequencing n jobs on one machine to minimize total tardiness. It proves theorems that establish the relative order in which pairs of jobs are processed in an optimal schedule; frequently they permit the jobs to be completely ordered, thus solving the problem without any searching. In particular, corollaries establish more general conditions than are currently recognized under which sequencing in order of nondecreasing processing times and sequencing in order of nondecreasing due dates are optimal. In general, even large problems may be at least partially ordered to the point that very few schedules remain to be searched. These results are then partly extended to the more general criterion of minimizing a sum of identical, convex, nondecreasing functions of job tardiness, and an efficient algorithm is proposed.
A Min-Min Max-Min selective algorihtm for grid task scheduling	Today, the high cost of supercomputers in the one hand and the need for large-scale computational resources on the other hand, has led to use network of computational resources known as Grid. Numerous research groups in universities, research labs, and industries around the world are now working on a type of Grid called Computational Grids that enable aggregation of distributed resources for solving large-scale data intensive problems in science, engineering, and commerce. Several institutions and universities have started research and teaching programs on Grid computing as part of their parallel and distributed computing curriculum. To better use tremendous capabilities of this distributed system, effective and efficient scheduling algorithms are needed. In this paper, we introduce a new scheduling algorithm based on two conventional scheduling algorithms, Min-Min and Max-Min, to use their cons and at the same time, cover their pros. It selects between the two algorithms based on standard deviation of the expected completion time of tasks on resources. We evaluate our scheduling heuristic, the Selective algorithm, within a grid simulator called GridSim. We also compared our approach to its two basic heuristics. The experimental results show that the new heuristic can lead to significant performance gain for a variety of scenarios.
evaluation of job scheduling strategies for grid computing	In this paper, we discuss typical scheduling structures that occur in computational grids. Scheduling algorithms and selection strategies applicable to these structures are introduced and classified. Simulations were used to evaluate these aspects considering combinations of different Job and Machine Models. Some of the results are presented in this paper and are discussed in qualitative and quantitative way. For hierarchical scheduling, a common scheduling structure, the simulation results confirmed the benefit of Backfill. Unexpected results were achieved as FCFS proves to perform better than Backfill when using a central job-pool.
an o n 2 5 algorithm for maximum matching in general graphs	
Basic Functionalities of a Grid-Infrastructure for Service-Oriented Content Management	To cope with the rapidly growing challenges of Content Management, a number of actions must be taken to create a competing new Content Management System. A service-oriented, automated design poses various challenges for the underlying infrastructure. For this thesis, the requirements were layered into three categories.  The service runtime has to provide basic SOA and manageability functionalities.  For the non-trivial Content Management services, classical stateless Web Services are not sufficient. Stateful services with life cycle capabilities are needed to manage scalability and fine-grained optimization tasks. The category of Resource Management (RM) combines requirements which focus on the handling of resource-based functionalities.   Key features of a required RM system are resource allocation and resource provisioning.  By providing customized access to a resource model, customers, administrators or computer programs can get an overview of currently used resources or services.  The provisioning service allows to install, configure  and  start  arbitrary  applications  on  newly  allocated  resources.   Together  with  a broad range of monitoring data,  the RM system offers a main piece of system knowledge, which is needed for the requirements category stated as System Automation .  This category concentrates on the combination of offered information by the service runtime and RM system to form a knowledge base for a kind of autonomic manager.  This autonomic manager has to be configured with detailed service policies, which control the system behaviour.  System automation is the field were a lot of research has to be done, as SLAs have to be transformed into service policies automatically.  To create effective service policies, the effects of possible configuration actions like the provisioning of new resources to a running EAM system are needed. For  this  thesis  the grid-related standards  WSRF  and  WSDM,  in  addition  to  their  open source implementations along with the commercial solutions IBM Dynamic Infrastructure (IDI) and IBM WebSphere Extended Deployment (WXD), were evaluated against the presented requirements. With the Web Services Resource Framework (WSRF) and the Web Services Distributed Management (WSDM), two powerful specifications exist that can offer the functionalities needed for a service runtime.  By taking WSRF as a requirement, the  Globus Tookit 4 and Apache Muse were  compared  and  evaluated.   With  Apache  Muse,  a  lightweight  implementation  was  chosen,  which  offers  a  flexible  way  to  create  different  service  granularities. With being runnable in standardized J2EE containers, the advantages of robust and well-known  application  servers  like  the IBM  WebSphere  Application  Server can  be  used.   By using WSDM features like metrics or relationships, the base for a manageable EAM system needed for later system automation is given. The implementation of a prototype by using Apache Muse has proven that for management and orchestrating functionalities WSRF / WSDM-based Web Services are a practical and comfortable way.  Compared to the previous cluster-based prototype, the new SOA-based implementation competes regarding performance and scalability, while offering extended features for configuration and manageability. IBM Dynamic Infrastructure (IDI) and IBM WebSphere XD (WXD) can cover a lot of the remaining requirements for resource management and system automation.  By having a central point of control with the IDI management console, all administrative tasks starting with offering an EAM service to customers,  over initiating a customized EAM instance based on a customer’s subscription, to manual management tasks during runtime and the final service termination can be handled.  A detailed resource model can be created, to manage resource allocations and metering tasks. WXD provides a powerful runtime environment for the CM services.  By combining all application servers allocated for an EAM instance to a dynamic cluster (see section 5.2), management tasks like application installation and configuration can be processed at a central point. The feature of vertical stacking can improve the overall resource utilization and can be configured to run automatically.  With its integrated monitoring capabilities, WXD provides a lot of the needed monitoring functionalities.  As a first step to system automation the optimization features by the On Demand Router (ODR) could be used. Although to handle the required  high-level service level objectives for EAM, a lot of work has to be done to adapt the features for the EAM system Figure 7.1 shows a possible composition of the infrastructure for the EAM system out of the evaluated software systems. The WebSphere Application Server (under control of WXD) builds the basis for the service runtime. Apache Muse, with its WSRF and WSDM conform Web Service stack, provides a comfortable solution for the service runtime. The monitoring aspect of resource management is not completely covered by the evaluated products.  Application-based monitoring can be implemented with Muse, although the scalability aspect of WSDM-based monitoring has to be examined. WXD offers low-level monitoring functionalities for the WebSphere servers. None of the products can combine the application and system-based monitoring data into one data stream. IDI covers most of the other necessary resource management functionalities.  Exemplarily the parts Resource Model and Provisioning Service are illustrated in figure 7.1. Most functionalities are missing in the automation category. SLA management is only partly covered by IDI and WXD. IDI offers event-based metering and accounting capabilities. The SLA functionalities of WXD may be expandable to meet the EAM requirements. The same applies for the policy-based optimization rules of WXD. Nevertheless, a lot of research has to be done regarding system automation.
Power provisioning for a warehouse-sized computer	Large-scale Internet services require a computing infrastructure that can beappropriately described as a warehouse-sized computing system. The cost ofbuilding datacenter facilities capable of delivering a given power capacity tosuch a computer can rival the recurring energy consumption costs themselves.Therefore, there are strong economic incentives to operate facilities as closeas possible to maximum capacity, so that the non-recurring facility costs canbe best amortized. That is difficult to achieve in practice because ofuncertainties in equipment power ratings and because power consumption tends tovary significantly with the actual computing activity. Effective powerprovisioning strategies are needed to determine how much computing equipmentcan be safely and efficiently hosted within a given power budget. In this paper we present the aggregate power usage characteristics of largecollections of servers (up to 15 thousand) for different classes ofapplications over a period of approximately six months. Those observationsallow us to evaluate opportunities for maximizing the use of the deployed powercapacity of datacenters, and assess the risks of over-subscribing it. We findthat even in well-tuned applications there is a noticeable gap (7 - 16%)between achieved and theoretical aggregate peak power usage at the clusterlevel (thousands of servers). The gap grows to almost 40% in wholedatacenters. This headroom can be used to deploy additional compute equipmentwithin the same power budget with minimal risk of exceeding it. We use ourmodeling framework to estimate the potential of power management schemes toreduce peak power and energy usage. We find that the opportunities for powerand energy savings are significant, but greater at the cluster-level (thousandsof servers) than at the rack-level (tens). Finally we argue that systems needto be power efficient across the activity range, and not only at peakperformance levels
a threshold of ln n for approximating set cover	Given a collection    F    of subsets of  S  ={1,…, n },  setcover  is the problem of selecting as few as possiblesubsets from      F    such that their union covers S, , and  maxk-cover  is the problem of selecting k  subsets from     F    such that their union has maximum cardinality. Both these problems areNP-hard.   We prove that (1 -  o (1)) ln n  is a threshold below   which setcover cannot be approximated efficiently, unless NP has slightlysuperpolynomial time algorithms. This closes the gap (up to low-orderterms) between the ratio of approximation achievable by the greedyalogorithm (which is (1 -  o (1)) lnn), and provious results of Lund and Yanakakis, that showed hardness ofapproximation within a ratio of       log   2  n  /2s0.72   ln  n . For max k -cover, we show an approximationthreshold of (1 - 1/ e )(up tolow-order terms), under assumption that   P≠NP   .
a price anticipating resource allocation mechanism for distributed shared clusters	In this paper we formulate the fixed budget resource allocation game to understand the performance of a distributed market-based resource allocation system. Multiple users decide how to distribute their budget  bids ) among multiple machines according to their  individual preferences  to maximize their individual utility. We look at both the efficiency and the fairness of the allocation at the equilibrium, where fairness is evaluated through the measures of  utility uniformity  and  envy-freeness . We show analytically and through simulations that despite being highly decentralized, such a system converges quickly to an equilibrium and unlike the  social optimum  that achieves high efficiency but poor fairness, the proposed allocation scheme achieves a nice balance of high degrees of efficiency and fairness at the equilibrium.
allocating modules to processors in a distributed system	The author studies the complexity of the problem of allocating modules to processes in a distributed system to minimize total communication and execution costs. He shows that unless P=NP, there can be no polynomial-time epsilon -approximate algorithm for the problem, nor can there exist a local search algorithm that requires polynomial time per iteration and yields an optimum assignment. Both results hold even if the communication graph is planar and bipartite. On the positive side, it is shown that if the communication graph is a partial k-tree or an almost-tree with parameter k, the module allocation problem can be solved in polynomial time. >
model of grid scheduling problem	An extension of Graham's classification of scheduling problems is proposed to cover Grid Scheduling Problems (GSP). The GSP consists of heterogeneous resources in distributed structures (queues), various jobs, and optimality criteria. We will discuss the characteristics (fault tolerance, competitive behavior) of this model and the hierarchies applied for description of the Grid structure.
flowmanager a workflow management system based on petri nets	The use of workflow technology to provide automated support to the management and execution of software engineering processes has become of great interest for large software companies that nowadays are moving towards the new model of "virtual" organizations. Therefore, workflow systems that allow co-operation among team members in a distributed environment are now a primary concern. In this paper we present a new workflow management system, named FlowManager, which has all the potential to be used in such application domain. FlowManager, in fact, will be a component of a larger European GENESIS project (Generalized Environment for Process Management in Cooperative Software Engineering), whose objective is to develop a non-invasive and open source environment for modeling software engineering processes and managing co-operation among geographically distributed teams.
dag scheduling for grid computing systems	Today’s parallel and distributed systems are changing in their organization and the concept of Grid computing, a set of dynamic and heterogeneous resources connected via Internet and shared by many and different users, is nowadays becoming a reality. A large number of scheduling heuristics for parallel applications described by directed acyclic graphs (DAGs) have been presented in the literature, but most of them assume a homogeneous system with a homogeneous network, i.e. a message is transmitted with the same speed on all the links. In a Grid environment this assumption cannot be done. In this thesis we tackle the problem of scheduling parallel applications described by directed acyclic graphs (DAGs) in a Grid computing system.
a quality of service architecture that combines resource reservation and application adaptation	Reservation and adaptation are two well-known and effective techniques for enhancing the end-to-end performance of network applications. However, both techniques also have limitations, particularly when dealing with high-bandwidth, dynamic flows: fixed-capability reservations tend to be wasteful of resources and hinder graceful degradation in the face of congestion, while adaptive techniques fail when congestion becomes excessive. We propose an approach to quality of service (QoS) that overcomes these difficulties by combining features of reservations and adaptation. In this approach, a combination of online control interfaces for resource management, a sensor permitting online monitoring, and decision procedures embedded in resources enable a rich variety of dynamic feedback interactions between applications and resources. We describe a QoS architecture, GARA, that has been extended to support these mechanisms, and use three examples of application-level adaptive strategies to show how this framework can permit applications to adapt both their resource requests and behavior in response to online sensor information.
the anatomy of the grid enabling scalable virtual organizations	"Grid" computing has emerged as an important new field, distinguished from conventional distributed computing by its focus on large-scale resource sharing, innovative applications, and, in some cases, high performance orientation. In this article, the authors define this new field. First, they review the "Grid problem," which is defined as flexible, secure, coordinated resource sharing among dynamic collections of individuals, institutions, and resources--what is referred to as virtual organizations. In such settings, unique authentication, authorization, resource access, resource discovery, and other challenges are encountered. It is this class of problem that is addressed by Grid technologies. Next, the authors present an extensible and open Grid architecture, in which protocols, services, application programming interfaces, and software development kits are categorized according to their roles in enabling resource sharing. The authors describe requirements that they believe any such mechanisms must satisfy and discuss the importance of defining a compact set of intergrid protocols to enable interoperability among different Grid systems. Finally, the authors discuss how Grid technologies relate to other contemporary technologies, including enterprise integration, application service provider, storage service provider, and peer-to-peer computing. They maintain that Grid concepts and technologies complement and have much to contribute to these other approaches.
the globus project a status report	The Globus project is a multi-institutional research effort that seeks to enable the construction of computational grids providing pervasive, dependable, and consistent access to high-performance computational resources, despite geographical distribution of both resources and users. Computational grid technology is being viewed as a critical element of future high-performance computing environments that will enable entirely new classes of computation-oriented applications, much as the World Wide Web fostered the development of new classes of information-oriented applications. The authors report on the status of the Globus project as of early 1998. They describe the progress that has been achieved to date in the development of the Globus toolkit, a set of core services for constructing grid tools and applications. They also discuss the Globus Ubiquitous Supercomputing Testbed (GUSTO) that they have constructed to enable large-scale evaluation of Globus technologies, and they review early experiences with the development of large-scale grid applications on the GUSTO testbed.
the set partitioning problem set covering with equality constraints	This paper gives an enumerative algorithm for the set-partitioning problem, that is, the set-covering problem with equality constraints, and presents computational results for real and randomly generated problems. The fact that many problems can be solved more rapidly than the corresponding linear programs demonstrates the efficiency of the algorithm; for example, a randomly generated problem with 1,400 variables and 100 constraints was solved in 15 minutes.
A Linear Programming Driven Genetic Algorithm for Meta-Scheduling on Utility Grids	The user-level brokers in grids consider individual application QoS requirements and minimize their cost without considering demands from other users. This results in contention for resources and sub-optimal schedules. Meta-scheduling in grids aims to address this scheduling problem, which is NP hard due to its combinatorial nature. Thus, many heuristic-based solutions using genetic algorithm (GA) have been proposed, apart from traditional algorithms such as greedy and FCFS. We propose a Linear Programming/Integer Programming model (LP/IP) for scheduling these applications to multiple resources. We also propose a novel algorithm LPGA (linear programming driven genetic algorithm) which combines the capabilities of LP and GA. The aim of this algorithm is to obtain the best meta-schedule for utility grids which minimize combined cost of all users in a coordinated manner. Simulation results show that our proposed integrated algorithm offers the best schedule having the minimum processing cost with negligible time overheard.
Meta scheduling for market-oriented grid and utility computing	With the significant advances in Information and Communications Technology (ICT) over the last half century, there is an increasingly perceived vision that computing will one day be the 5th utility (after water, electricity, gas, and telephony). This computing utility, like all other four existing utilities, will provide the basic level of computing service that is considered essential to meet the everyday needs of the general community. To deliver this vision, a number of computing paradigms have been proposed, of which the latest one is known as Cloud computing. Hence, in this paper, we define Cloud computing and provide the architecture for creating Clouds with market-oriented resource allocation by leveraging technologies such as Virtual Machines (VMs). We also provide insights on market-based resource management strategies that encompass both customer-driven service management and computational risk management to sustain Service Level Agreement (SLA)-oriented resource allocation. In addition, we reveal our early thoughts on interconnecting Clouds for dynamically creating global Cloud exchanges and markets. Then, we present some representative Cloud platforms, especially those developed in industries, along with our current work towards realizing market-oriented resource allocation of Clouds as realized in Aneka enterprise Cloud technology. Furthermore, we highlight the difference between High Performance Computing (HPC) workload and Internet-based services workload. We also describe a meta-negotiation infrastructure to establish global Cloud exchanges and markets, and illustrate a case study of harnessing 'Storage Clouds' for high performance content delivery. Finally, we conclude with the need for convergence of competing IT paradigms to deliver our 21st century vision.
market oriented resource management and scheduling a taxonomy and survey	Market-oriented computing has gained a lot of attention both from industry and academia. Grid computing is the major paradigm, which supports the market-oriented computing, thus can enable vision of computing as utility a reality. Most important challenge in enabling utility Grids is the resource management and scheduling. From last decade many researchers has try to address many issues within the resource management and scheduling but still it looks far away from the original vision. Thus, to find out the gaps and direct future research, this chapter summarizes and classified all the important works through a comprehensive Taxonomy. This chapter also presents the survey of the most popular market-oriented resource management systems with research gaps still needed to be filled in. This survey is intended to help researchers to make cooperative effort towards the goal of utility grids and provide insights for extending and reusing the existing grid middleware.
g commerce market formulations controlling resource allocation on the computational grid	In this paper we investigate G-commerce-computational economies for controlling resource allocation in Computational Grid settings. We define hypothetical resource consumers (representing users and Grid-aware applications) and resource producers (representing resource owners who "sell" their resources to the Grid). We then measure the efficiency of resource allocation under two different market conditions: commodities markets and auctions. We compare both market strategies in terms of price stability, market equilibrium, consumer efficiency, and producer efficiency. Our results indicate that commodities markets are a better choice for controlling Grid resources than previously defined auction strategies.
on heuristic search for the single machine total weighted tardiness problem some theoretical insights and their empirical verification	The article presents theoretical and experimental investigations of computational intelligence techniques for machine sequencing problems. Contrary to other approaches, which are experimentally driven only, our work is motivated by gaining insights in the underlying principles of heuristic search for this particular problem. We therefore first theoretically analyze local search neighborhoods, deriving expectations about their relative performance. An empirical study on benchmark data follows, verifying the initial propositions. In result, we may conclude theoretically and empirically on the relative performance of neighborhood search operators for the single machine total weighted tardiness problem. The results are useful for the proposition of heuristic search procedures based on local search, as they lead to an order of neighborhood structures with respect to their relative performance. The obtained insights are verified by investigating the effectiveness of a (multi-operator) Variable Neighborhood Search approach for the problem at hand. We are able to show that most known benchmark instances are reliably solved to optimality, leaving an overall average gap of around 1% above the optimum.
maximum skew symmetric flows and matchings	The maximum integer skew-symmetric flow problem (MSFP) generalizes both the maximum flow and maximum matching problems. It was introduced by Tutte [28] in terms of self-conjugate flows in antisymmetrical digraphs. He showed that for these objects there are natural analogs of classical theoretical results on usual network flows, such as the flow decomposition, augmenting path, and max-flow min-cut theorems. We give unified and shorter proofs for those theoretical results. We then extend to MSFP the shortest augmenting path method of Edmonds and Karp [7] and the blocking flow method of Dinits [4], obtaining algorithms with similar time bounds in general case. Moreover, in the cases of unit arc capacities and unit “node capacities” our blocking skew-symmetric flow algorithm has time bounds similar to those established in [8, 21] for Dinits’ algorithm. In particular, this implies an algorithm for finding a maximum matching in a nonbipartite graph in * time, which matches the time bound for the algorithm of Micali and Vazirani [25]. Finally, extending a clique compression technique of Feder and Motwani [9] to particular skew-symmetric graphs, we speed up the implied maximum matching algorithm to run in * time, improving the best known bound for dense nonbipartite graphs. Also other theoretical and algorithmic results on skew-symmetric flows and their applications are presented.
a modified greedy heuristic for the set covering problem with improved worst case bound	The Set Covering problem is an NP-complete problem. A recent result of Lund and Yanakakis establishes that Set Covering cannot be approximated with ratio c log2n for any c < 14 unless all NP problems are solvable in DTIME(npolylog n). The known greedy algorithm for Set Covering delivers a ratio of H(d) = ∑di=11i, where d is the size of the largest set, a value bounded by 1 + log d. Here we describe an improved version of the greedy algorithm and show that its worst case ratio bound is, H(d) − 16.
market based resource allocation for grid computing a model and simulation	
outline of an algorithm for integer solutions to linear programs	
scalably scheduling power heterogeneous processors	We show that a natural online algorithm for scheduling jobs on a heterogeneous multiprocessor, with arbitrary power functions, is scalable for the objective function of weighted flow plus energy.
algebraic algorithms for matching and matroid problems	We present new algebraic approaches for two well-known combinatorial problems: nonbipartite matching and matroid intersection. Our work yields new randomized algorithms that exceed or match the efficiency of existing algorithms. For nonbipartite matching, we obtain a simple, purely algebraic algorithm with running time $O(n^\omega)$ where $n$ is the number of vertices and $\omega$ is the matrix multiplication exponent. This resolves the central open problem of Mucha and Sankowski (2004). For matroid intersection, our algorithm has running time $O(nr^{\omega-1})$ for matroids with $n$ elements and rank $r$ that satisfy some natural conditions.
a better than greedy approximation algorithm for the minimum set cover problem	In the weighted set-cover problem we are given a set of elements $E=\{ e_1,e_2, \ldots ,e_n \}$ and a collection $\cal F$ of subsets of $E$, where each $S \in \cal F$ has a positive cost $c_{S}$. The problem is to compute a subcollection $SOL$ such that $\bigcup_{S\in SOL}S_j=E$ and its cost $\sum_{S\in SOL}c_S$ is minimized. When $|S|\le k\ \forall S\in\cal F$ we obtain the weighted $k$-set cover problem. It is well known that the greedy algorithm is an $H_k$-approximation algorithm for the weighted $k$ set cover, where $H_k=\sum_{i=1}^k {1 \over i}$ is the $k$th harmonic number, and that this bound is exact for the greedy algorithm for all constant values of $k$. In this paper we give the first improvement on this approximation ratio for all constant values of $k$. This result shows that the greedy algorithm is not the best possible for approximating the weighted set cover problem. Our method is a modification of the greedy algorithm that allows the algorithm to regret.
gma a gma based monitoring and management infrastructure for grid	In this paper, we investigate many monitoring and management tools in Grid and other distributed systems. After focusing on the advantage and disadvantage of GMA (Grid Monitoring Architecture), we propose a new monitoring and management schema for Grid –GMA+. In GMA+, we add a close loop feedback structure to GMA and provides interfaces which match Grid Service standards for all its components and defines metadata for monitoring events. It is a novel infrastructure for Grid monitoring and management with highly modularity, usability and scalability.
QoS guided Min-Min heuristic for grid task scheduling	Task scheduling is an integrated component of computing. With the emergence of Grid and ubiquitous computing, new challenges appear in task scheduling based on properties such as security, quality of service, and lack of central control within distributed administrative domains. A Grid task scheduling framework must be able to deal with these issues. One of the goals of Grid task scheduling is to achieve high system throughput while matching applications with the available computing resources. This matching of resources in a non-deterministically shared heterogeneous environment leads to concerns over Quality of Service (QoS). In this paper a novel QoS guided task scheduling algorithm for Grid computing is introduced. The proposed novel algorithm is based on a general adaptive scheduling heuristics that includes QoS guidance. The algorithm is evaluated within a simulated Grid environment. The experimental results show that the new QoS guided Min-Min heuristic can lead to significant performance gain for a variety of applications. The approach is compared with others based on the quality of the prediction formulated by inaccurate information.
High-performance Intelligent Computations for Environmental and Disaster Monitoring	In this paper we present different approaches to multi-source data integration for the solution of complex applied  problems,  in  particular  flood  mapping  and  vegetation  state  estimation  using  satellite,  modelling  and  in-situ data. Since these applications are data- and computation-intensive, we use Grid computing technologies. In such a case  computational  and  informational  resources  are  geographically  distributed  and  may  belong  to  different  organisations.  For  this  purpose,  we  also  investigate  benefits  of  different  approaches  to  the  integration  of  satellite-based monitoring systems. 
approximation algorithms for the set covering and vertex cover problems	We propose a heuristic that delivers in $O(n^3 )$ steps a solution for the set covering problem the value of which does not exceed the maximum number of sets covering an element times the optimal value.
an n 5 2 algorithm for maximum matchings in bipartite graphs	The present paper shows how to construct a maximum matching in a bipartite graph with n vertices and m edges in a number of computation steps proportional to $(m + n)\sqrt n $.
hrmf g a grid based hierarchical resource management framework	Grid resource management is a core component of the grid. This paper analyzes the characteristics of the grid, and designed a Hierarchical Resource Management Framework for data resource in grid(HRMF-G). For the characteristics of the grid and the existing shortage of hierarchical resource management, we improved, respectively, the resource management domain model by Wang Hong et al, the multi-level resource schedule model by Zeren Zhima et al and the general resource manager by Klaus Krauter et al. And then applies them to the HRMF-G.
Algorithmic problems in power management	We survey recent research that has appeared in the theoretical computer science literature on algorithmic problems related to power management. We will try to highlight some open problem that we feel are interesting. This survey places more concentration on lines of research of the authors: managing power using the techniques of speed scaling and power-down which are also currently the dominant techniques in practice.
algorithms for power savings	This article examines two different mechanisms for saving power in battery-operated embedded systems. The first strategy is that the system can be placed in a sleep state if it is idle. However, a fixed amount of energy is required to bring the system back into an active state in which it can resume work. The second way in which power savings can be achieved is by varying the speed at which jobs are run. We utilize a power consumption curve  P ( s ) which indicates the power consumption level given a particular speed. We assume that  P ( s ) is convex, nondecreasing, and nonnegative for  s  ≥ 0. The problem is to schedule arriving jobs in a way that minimizes total energy use and so that each job is completed after its release time and before its deadline. We assume that all jobs can be preempted and resumed at no cost. Although each problem has been considered separately, this is the first theoretical analysis of systems that can use both mechanisms. We give an offline algorithm that is within a factor of 2 of the optimal algorithm. We also give an online algorithm with a constant competitive ratio.
resource management in grid computing a review	As technology advances and the popularity and dependence on internet increases by the day, new ways of finding faster and cheaper solutions to computational problems are sought. This has lead to the development of a new concept known as grid computing, which is a type of distributed computing, heterogeneous in nature because it makes an aggregated use of resources distributed over a large geographical area to solve problems usually complex ones on a larger scale. Since it involves using resources from different places, from different ownerships and with different individual qualities, it requires a complex resource management process for its proper functioning. This article provides a brief overview on grid computing and its resource management processes, important factors considered in resource management, comparison of different resource management processes and future outlook of grid computing and its resource management.
live runtime power measurements as a foundation for evaluating power performance tradeoffs	,+ ' /. # 0,12. 0 ( # 3%& ) 45 76 . ) 6 8' 9% : 45  0@?A B ^ _7 /. % %& # Q' ) %&' a :"$%& N # % D . "5. 4$ ' f%& # "5 @ & T1g4$ E. h @ N # # % -% . % u t vw% . %I "='G I. ' ! x "$ E &1K"$ 1Z ] 1a ) 4=' J : # Q' I.T' "5# 6S' .T'K N & + /. # % &? # ) ' I. 4N"$ ) K ) %I y. R "$'2 N ) 45. ' "$ # R"5#/' , .T'I.U% . % 0 ?>  0 !3p &' "$% + Z D . 4$) .T' "5# 6].G "$6 #:% #f' "$ . N & N1Z + % ) 7 #o% : . "$# 6/ N & + /. # % H N # & ' ' U N 12 & R%& Q' + K .T ' "5%&) 45. J @ "$6 #p &45 & : # ' !9P2 7 45. ' + + 7' S  #X I @ & H' f"5 45. ' y . ' "$% ) 45. N  ¢ i . : 45 & 7 + ' H N T1Z & 1K"$# 1K y "$ 45. 0 X1K"=' 4$"$DE fj2. Q' 4$ f N T1Z & . "$# 6 /. ' * 45 @ #p N # % A »pI Ð N OOAI ·K ̧¬1No|»T1⁄4`O(3⁄4]O  ̧¬»T1⁄4 A AE I9A IH1⁄4 »yÂ`1⁄4 A E o|»T1⁄4 Â`1⁄4@A(AEHAAA »fI(ÐTN O¬OAI m H' "$ H1Z N M1Z + % ) U #X' ' 'I. 43 N 12 & H . @"$# 6 U6 "$DE # 0c "= %&'H : . ) : &# ' !/z{ "$45 :' : N T1Z & U . @ 1K# G1K"$454 4$"$ E 4=0` TDE ) + ) 4Z"$# + ) ' ) U12 N M1Z / F# 'H) U' + & ) 4=' ,6 "$DE #p"$#p' "$ R . N  12 &#Y' "$# ' & # . 42 N 12 < : ) 4=0 . # y : ' < N E. I C!-zX J' # 45. % p.U ) # 'Z "$ Q' ,"5# & "$ Shunt Resistor
dominance rules for the parallel machine total weighted tardiness scheduling problem with release dates	We address the parallel machine total weighted tardiness scheduling problem with release dates. We describe dominance rules and filtering methods for this problem. Most of them are adaptations of dominance rules based on solution methods for the single-machine problem. We show how it is possible to deduce whether or not certain jobs can be processed by a particular machine in a particular context and we describe techniques that use this information to improve the dominance rules. On the basis of these techniques we describe an enumeration procedure and we provide experimental results to determine the effectiveness of the dominance rules.
new precedence theorems for one machine weighted tardiness	In an earlier paper by Emmons [Emmons, H. 1969. One-machine sequencing to minimize certain functions of job tardiness. Oper. Res.17 701--715], the problem of sequencing jobs on a single machine in order to minimize total tardiness was analyzed. Emmons provided three theorems for specifying precedence relations for pairs of jobs. His theorems apply when the tardiness penalty for each job grows at the same rate. Rinnooy Kan et al. [Rinnooy Kan, A. H. G., B. J. Lageweg, J. K. Lenstra. 1975. Minimizing total costs in one-machine scheduling. Oper. Res.23 908--927] later extended Emmons's theorems to the case when job tardiness penalties can grow at different rates for different jobs. Provided here is a set of theorems, stronger than those of Rinnooy Kan et al., that more fully exploits the special properties of the weighted tardiness function, allowing for greater reduction of the solution space.
Algorithms for bipartite matching problems with connections to sparsification and streaming	The problem of finding maximum matchings in bipartite graphs is a classical problem in combinato- rial optimization with a long algorithmic history.  Graph sparsification is a more recent paradigm of replacing a graph with a smaller subgraph that preserves some useful properties of the original graph, perhaps approximately.  Traditionally, sparsification has been used for obtaining faster algorithms for cut-based optimization problems. The contributions of this thesis are centered around new algorithms for bipartite matching prob- lems,  in  which,  surprisingly,  graph  sparsification  plays  a  major  role,  and  efficient  algorithms  for constructing sparsifiers in modern data models. In the first part of the thesis we develop sublinear time algorithms for finding perfect matchings in regular bipartite graphs.  These graphs have been studied extensively in the context of expander constructions, and have several applications in combinatorial optimization.  The problem of finding perfect matchings in regular bipartite graphs has seen almost 100 years of algorithmic history, with the first algorithm dating back to K ̈onig in 1916 and an algorithm with runtime linear in the number of edges in the graph discovered in 2000.  In this thesis we show that, even though traditionally the use of sparsification has been restricted to cut-based problems, in fact sparsification yields extremely efficient sublinear time algorithms for finding perfect matchings in regular bipartite graphs when the graph is given in adjacency array representation.  Thus, our algorithms recover a perfect matching (with high probability) without looking the whole input.  We present two approaches, one based on independent sampling and another on random walks, obtaining an algorithm that recovers a perfect matching in O ( n log n ) time, within O (log n ) of output complexity, essentially closing the problem. In the second part of the thesis we study the streaming complexity of maximum bipartite match- ing.  This problem is relevant to modern data models, where the algorithm is constrained in space and is only allowed few passes over the input.  We are interested in determining the best tradeoff between the space usage and the quality of the solution obtained.  We first study the problem in the single pass setting.  A central object of our study is a new notion of sparsification relevant to matching problems:  we define the notion of an -matching cover of a bipartite graph as a subgraph that approximately preserves sizes of matchings between every two subsets of vertices, which can be viewed as a sparsifier for matching problems.  We give an efficient construction of a sparse subgraph that we call a matching skeleton, which we show is a linear-size matching cover for a certain range of parameters (in fact, for _x005F_x000f_ > 1 / 2).  We then show that our sparsifier can be applied repeatedly while maintaining a non-trivial approximation ratio in the streaming model with vertex arrivals, obtaining the first 1 − 1 /e deterministic one-pass streaming algorithm that uses linear space for this setting. Further, we show that this is in fact best possible:  no algorithm can obtain a better than 1 − 1 /e approximation in a single pass unless it uses significantly more than quasilinear space.  This is a rather striking conclusion since a 1 − 1 /e approximation can be obtained even in the more restrictive online model for this setting.  Thus, we show that streaming algorithms can get no advantage over online algorithms for this problem unless they use substantially more than quasilinear space. Our impossibility results for approximating matchings in a single pass using small space exploit a  surprising  connection  between  the  sparsifiers  that  we  define  and  a  family  of  graphs  known  as Ruzsa-Szemer ́edi graphs.  In particular, we show that bounding the best possible size of _x005F_x000f_ -covers for general _x005F_x000f_ is essentially equivalent to determining the optimal size of an _x005F_x000f_ -Ruzsa-Szemer ́edi graph. These graphs have received significant attention due to applications in PCP constructions, property testing and additive combinatorics,  but determining their optimal size still remains a challenging open problem. Besides giving matching upper and lower bounds for single pass algorithms in the vertex arrival setting, we also consider the problem of approximating matchings in multiple passes.  Here we give an algorithm that achieves a factor of 1 − e − k k k /k ! = 1 − 1 √ 2 πk + o (1 /k ) in k passes, improving upon the previously best known approximation. In the third part of the thesis we consider the concept of spectral  sparsification introduced by Spielman and Teng.  Here, we uncover a connection between spectral sparsification and spanners, i.e.  subgraphs that approximately preserve shortest path distances.  This connection allows us to obtain a quasilinear time algorithm for constructing spectral sparsifiers using approximate distance oracles and entirely bypassing linear system solvers, which was previously the only known way of constructing spectral sparsifiers in quasilinear time. Finally,  in  the  last  part  of  the  thesis  we  design  an  efficient  implementation  of  cut-preserving sparsification in a streaming setting with edge deletions using only one pass over the data.
generalized knapsack solvers for multi unit combinatorial auctions analysis and application to computational resource allocation	The problem of allocating discrete computational resources motivates interest in general multi-unit combinatorial exchanges. This paper considers the problem of computing optimal (surplus-maximizing) allocations, assuming unrestricted quasi-linear preferences. We present a solver whose pseudo-polynomial time and memory requirements are linear in three of four natural measures of problem size: number of agents, length of bids, and units of each resource. In applications where the number of resource  types  is inherently a small constant, e.g., computational resource allocation, such a solver offers advantages over more elaborate approaches developed for high-dimensional problems.   We also describe the deep connection between auction winner determination problems and generalized knapsack problems, which has received remarkably little attention in the literature. This connection leads directly to pseudo-polynomial solvers, informs solver benchmarking by exploiting extensive research on hard knapsack problems, and allows E-Commerce research to leverage a large and mature body of literature.
meta brokering solution for establishing grid interoperability	
meta brokering solutions for expanding grid middleware limitations	Grid Resource Management tools evolved from manual discovery and task submission to sophisticated brokering solutions. User requirements created certain properties that resource managers have learned to support. This development is still continuing, and users already need to stress themselves to distinguish brokers and migrate their applications when they move to a different grid. Moreover, grid interoperability have emerged the need for higher level brokering services. This paper introduces a meta-brokering approach that means a higher level resource management by enabling automatic and simultaneous utilization of Grid Brokers. First we gather the requirements of this novel middleware service then define a general meta-brokering architecture. Finally we show how meta-brokers can be implemented in different grid environments and we conclude with their evaluations.
power aware scheduling of bag of tasks applications with deadline constraints on dvs enabled clusters	Power-aware scheduling problem has been a recent issue in cluster systems not only for operational cost due to electricity cost, but also for system reliability. As recent commodity processors support multiple operating points under various supply voltage levels, Dynamic Voltage Scaling (DVS) scheduling algorithms can reduce power consumption by controlling appropriate voltage levels. In this paper, we provide power-aware scheduling algorithms for bag-of-tasks applications with deadline constraints on DVS-enabled cluster systems in order to minimize power consumption as well as to meet the deadlines specified by application users. A bag-of-tasks application should finish all the sub-tasks before the deadline, so that the DVS scheduling scheme should consider the deadline as well. We provide the DVS scheduling algorithms for both time-shared and space-shared resource sharing policies. The simulation results show that the proposed algorithms reduce much power consumption compared to static voltage schemes.
a faster fully polynomial approximation scheme for the single machine total tardiness problem	Lawler [E.L. Lawler, A fully polynomial approximation scheme for the total tardiness problem, Operations Research Letters 1 (1982) 207-208] proposed a fully polynomial approximation scheme for the single-machine total tardiness problem which runs in time (where n is the number of jobs and [epsilon] is the desired level of approximation). A faster fully polynomial approximation scheme running in time is presented in this note by applying an alternative rounding scheme in conjunction with implementing Kovalyov's [M.Y. Kovalyov, Improving the complexities of approximation algorithms for optimization problems, Operations Research Letters 17 (1995) 85-87] bound improvement procedure.
the single machine total tardiness scheduling problem review and extensions	We review the latest theoretical developments for the single-machine total tardiness scheduling problem and propose extensions to some of them. We also review (and in some cases extend) exact algorithms, fully polynomial time approximation schemes, heuristic algorithms, special cases and generalizations of the problem. Our findings indicate that the problem continues to attract significant research interest from both a theoretical and a practical perspective. Even though the problem is ordinary NP-hard, the current state-of-the-art algorithms are capable of solving problems with up to 500 jobs.
the total tardiness problem review and extensions	We provide a unified framework for the total tardiness problem by surveying the related literature in the single-machine, parallel machine, flowshop and jobshop settings. We focus on critically evaluating the heuristic algorithms; we also propose new heuristics for both the single-machine and the parallel-machine tardiness problems. Finally, we identify the areas where further research is needed and we give directions for future research.
improving the complexities of approximation algorithms for optimization problems	A procedure to improve the lower and upper bound for the optimal objective function value of a minimization problem is presented. The procedure is based on an approximation scheme. Properties of this approximation scheme are established on which the correctness and effectiveness of the bound improvement procedure are based. The procedure is applied to improve the computational complexities of approximation algorithms for several single and parallel machine scheduling problems.
a taxonomy and survey of grid resource management systems for distributed computing	The resource management system is the central component of distributed network computing systems. There have been many projects focused on network computing that have designed and implemented resource management systems with a variety of architectures and services. In this paper, an abstract model and a comprehensive taxonomy for describing resource management architectures is developed. The taxonomy is used to identify approaches followed in the implementation of existing resource management systems for very large-scale network computing systems known as Grids. The taxonomy and the survey results are used to identify architectural approaches and issues that have not been fully explored in the research. Copyright © 2001 John Wiley & Sons, Ltd.
minimizing total tardiness for single machine sequencing	We consider the single machine sequencing problem in which each job has a processing time and a due date. The objective is to find a sequence of n jobs which minimizes the sum of the tardiness of each job. We present an O(n log n) MDD (Modified Due Date) rule which satisfies local optimality and show that the MDD rule has a worst-case performance ratio of $. The MDD rule is superior to other known O(n log n) heuristics in the sense of worst-case performance.
improved multi processor scheduling for flow time and energy	Energy usage has been an important concern in recent research on online scheduling. In this paper, we study the tradeoff between flow time and energy (Albers and Fujiwara in ACM Trans. Algorithms 3(4), 2007; Bansal et al. in Proceedings of ACM-SIAM Symposium on Discrete Algorithms, pp. 805---813, 2007b, Bansal et al. in Proceedings of International Colloquium on Automata, Languages and Programming, pp. 409---420, 2008; Lam et al. in Proceedings of European Symposium on Algorithms, pp. 647---659, 2008b) in the multi-processor setting. Our main result is an enhanced analysis of a simple non-migratory online algorithm called CRR (classified round robin) on m?2 processors, showing that its flow time plus energy is within O(1) times of the optimal non-migratory offline algorithm, when the maximum allowable speed is slightly relaxed. The result still holds even if the comparison is made against the optimal migratory offline algorithm. This improves previous analysis that CRR is O(log?P)-competitive where P is the ratio of the maximum job size to the minimum job size.
A “Pseudopolynomial” Algorithm for Sequencing Jobs to Minimize Total Tardiness	Suppose n jobs are to be processed by a single machine. Associated with each job j are a fixed integer processing time pi, a due date di, and a positive weight wj. The weighted tardiness of job j in a given sequence is wj, max (O, Ci, - di), where Ci is the completion time of job j. Assume that the weighting of jobs is “agreeable”, in the sense that pi <pi implies wi ⩾wi. Under these conditions, it is shown that a sequence minimizing total weighted tardiness can be found by a dynamic programming algorithm with worst-case running time of O(n4P) or O(n5pmax), where P = Σpi and pmax = max {pi}. The algorithm cis “pseudopolynomial”, since a true polynomialbounded algorithm should be polynomial in Σ log2,pi.
a fully polynomial approximation scheme for the total tardiness problem	A fully polynomial approximation scheme is presented for the problem of sequencing jobs for processing by a single machine so as to minimize total tardiness. This result is obtained by modifying the author's pseudopolynomial algorithm for the same problem.
on scheduling problems with deferral costs	A class of scheduling problems involving deferral costs has been formulated by McNaughton, who has described a simple method of solution for the linear, single-processor case. In this report dynamic programming and linear programming techniques are applied to nonlinear and multiple-processor problems. A dynamic programming solution of the nonlinear, single processor problem is possible, provided the number of jobs is small. Transportation methods of linear programming can be used to solve large nonlinear, multiple-processor problems, provided the processing times for the jobs are equal. Approximate and/or partial solutions are possible for other cases.
algorithms for special cases of the single machine total tardiness problem and an application to the even odd partition problem	The scheduling problem of minimizing total tardiness on a single machine is known to be NP-hard in the ordinary sense. In this paper, we consider the special case of the problem when the processing times p"j and the due dates d"j of the jobs j,[email protected]?N={1,2,...,n}, are oppositely ordered: p"1>=p"2>=...>=p"n and d"[email protected]?d"[email protected][email protected]?d"n. It is shown that already this special case is NP-hard in the ordinary sense, too. The set of jobs N is partitioned into k,[email protected][email protected]?n, subsets M"1,M"2,...,M"k, M"@[email protected]?M"@[email protected]? for @n @m,N=M"[email protected]?M"[email protected][email protected]?M"k, such that max"i","j"@?"M"""@n|d"i-d"j|@?min"j"@?"M"""@np"j for each @n=1,2,...,k. We propose algorithms which solve the problem: in O([email protected]?p"j) time if [email protected]?k=p"2>=...>=p"n mentioned above nor integer processing times to construct an optimal schedule. Finally, we apply the idea of the presented algorithm for the case k=1 to the even-odd partition problem.
practical scheduling of bag of tasks applications on grids with dynamic resilience	Over the past decade, the grid has emerged as an attractive platform to tackle various large-scale problems, especially in science and engineering. One primary issue associated with the efficient and effective utilization of heterogeneous resources in a grid is scheduling. Grid scheduling involves a number of challenging issues, mainly due to the dynamic nature of the grid. There are only a handful of scheduling schemes for grid environments that realistically deal with this dynamic nature that have been proposed in the literature. In this paper, two novel scheduling algorithms, called the shared-input-data-based listing (SIL) algorithm and the multiple queues with duplication (MQD) algorithm for bag-of-tasks (BoT) applications in grid environments are proposed. The SIL algorithm targets scheduling data-intensive BoT (DBoT) applications, whereas the MQD algorithm deals with scheduling computationally intensive BoT (CBoT) applications. Their common and primary forte is that they make scheduling decisions without fully accurate performance prediction information. Another point to note is that both scheduling algorithms adopt task duplication as an attempt to reduce serious schedule increases. Our evaluation study employs a number of experiments with various simulation settings. The results show the practicability and competitiveness of our algorithms when compared to existing methods
approximating the unweighted k set cover problem greedy meets local search	In the unweighted set-cover problem we are given a set of elements E={ e1,e2, ...,en } and a collection $\cal F$ of subsets of E. The problem is to compute a sub-collection SOL⊆$\cal F$ such that $\bigcup_{S_j\in SOL}S_j=E$ and its size |SOL| is minimized. When |S|≤k for all $S\in\cal F$ we obtain the unweighted k-set cover problem. It is well known that the greedy algorithm is an Hk-approximation algorithm for the unweighted k-set cover, where $H_k=\sum_{i=1}^k {1 \over i}$ is the k-th harmonic number, and that this bound on the approximation ratio of the greedy algorithm, is tight for all constant values of k. Since the set cover problem is a fundamental problem, there is an ongoing research effort to improve this approximation ratio using modifications of the greedy algorithm. The previous best improvement of the greedy algorithm is an $\left( H_k-{1\over 2}ight)$-approximation algorithm. In this paper we present a new $\left( H_k-{196\over 390}ight)$-approximation algorithm for k ≥4 that improves the previous best approximation ratio for all values of k≥4 . Our algorithm is based on combining local search during various stages of the greedy algorithm.
scheduling task graphs onto heterogeneous multiprocessors	In a heterogeneous system, the efficient exploitation of parallelism requires scheduling strategies that account for heterogeneity among processors to achieve an effective mapping of computations to processors. The paper presents a scheduling heuristic specialized for heterogeneous multiprocessor systems which make use of several different types of processors. The new algorithm is based on the greedy strategy: no processor remains idle if there is some task available that it could process. A graph called the classified typed task graph is used to describe the current status of tasks of different types at each scheduling step. With the graph, the algorithm dynamically evaluates the priorities of tasks only when there are multiply executable candidates, and then schedules an appropriate one onto the currently available processors of the corresponding type. A preliminary evaluation shows that this algorithm has promising performance. >
investigation of the scheduler for heterogeneous distributed computing systems based on minimal cover method	The article describes the scheduling system for heterogeneous distributed computing systems. The scheduler based on minimal cover method. The analysis of the effectiveness of the scheduling system for tasks with varying intensity, the law of distribution complexity. The advantage of the method of minimal cover compared to FCFS. A system of rules for the optimization of the proposed planning changes in the intensity and complexity of tasks.
the solution algorithms for problems on the minimal vertex cover in networks and the minimal cover in boolean matrixes	The authors propose approximate algorithms for solving the problem of the minimal vertex cover of arbitrary graphs and the problem of minimal cover on the basis of their reduction, respectively, to the problems of quadratic and nonlinear Boolean programming, their specificity allowing to construct algorithms with time complexity not exceeding O (mn 2 ), where in the case of solving the problem of minimal vertex cover of arbitrary graphs n is the number of vertices in the graph, m is the number of edges in the graph, and in the case of solving the problem of minimal cover n is the number of columns in the Boolean matrix, m is the number of rows in Boolean matrix.
general approach to solving optimization problems in distributed computing systems and theory of intelligence systems construction	
high throughput resource management	
on the ratio of optimal integral and fractional covers	It is shown that the ratio of optimal integral and fractional covers of a hypergraph does not exceed 1 + log d, where d is the maximum degree. This theorem may replace probabilistic methods in certain circumstances. Several applications are shown.
hierarchies in a multidimensional model from conceptual modeling to logical representation	Hierarchies are used in data warehouses (DWs) and on-line analytical processing (OLAP) systems to see data at different levels of detail. However, many kinds of hierarchies arising in real-world situations are not addressed by current OLAP systems. Further, there is still no agreement on a conceptual model for DW and OLAP design that offers both a graphical representation and a formal definition.In this paper, we formally define the MultiDimER model, a conceptual multidimensional model that allows to represent facts with measures as well as the different kinds of hierarchies already classified in our previous work [E. Malinowski, E. Zimanyi, OLAP hierarchies: a conceptual perspective, in: Proceedings of the 16th International Conference on Advanced Information Systems Engineering, 2004, pp. 477-491]. We also present the mapping of such hierarchies to the relational model, as well as their implementation in commercial DW products.
managing energy and server resources in hosting centers	Internet hosting centers serve multiple service sites from a common hardware base. This paper presents the design and implementation of an architecture for resource management in a hosting center operating system, with an emphasis on  energy  as a driving resource management issue for large server clusters. The goals are to provision server resources for co-hosted services in a way that automatically adapts to offered load, improve the energy efficiency of server clusters by dynamically resizing the active server set, and respond to power supply disruptions or thermal events by degrading service in accordance with negotiated Service Level Agreements (SLAs).Our system is based on an economic approach to managing shared server resources, in which services "bid" for resources as a function of delivered performance. The system continuously monitors load and plans resource allotments by estimating the value of their effects on service performance. A greedy resource allocation algorithm adjusts resource prices to balance supply and demand, allocating resources to their most efficient use. A reconfigurable server switching infrastructure directs request traffic to the servers assigned to each service. Experimental results from a prototype confirm that the system adapts to offered load and resource availability, and can reduce server energy usage by 29% or more for a typical Web workload.
an algorithm for the generalized assignment problem	
 An O( V E ) algorithm for finding maximum matching in general graphs	We  define  two  generalized  types  of  a  priority  queue  by  allowing  some  forms  of  changing  the  priorities  of  the  elements  in  the  queue.  We  show  that  they  can  be  implemented  efficiently.  Consequently,  each  operation  takes  O(log  n)  time.  We  use  these  generalized  priority  queues  to  con- struct  an  O(EV  log  V)  algorithm  for  finding  a  maximal  weighted  matching  in  general  graphs
Estimation of algorithms and time complexity for cover problem	
modeling and solving the crew rostering problem	The Crew Rostering Problem (CRP) aims at determining an optimal sequencing of a given set of duties into rosters satisfying operational constraints deriving from union contract and company regulations. Previous work on CRP addresses mainly urban mass-transit systems, in which the minimum number of crews to perform the duties can easily be determined, and the objective is to evenly distribute the workload among the crews. In typical railway applications, however, the roster construction has to take into account more involved sequencing rules, and the main objective is the minimization of the number of crews needed to perform the duties. In this paper we propose a basic model for CRP, and describe a Lagrangian lower bound based on the solution of an assignment problem on a suitably defined graph. The information obtained through the lower bound computation is used to drive an effective algorithm for finding a tight approximate solution to the problem. Computational results for real-world instances from railway applications involving up to 1,000 duties are presented, showing that the proposed approach yields, within short computing time, lower and upper bound values that are typically very close. The code based on the approach we propose won the FARO competition organized by the Italian railway company, Ferrovie dello Stato SpA, in 1995.
monitoring with ganglia	Written by Ganglia designers and maintainers, this book shows you how to collect and visualize metrics from clusters, grids, and cloud infrastructures at any scale. Want to track CPU utilization from 20,000 hosts every ten seconds? Ganglia is just the tool you need, once you know how its main components work together. This hands-on book helps experienced system administrators take advantage of Ganglia 3.x. Learn how to extend the base set of metrics you collect, fetch current values, see aggregate views of metrics, and observe time-series trends in your data. Youll also examine real-world case studies of Ganglia installs that feature challenging monitoring requirements. Determine whether Ganglia is a good fit for your environment Learn how Ganglias gmond and gmetad daemons build a metric collection overlay Plan for scalability early in your Ganglia deployment, with valuable tips and advice Take data visualization to a new level with gweb, Ganglias web frontend Write plugins to extend gmonds metric-collection capability Troubleshoot issues you may encounter with a Ganglia installation Integrate Ganglia with the sFlow and Nagios monitoring systems Contributors include: Robert Alexander, Jeff Buchbinder, Frederiko Costa, Alex Dean, Dave Josephsen, Peter Phaal, and Daniel Pocock.
multi criteria grid resource management using performance prediction techniques	To date, many of existing Grid resource brokers make their decisions concerning selection of the best resources for computational jobs using basic resource parameters such as, for instance, load. This approach may often be insufficient. Estimations of job start and execution times are needed in order to make more adequate decisions and to provide better quality of service for end-users. Nevertheless, due to heterogeneity of Grids and often incomplete information available the results of performance prediction methods may be very inaccurate. Therefore, estimations of prediction errors should be also taken into consideration during a resource selection phase. We present in this paper the multi-criteria resource selection method based on estimations of job start and execution times, and prediction errors. To this end, we use GRMS [28] and GPRES tools. Tests have been conducted based on workload traces which were recorded from a parallel machine at UPC. These traces cover 3 years of job information as recorded by the LoadLeveler batch management systems. We show that the presented method can considerably improve the efficiency of resource selection decisions.
QoS Sufferage Heuristic for Independent Task Scheduling in Grid	"Grid" computing has emerged as an important new field, distinguished from conventional distributed computing by its focus on large-scale resource sharing, innovative applications, and, in some cases, high performance orientation. In this article, the authors define this new field. First, they review the "Grid problem," which is defined as flexible, secure, coordinated resource sharing among dynamic collections of individuals, institutions, and resources--what is referred to as virtual organizations. In such settings, unique authentication, authorization, resource access, resource discovery, and other challenges are encountered. It is this class of problem that is addressed by Grid technologies. Next, the authors present an extensible and open Grid architecture, in which protocols, services, application programming interfaces, and software development kits are categorized according to their roles in enabling resource sharing. The authors describe requirements that they believe any such mechanisms must satisfy and discuss the importance of defining a compact set of intergrid protocols to enable interoperability among different Grid systems. Finally, the authors discuss how Grid technologies relate to other contemporary technologies, including enterprise integration, application service provider, storage service provider, and peer-to-peer computing. They maintain that Grid concepts and technologies complement and have much to contribute to these other approaches.
new grid scheduling and rescheduling methods in the grads project	The goal of the Grid Application Development Software (GrADS) Project is to provide programming tools and an execution environment to ease program development for the Grid. This paper presents recent extensions to the GrADS software framework: a new approach to scheduling workflow computations, applied to a 3-D image reconstruction application; a simple stop/migrate/restart approach to rescheduling Grid applications, applied to a QR factorization benchmark; and a process-swapping approach to rescheduling, applied to an N-body simulation. Experiments validating these methods were carried out on both the GrADS MacroGrid (a small but functional Grid) and the MicroGrid (a controlled emulation of the Grid).
a rescheduling heuristic for the single machine total tardiness problem	In this paper, we propose a rescheduling heuristic for scheduling N jobs on a single machine in order to minimise total tardiness. The heuristic is of the interchange type and constructs a schedule from the modified due date (MDD) schedule. Unlike most interchange heuristics that consider interchanges involving only two jobs at a time, the newly proposed heuristic uses interchanges that may involve more than two jobs at any one time. Experimental results show that the heuristic is effective at reducing total tardiness producing schedules that either similar or better than those produced by the MDD alone. Furthermore, when applied to some test problems the heuristic found optimal schedules to all of them.
on decomposition of the total tardiness problem	As an improvement of the famous Lawler Decomposition Theorem for the one-machine total tardiness problem, some conditions on decomposition positions are obtained by Potts and Wassenhove, and are used by them to make the decomposition algorithm more efficient. In this paper, more conditions on the leftmost decomposition position are proved. Additional computational tests are described.
optimal power allocation in server farms	Server farms today consume more than 1.5% of the total electricity in the U.S. at a cost of nearly $4.5 billion. Given the rising cost of energy, many industries are now seeking solutions for how to best make use of their available power. An important question which arises in this context is how to distribute available power among servers in a server farm so as to get maximum performance.   By giving more power to a server, one can get higher server frequency (speed). Hence it is commonly believed that, for a given power budget, performance can be maximized by operating servers at their highest power levels. However, it is also conceivable that one might prefer to run servers at their lowest power levels, which allows more servers to be turned on for a given power budget. To fully understand the effect of power allocation on performance in a server farm with a fixed power budget, we introduce a queueing theoretic model, which allows us to predict the optimal power allocation in a variety of scenarios. Results are verified via extensive experiments on an IBM BladeCenter.   We find that the optimal power allocation varies for different scenarios. In particular, it is not always optimal to run servers at their maximum power levels. There are scenarios where it might be optimal to run servers at their lowest power levels or at some intermediate power levels. Our analysis shows that the optimal power allocation is non-obvious and depends on many factors such as the power-to-frequency relationship in the processors, the arrival rate of jobs, the maximum server frequency, the lowest attainable server frequency and the server farm configuration. Furthermore, our theoretical model allows us to explore more general settings than we can implement, including arbitrarily large server farms and different power-to-frequency curves. Importantly, we show that the optimal power allocation can significantly improve server farm performance, by a factor of typically 1.4 and as much as a factor of 5 in some cases.
dma aware memory energy management	As increasingly larger memories are used to bridge the widening gap between processor and disk speeds, main memory energy consumption is becoming increasingly dominant. Even though much prior research has been conducted on memory energy management, no study has focused on data servers, where main memory is predominantly accessed by DMAs instead of processors. In this paper, we study DMA-aware techniques for memory energy management in data servers. We first characterize the effect of DMA accesses on memory energy and show that, due to the mismatch between memory and I/O bus band-widths, significant energy is wasted when memory is idle but still active during DMA transfers. To reduce this waste, we propose two novel performance-directed energy management techniques that maximize the utilization of memory devices by increasing the level of concurrency between multiple DMA transfers from different I/O buses to the same memory device. We evaluate our techniques using a detailed trace-driven simulator, and storage and database server traces. The results show that our techniques can effectively minimize the amount of idle energy waste during DMA transfers and, consequently, conserve up to 38.6% more memory energy than previous approaches while providing similar performance.
parallel query processing for olap in grids	OLAP query processing is critical for enterprise grids. Capitalizing on our experience with the ParGRES database cluster, we propose a middleware solution, GParGRES, which exploits database replication and inter- and intra-query parallelism to efficiently support OLAP queries in a grid. GParGRES is designed as a wrapper that enables the use of ParGRES in PC clusters of a grid (in our case, Grid5000). Our approach has two levels of query splitting: grid-level splitting, implemented by GParGRES, and node-level splitting, implemented by ParGRES. GParGRES has been partially implemented as database grid services compatible with existing grid solutions such as the open grid service architecture and the Web services resource framework. We give preliminary experimental results obtained with two clusters of Grid5000 using queries of the TPC-H Benchmark. The results show linear or almost linear speedup in query execution, as more nodes are added in all tested configurations. Copyright © 2008 John Wiley & Sons, Ltd.
pargres a middleware for executing olap queries in parallel	
performance comparison of priority rule scheduling algorithms using different inter arrival time jobs in grid environment	Recent advancement in meta-heuristics grid scheduling studies have applied various techniques such as Particle Swarm Optimization (PSO), Genetic Algorithm (GA) and Ant Colony Optimization (ACO) to solve the grid scheduling problem. All of these technique requires an initial scheduler in order to initiate the scheduling process and the priority rule algorithms will typically be used. However, from the literature, none of these studies elaborate and justify their selection of a particular priority rule algorithms over another. Since the initial scheduler can significantly affect the entire scheduling process, it is important that the correct initial scheduler be selected. In this paper we quantitatively compared six initial scheduler algorithms to determine the best algorithm performance. We believe the performance comparison would enable users to utilize the best initial scheduler to fit their meta-heuristics grid scheduling studies.
performance comparison of three batch mode scheduling heuristics	Grid scheduling issue has been an exploration hotspot lately. Some custom heuristics have been utilized to upgrade it and have got some great results. In any case, selecting the best heuristic to use in a given domain remains a troublesome issue. So to beat this, a few examinations have been made in this paper which will give the data that which heuristic will gives better Makespan, Flowtime and Average completion time value. So in this paper, three heuristics i.e., Min-Min, Max-Min & LJFR-SJFR are chosen, compared, analyzed and executed by using Gridsim 5.2. General Terms Scheduling Heuristics.
the time dependent traveling salesman problem and its application to the tardiness problem in one machine scheduling	The time-dependent traveling salesman problem may be stated as a scheduling problem in which n jobs have to be processed at minimum cost on a single machine. The set-up cost associated with each job depends not only on the job that precedes it, but also on its position time in the sequence. The optimization method described here combines finding shortest paths in an associated multipartite network with subgradient optimization and some branch-and-bound enumeration. Minimizing the tardiness costs in one-machine scheduling in which the cost is a non-decreasing function of the completion time of each job is then attacked by this method. A branch-and-bound algorithm is designed for this problem. It uses a related time-dependent traveling salesman problem to compute the required lower bounds. We give computational results for the weighted tardiness problem.
APPLICATION OF COMBINATIONAL PROGRAMMING TO A CLASS OF ALL-ZERO-ONE INTEGER PROGRAMMING PROBLEMS.	Problem-solving procedures based on the methods of combinatorial programming are presented for solving a class of integer programming problems in which all elements are zero or one. All of the procedures seek first a feasible solution and then successively better and better feasible solutions until ultimately one is discovered which is shown to be optimal. By representing the problem elements in a binary computer as bits in a word and employing logical "and" and "or" operations in the problemsolving process, a number of problems involving several hundred integer variables have been solved in a matter of seconds.
improving processor allocation in heterogeneous computing grid through considering both speed heterogeneity and resource fragmentation	In a heterogeneous grid environment, there are two major factors which would severely affect overall system performance: speed heterogeneity and resource fragmentation. Moreover, the relative effect of these two factors changes with different workload and resource conditions. Processor allocation methods have to deal with this issue. However, most existing allocation methods focus on one of these two factors. This paper first analyzes the relative strength of different existing methods. Based on the analysis, we propose an intelligent processor allocation method which considers both the speed heterogeneity and resource fragmentation effects. Extensive simulation studies have been conducted to show that the proposed method can effectively deliver better performance under most resource and workload conditions.
A decomposition algorithm for the single machine total tardiness problem	The problem of sequencing jobs on a single machine to minimize total tardiness is considered. An algorithm, which decomposes the problem into subproblems which are then solved by dynamic programming when they are sufficiently small, is presented and is tested on problems with up to 100 jobs.
dynamic programming and decomposition approaches for the single machine total tardiness problem	Abstract   The problem of sequencing jobs on a single machine to minimize total tardiness is considered. General precedence constrained dynamic programming algorithms and special-purpose decomposition algorithms are presented. Computational results for problems with up to 100 jobs are given.
single machine tardiness sequencing heuristics	Abstract This paper presents a collection of heuristics for the single machine total (weighted) tardiness problem. The methods considered range from simple quick and dirty heuristics to more sophisticated algorithms exploiting problem structure. These heuristics are compared to interchange and simulated annealing methods on a large set of test problems. For the total tardiness problem a heuristic based on decomposition performs very well, whereas for the total weighted tardiness problem simulated annealing appears to be a viable approach. Our computational results also indicate that straightforward interchange methods perform remarkably well.
modeling and supporting grid scheduling	Grid resource management systems and schedulers are important components for building Grids. They are responsible for the selection and allocation of Grid resources to current and future applications. Thus, they are important building blocks for making Grids available to user communities. In this paper we briefly analyze the requirements of Grid resource management and provide a classification of schedulers. Then, we define an extensible formal model for Grid scheduling activities, and characterize the general Grid scheduling problem. Finally, we provide a reference architecture for the support of our model and discuss different aspects of architectural implementations.
maximum matchings in general graphs through randomization	A new randomized algorithm for the maximum matching problem is presented. Unlike conventional matching algorithms which are combinatorial, our algorithm is algebraic and works on the Tutte matrix of the given graph. Although slower than the best known matching algorithm, our algorithm We present a new randomized algorithm for the maximum matching problem. Unlike conventional matching algorithms which are based on the combinatorial approach of finding "augmenting paths" and "blossoms" in graphs (see (Edl) for definitions), our algorithm is algebraic and works on the Tutte matrix of the given graph. Edmonds (Edl) gave the first polynomial time algorithm (O(n4)) for this problem by giving an ingenious way of dealing with the complex manner in which blossoms get nested. Subsequently more efficient algorithms were obtained. The current best running time is O(m
a note on the weighted tardiness problem	We identify a condition characterizing adjacent jobs in an optimal sequence for the weighted tardiness problem. This condition can be used as an effective pruning device in enumerative methods. Further, we show that the Modified Due Date Rule is a special case of this condition. Lastly, we identify a set of circumstances under which the first job in an optimal sequence can be determined without fully solving the problem.
a new heuristic approach for the large scale generalized assignment problem	
a framework for qos based resource brokering in grid computing	Effective and efficient exploitation of Grid computing facilities requires advanced resource management systems to automatically and transparently ensure the fulfillment not only of functional requirements but also of non-functional ones. This paper presents a framework for brokering of Grid resources, virtualized through Web Services, which can be dynamically configured with respect to multiple syntactic and semantic description languages and related matching strategies. Hence, it discovers and selects resources and automatically allocates application tasks to them on the basis of both functional and quality of service (QoS) requirements. In particular, the paper presents a framework specialization which aims to select a pool of resources whose overall performance allows for satisfying time and cost constraints for the execution of an application partitioned in concurrent tasks according to the data parallelism pattern.
resource allocation on computational grids using a utility model and the knapsack problem	This work introduces a utility model (UM) for resource allocation on computational grids and formulates the allocation problem as a variant of the 0-1 multichoice multidimensional knapsack problem. The notion of task-option utility is introduced, and it is used to effect allocation policies. We present a variety of allocation policies, which are expressed as functions of metrics that are both intrinsic and external to the task and resources. An external user-defined credit-value metric is shown to allow users to intervene in the allocation of urgent or low priority tasks. The strategies are evaluated in simulation against random workloads as well as those drawn from real systems. We measure the sensitivity of the UM-derived schedules to variations in the allocation policies and their corresponding utility functions. The UM allocation strategy is shown to optimally allocate resources congruent with the chosen policies.
r gma an information integration system for grid monitoring	Computational Grids are distributed systems that provide access to computational resources in a transparent fashion. Collecting and providing information about the status of the Grid itself is called Grid monitoring.
minimizing total costs in one machine scheduling	Suppose we have n jobs that arrive simultaneously to be processed on a continuously available machine that can handle only one job at a time. Each job has a fixed processing time and a cost function that is nondecreasing in its finishing time. We want to find a schedule that minimizes total costs. After reviewing the relevant work on this problem, we present a new algorithm for a general cost function. The algorithm is tested for the well known case of a weighted tardiness criterion.
mathematical modelling and optimization of flexible job shops scheduling problem	The flexible job shop scheduling problem (F-JSSP) is mathematically formulated. One novel position-based and three sequence-based mixed integer linear programming models are developed. Since F-JSSPs are strongly NP-hard, MILPs fail to solve large-size instances within a reasonable timeframe. Thus, a meta-heuristic, a hybrid of artificial immune and simulated annealing (AISA), is developed for use with larger instances of the F-JSSP. To prove the efficiency of developed MILPs and AISA, they are compared against state-of-the-art MILPs and meta-heuristics in literature. Comparative evaluations are conducted to test the quality and performance of the developed models and solution technique respectively. To this end, size complexities of the developed MILPs are investigated. The acquired results demonstrate that the proposed MILPs outperform the state-of-the-art MILP models in literature. Likewise, the proposed AISA outperforms all the previously developed meta-heuristics. The developed AISA has successfully been applied to a realistic case study from mould and die industry.
taxonomy of dynamic task scheduling schemes in distributed computing systems	System state estimation and decision making are the two major components of dynamic task scheduling in a distributed computing system. Combinations of solutions to each individual component constitute solutions to the dynamic task scheduling problem. It is important to consider a solution to the state estimation problem separate from a solution to the decision making problem to understand the similarities and differences between different solutions to dynamic task scheduling. Also, a solution to the state estimation problem has a significant impact on the scalability of a task scheduling solution in large scale distributed systems. The author presents a taxonomy of dynamic task scheduling schemes that is synthesised by treating state estimation and decision making as orthogonal problems. Solutions to estimation and decision making are analysed in detail and the resulting solution space of dynamic task scheduling is clearly shown. The proposed taxonomy is regular, easily understood, compact, and its wide applicability is demonstrated by means of examples that encompass solutions proposed in the literature. The taxonomy illustrates possible solutions that have not been evaluated and those solutions that may have potential in future research. >
	
	
a hyper heuristic approach for efficient resource scheduling in grid	Efficient execution of computations in grid can require mapping of tasks to processors whose performance is both irregular and time varying because of dynamic nature. The task of mapping jobs to the available computing nodes or scheduling of the jobs on the grid is a NP complete problem. The NP-hard problem is often solved using heuristics techniques. Heuristic and metaheuristic approaches tend to be knowledge rich, requiring substantial expertise in both the problem domain and appropriate heuristics techniques. To alleviate this problem the concept of Hyperheuristic was introduced. They operate on the search space of heuristics instead of candidate solutions and can be applied to any optimization problem. This paper emphasizes the use of Hyper-heuristics built on top of hybridized Metaheuristics to efficiently and effectively schedule jobs onto available resources in a grid environment thus resulting in an optimal schedule with minimum makespan.
many objective comparison of twelve grid scheduling heuristics	
	
dynamic programming solution of sequencing problems with precedence constraints	Consider a set of tasks that are partially ordered by precedence constraints. A subset of tasks is called feasible if, for every task in the subset, all predecessors are also in the subset. The major results are 1 a method for enumerating all feasible subsets and 2 a method for assigning to each feasible subset an easily computed label that can be used as a physical address for storing information about the subset. These two results permit a very compact computer implementation of a dynamic programming algorithm for solving one-machine sequencing problems with precedence constraints. This algorithm appears to be much more efficient than previous ones for certain one-machine sequencing problems.
resource management for future generation grids	This paper discusses the requirements for and functionalities of resource management systems for future generation Grids. To this end it is also necessary to review the actual scope of future Grids. Here we examine differences and similarities of current Grid systems and distinguish several Grid scenarios to highlight the different understandings of the term Grid which exist today. While we expect that a generic Grid infrastructure cannot suite all application scenarios, it would certainly be beneficial to many of them to share such an infrastructure. Instead of identifying a minimal subset of necessary Grid middleware functionalities, we postulate that Grids need a resource management system both well-designed and rich in features to be usable for a large variety of applications. This includes for example extended functionalities for information and negotiation services which can be used by automatic scheduling and brokering solutions.
on the single machine scheduling problem with tardiness penalties	The n-job, single-machine total tardiness problem is considered in this paper. A branching algorithm based on three theorems is proposed to generate a reduced set of candidate sequences. The computational results indicate that the proposed algorithm provides a smaller set of candidate sequences than the DP algorithm of Schrage and Baker.
static scheduling research to minimize weighted and unweighted tardiness a state of the art survey	Abstract   This paper reviews research on the total tardiness (TT) and total weighted tardiness (TWT) problems. Heuristic methods and optimizing techniques are surveyed for both types of problems in the single-machine environment. Complexity theory related to these problems is also discussed. Some extensions of the TT and TWT problems are given for multi-machine environments.
	
	
simulation based performance prediction for large parallel machines	We present a performance prediction environment for large scale computers such as the Blue Gene machine. It consists of a parallel simulator, BigSim, for predicting performance of machines with a very large number of processors, and BigNetSim, which incorporates a pluggable module of a detailed contention-based network model. The simulators provide the ability to make performance predictions for very large machines such as Blue Gene/L. We illustrate the utility of our simulators using validation and prediction studies of several applications using smaller numbers of processors for simulations.
dispatcher based dynamic load balancing on web server system	The traffic increasing in the network creates bulk congestion while the bulk transfer of data evolves. Performance evaluation and high availability of servers are important factors to resolve this problem using various cluster based systems. There are several low-cost servers using the load sharing cluster system which are connected to high speed networks, and apply load balancing technique between servers. It offers high computing power and high availability. A distributed website server can provide scalability and flexibility to manage with emergent client demands. Efficiency of a replicated web server system will depend on the way of distributed incoming requests among these replicas. A distributed Web-server architectures schedule client requests among the multiple server nodes in a user-transparent way that affects the scalability and availability. The aim of this paper is the development of a load balancing techniques on distributed Web-server systems.
a survey on qos based task scheduling approach in grid computing	Science and engineering are the fields which deal with the complex computational problems. So, dealing with these problems requires a very robust platform and Grid Computing provides the required functionality. Geographically distributed heterogeneous resources define the Grid computing scenario. The major problem which arises in the area of Grid Computing is the task scheduling which tends to select the best resource for a given job. There are many scheduling heuristics (online and batch mode) are available but they are not able to achieve the maximum objectives. So, Quality of Service (QoS) based approach is required to achieve the maximum objectives. The QoS based approach keeps into account the QoS based characteristics for both the tasks and the resources. In this paper we study the different heuristics techniques for resource selection in Grid Computing and also we go through the need and significance of this QoS based approach in Grid Computing.
	
a tight analysis of the greedy algorithm for set cover	We establish significantly improved bounds on the performance of the greedy algorithm for approximatingset cover. In particular, we provide the first substantial improvement of the 20-year-old classical harmonic upper bound,H(m), of Johnson, Lovasz, and Chvatal, by showing that the performance ratio of the greedy algorithm is, in fact,exactlylnm?lnlnm+?(1), wheremis the size of the ground set. The difference between the upper and lower bounds turns out to be less than 1.1. This provides the first tight analysis of the greedy algorithm, as well as the first upper bound that lies belowH(m) by a function going to infinity withm. We also show that the approximation guarantee for the greedy algorithm is better than the guarantee recently established by Srinivasan for the randomized rounding technique, thus improving the bounds on theintegrality gap. Our improvements result from a new approach which might be generally useful for attacking other similar problems.
improved performance of the greedy algorithm for partial cover	We prove that the classical bounds on the performance of the greedy algorithm for approximating MINIMUM COVER with costs are valid for PARTIAL COVER as well, thus lowering, by more than a factor of two, the previously known estimate. In order to do so, we introduce a new simple technique that might be useful for attacking other similar problems.
	
a hybrid algorithm for the one machine sequencing problem to minimize total tardiness	Abstract : In a recent paper, Hamilton Emmons has established theorems relating to the order in which pairs of jobs are to be processed in an optimal schedule to minimize the total tardiness of performing jobs on one machine. Using these theorems, the algorithm of this paper determines the precedence relationships among pairs of jobs (whenever possible) and eliminates the first and the last few jobs in an optimal sequence. The remaining jobs are then ordered by incorporating the precedence relationships in a dynamic programming framework. Propositions are proved which considerably reduce the total computation involved in the dynamic programming phase. Computational results indicate that the solution time goes up only linearly with the size (n) of the problem. The median solution time for solving 50 job problems was 0.36 seconds on UNIVAC 1108 computer. (Author)
resource management in grid computing a review	As technology advances and the popularity and dependence on internet increases by the day, new ways of finding faster and cheaper solutions to computational problems are sought. This has lead to the development of a new concept known as grid computing, which is a type of distributed computing, heterogeneous in nature because it makes an aggregated use of resources distributed over a large geographical area to solve problems usually complex ones on a larger scale. Since it involves using resources from different places, from different ownerships and with different individual qualities, it requires a complex resource management process for its proper functioning. This article provides a brief overview on grid computing and its resource management processes, important factors considered in resource management, comparison of different resource management processes and future outlook of grid computing and its resource management.
decomposition of the single machine total tardiness problem	The paper deals with the single machine total tardiness problem. It develops a new decomposition rule and presents a special and very fast branch and bound algorithm based on pure decomposition. This algorithm is tested on 2400 problems whose sizes vary from 100 to 150 jobs.
weighted tardiness single machine scheduling with proportional weights	This paper considers Arkin and Roundy's single machine weighted tardiness scheduling model with tardiness penalties proportional to the processing times. It presents a two-stage decomposition mechanism that proves to be powerful in solving the problem completely or reducing it to a much smaller problem. Three types of orderings of adjacent jobs are derived that play a crucial role in problem decomposition. The decomposition method solves 155 out of 320 test problems with job sizes ranging from 20 to 150. It reduces 163 unsolved problems to smaller subproblems with sizes not exceeding 25 jobs. The job sizes of the remaining two unsolved subproblems are 30 and 45.
new insights on the single machine total tardiness problem	Virtually all algorithmic studies on the single machine total tardiness problem use Emmons’ theorems that establish precedence relations between job pairs. In this paper, we investigate these theorems with a geometric viewpoint. This approach provides a compact way of representing Emmons’ theorems and promotes better insights into dominance properties. We use these insights to differentiate between certain classes of easy and hard instances.
task execution time modeling for heterogeneous computing systems	A distributed heterogeneous computing (HC) system consists of diversely capable machines harnessed together to execute a set of tasks that vary in their computational requirements. Heuristics are needed to map (match and schedule) tasks onto machines in an HC system so as to optimize some figure of merit. This paper characterizes a simulated HC environment by using the expected execution times of the tasks that arrive in the system onto the different machines present in the system. This information is arranged in an "expected time to compute" (ETC) matrix as a model of the given HC system, where the entry (i, j) is the expected execution time of task i on machine j. This model is needed to simulate different HC environments to allow testing of relative performance of different mapping heuristics under different circumstances. In particular the ETC model is used to express the heterogeneity among the runtimes of the tasks to be executed, and among the machines in the HC system. An existing range-based technique to generate ETC matrices is described. A coefficient-of-variation based technique to generate ETC matrices is proposed, and compared with the range-based technique. The coefficient-of-variation-based ETC generation method provides a greater control over the spread of values (i.e., heterogeneity) in any given row or column of the ETC matrix than the range-based method.
the grid 2 blueprint for a new computing infrastructure	
the grid blueprint for a new computing infrastructure	Preface Foreword 1. Grids in Context 2. Computational Grids I Applications 3 Distributed Supercomputing Applications 4 Real-Time Widely Distributed Instrumentation Systems 5 Data-Intensive Computing 6 Teleimmersion II Programming Tools 7 Application-Specific Tools 8 Compilers, Languages, and Libraries 9 Object-Based Approaches 10 High-Performance Commodity Computing III Services 11 The Globus Toolkit 12 High-Performance Schedulers 13 High-Throughput Resource Management 14 Instrumentation and Measurement 15 Performance Analysis and Visualization 16 Security, Accounting, and Assurance IV Infrastructure 17 Computing Platforms 18 Network Protocols 19 Network Quality of Service 20 Operating Systems and Network Interfaces 21 Network Infrastructure 22 Testbed Bridges from Research to Infrastructure Glossary Bibliography Contributor Biographies
towards quality of service support for grid workflows	Service-oriented workflow languages are being considered as a key programming paradigm for composing Grid applications from basic services. In this paper we present QoS support for grid workflows addressing the special requirements of time-critical Grid applications, as for example medical simulation services. QoS support for grid workflow is currently being developed in the context of the Vienna Grid Environment, a service-oriented Grid infrastructure for the provision of parallel simulation codes as QoS-aware Grid services, which are capable of dynamically negotiating with clients various QoS guarantees, e.g. with respect to execution time and price. We use a real world Grid service for medical image reconstruction to describe the main features of our approach and present the first prototype of a QoS-aware workflow engine which supports dynamic QoS negotiation and QoS-aware workflow execution.
np complete scheduling problems	We show that the problem of finding an optimal schedule for a set of jobs is NP-complete even in the following two restricted cases.o(1)All jobs require one time unit. (2)All jobs require one or two time units, and there are only two processor resolving (in the negative a conjecture of R. L. Graham, Proc. SJCC, 1972, pp. 205-218). As a consequence, the general preemptive scheduling problem is also NP-complete. These results are tantamount to showing that the scheduling problems mentioned are intractable.
resource allocation and scheduling strategies using utility and the knapsack problem on computational grids	Computational grids are distributed systems composed of heterogeneous computing resources which are distributed geographically and administratively. These highly scalable systems are designed to meet the large computational demands of many users from scientific and business orientations. This dissertation address problems related to the allocation of the computing resources which compose a grid.   First, the design of a pan-Canadian grid is presented. The design exploits the maturing stability of grid deployment toolkits, and introduces novel services for efficiently allocating the grids resources. The challenges faced by this grid deployment motivate further exploration in optimizing grid resource allocations.   The primary contribution of this dissertation is one such technique for allocating grid resources. By applying a utility model to the grid allocation options, it is possible to quantify the relative merits of the various possible scheduling decisions. Indeed, a number of utility heuristics are derived to provide quality-of-service policies on the grid; these implement scheduling policies which favour efficiency and also allow users to intervene with urgent tasks. Using this model, the allocation problem is then formulated as a knapsack problem. Formulation in this manner allows for rapid solution times and results in nearly optimal allocations.   The combined utility/knapsack approach to grid resource allocation is first presented in the allocation of single resource type, processors. By evaluating the approach with novel utility heuristics using both random and real workloads, it is shown to result in efficient schedules which have characteristics that match the intended policies. Additionally, two design and analysis techniques are performed to optimize the design of the utility/knapsack scheduler; these techniques play a significant role in practical adoption of the approach.   Next, the utility/knapsack approach is extended to the allocation of multiple resource types. This extension generalizes the grid allocation solution a wider variety of resources, including processors, disk storage, and network bandwidth. The general technique, when combined with new heuristics for the varied resource types, is shown to result in improved performance against reference strategies.   This dissertation concludes with a novel application of the utility/knapsack approach to fault-tolerant task scheduling. Computational grids typically feature many techniques for providing fault tolerance to the grid tasks, including retrying failed tasks or replicating running tasks. By applying the utility/knapsack approach, the relative merits of these varied techniques can be quantified, and the overall number of failures can be decreased subject to resource cost considerations.
a grid service broker for scheduling e science applications on global data grids	The next generation of scientific experiments and studies, popularly called e-Science, is carried out by large collaborations of researchers distributed around the world engaged in the analysis of huge collections of data generated by scientific instruments. Grid computing has emerged as an enabler for e-Science as it permits the creation of virtual organizations that bring together communities with common objectives. Within a community, data collections are stored or replicated on distributed resources to enhance storage capability or the efficiency of access. In such an environment, scientists need to have the ability to carry out their studies by transparently accessing distributed data and computational resources. In this paper, we propose and develop a Grid broker that mediates access to distributed resources by: (a) discovering suitable data and computational resources sources for a given analysis scenario; (b) optimally mapping analysis jobs to resources; (c) deploying and monitoring job execution on selected resources; (d) accessing data from local or remote data sources during job execution; and (e) collating and presenting results. The broker supports a declarative and dynamic parametric programming model for creating Grid applications. We have used this model in Grid-enabling a high-energy physics analysis application (the Belle Analysis Software Framework). The broker has been used in deploying Belle experimental data analysis jobs on a Grid testbed, called the Belle Analysis Data Grid, having resources distributed across Australia interconnected through GrangeNet. Copyright © 2005 John Wiley & Sons, Ltd.
web server qos models applying scheduling rules from production planning	Most web servers, in practical use, use a queuing policy based on the Best Effort model, which employs the first-in-first-out (FIFO) scheduling rule to prioritize web requests in a single queue. This model does not provide Quality of Service (QoS). In the Differentiated Services (DiffServ) model, separate queues are introduced to differentiate QoS for separate web requests with different priorities. This paper presents web server QoS models that use a single queue, along with scheduling rules from production planning in the manufacturing domain, to differentiate QoS for classes of web service requests with different priorities. These scheduling rules are Weighted Shortest Processing Time (WSPT), Apparent Tardiness Cost (ATC), and Earliest Due Date. We conduct simulation experiments and compare the QoS performance of these scheduling rules with the FIFO scheme used in the basic Best Effort model with only one queue, and the basic DiffServ model with two separate queues. Simulation results demonstrate better QoS performance using WSPT and ATC, especially when requested services exceed the capacity of a web server.
an algorithm for large scale 0 1 integer programming with application to airline crew scheduling	We present an approximation algorithm for solving large 0–1 integer programming problems whereA is 0–1 and whereb is integer. The method can be viewed as a dual coordinate search for solving the LP-relaxation, reformulated as an unconstrained nonlinear problem, and an approximation scheme working together with this method. The approximation scheme works by adjusting the costs as little as possible so that the new problem has an integer solution. The degree of approximation is determined by a parameter, and for different levels of approximation the resulting algorithm can be interpreted in terms of linear programming, dynamic programming, and as a greedy algorithm. The algorithm is used in the CARMEN system for airline crew scheduling used by several major airlines, and we show that the algorithm performs well for large set covering problems, in comparison to the CPLEX system, in terms of both time and quality. We also present results on some well known difficult set covering problems that have appeared in the literature.
	
batch mode scheduling in grid systems	Despite recent advances, grid and P2P systems remain difficult for many users to bring to real-world applications. One difficulty is the lack of schedulers for such systems. In this work, we consider the allocations of jobs to resources using batch mode methods. These methods are able to provide fast planning by exploring characteristics of distributed and highly heterogeneous systems. In evaluating these methods, four parameters of the system are measured: makespan, flowtime, resource utilisation and matching proximity. These methods were tested using the benchmark model of Braun et al. (2001) for distributed heterogeneous systems. Based on the computational results, we evaluate the performance of these methods with regard to the four considered metrics. Also, we evaluate the usefulness of batch methods when grid characteristics, such as degree of consistency of computing and heterogeneity of jobs and resources, are known in advance. We observe that batch mode methods are beneficial to grid scheduling services, for adaptively providing these services according to the grid infrastructure characteristics.
computational models and heuristic methods for grid scheduling problems	In this paper we survey computational models for Grid scheduling problems and their resolution using heuristic and meta-heuristic approaches. Scheduling problems are at the heart of any Grid-like computational system. Different types of scheduling based on different criteria, such as static versus dynamic environment, multi-objectivity, adaptivity, etc., are identified. Then, heuristic and meta-heuristic methods for scheduling in Grids are presented. The paper reveals the complexity of the scheduling problem in Computational Grids when compared to scheduling in classical parallel and distributed systems and shows the usefulness of heuristic and meta-heuristic approaches for the design of efficient Grid schedulers. We also discuss on requirements for a modular Grid scheduling and its integration with Grid architecture.
meta heuristics for grid scheduling problems	In this chapter, we review a few important concepts from Grid computing related to scheduling problems and their resolution using heuristic and meta-heuristic approaches. Scheduling problems are at the heart of any Grid-like computational system. Different types of scheduling based on different criteria, such as static vs. dynamic environment, multi-objectivity, adaptivity, etc., are identified. Then, heuristics and meta-heuristics methods for scheduling in Grids are presented. The chapter reveals the complexity of the scheduling problem in Computational Grids when compared to scheduling in classical parallel and distributed systems and shows the usefulness of heuristics and meta-heuristics approaches for the design of efficient Grid schedulers.
	
a scheduling model for reduced cpu energy	The energy usage of computer systems is becoming an important consideration, especially for battery-operated systems. Various methods for reducing energy consumption have been investigated, both at the circuit level and at the operating systems level. In this paper, we propose a simple model of job scheduling aimed at capturing some key aspects of energy minimization. In this model, each job is to be executed between its arrival time and deadline by a single processor with variable speed, under the assumption that energy usage per unit time, P, is a convex function, of the processor speed s. We give an off-line algorithm that computes, for any set of jobs, a minimum-energy schedule. We then consider some on-line algorithms and their competitive performance for the power function P(s)=s/sup p/ where p/spl ges/2. It is shown that one natural heuristic, called the Average Rate heuristic, uses at most a constant times the minimum energy required. The analysis involves bounding the largest eigenvalue in matrices of a special type.
a taxonomy of market based resource management systems for utility driven cluster computing	In utility-driven cluster computing, cluster Resource Management Systems (RMSs) need to know the specific needs of different users in order to allocate resources according to their needs. This in turn is vital to achieve service-oriented Grid computing that harnesses resources distributed worldwide based on users' objectives. Recently, numerous market-based RMSs have been proposed to make use of real-world market concepts and behavior to assign resources to users for various computing platforms. The aim of this paper is to develop a taxonomy that characterizes and classifies how market-based RMSs can support utility-driven cluster computing in practice. The taxonomy is then mapped to existing market-based RMSs designed for both cluster and other computing platforms to survey current research developments and identify outstanding issues. Copyright © 2006 John Wiley & Sons, Ltd.
greedy set cover algorithms	
qos based scheduling of workflows on global grids	Grid computing has emerged as a global cyber-infrastructure for the next-generation of e-Science applications by integrating large-scale, distributed and heterogeneous resources. Scientific communities are utilizing Grids to share, manage and process large data sets. In order to support complex scientific experiments, distributed resources such as computational devices, data, applications, and scientific instruments need to be orchestrated while managing the application workflow operations within Grid environments. This thesis investigates properties of Grid workflow management systems, presents a workflow engine and algorithms for mapping scientific workflow applications to Grid resources based on specified QoS (Quality of Service) constraints. To address the field of Grid computing of workflow application scheduling, the thesis has made the following contributions: • proposed a taxonomy of workflow management systems for Grid computing. • developed a workflow engine which leverages tuple spaces to provide event-based execution management. • developed deadline and budget distribution strategies based on the workload and dependency of tasks. • developed algorithms for scheduling workflows with QoS constraints using genetic algorithms. • leveraged multi-objective evolutionary algorithms (MOEAs) for workflow execution planning to generate a set of trade-off alternative scheduling solutions.
workflow scheduling algorithms for grid computing	Workflow scheduling is one of the key issues in the management of workflow execution. Scheduling is a process that maps and manages execution of inter-dependent tasks on distributed resources. It introduces allocating suitable resources to workflow tasks so that the execution can be completed to satisfy objective functions specified by users. Proper scheduling can have significant impact on the performance of the system. In this chapter, we investigate existing workflow scheduling algorithms developed and deployed by various Grid projects.
toward practical multi workflow scheduling in cluster and grid environments	Workflow applications are gaining popularity in recent years because of the prevalence of cluster and Grid environments. Many algorithms have been developed ever since, however two fundamental challenges in this area, i.e., dynamic resource and dynamic workload, are not well addressed. In cluster and Grid environments, resources may be contributed and controlled by different virtual organizations and shared by a variety of users who in turn submit various kinds of applications. Resources are heterogeneous under different ownership, their availability varies over time and may fail in a high rate. On the other hand, resources are shared and hence competed among many applications with various computation requirements. Existing static algorithms are designed to schedule a single workflow application, without considering other workloads and any resource competition in the system. Hence static approaches are not utilized widely in practice despite its known advantages. Dynamic scheduling approaches can handle the dynamic workload and resources practically by nature but their effectiveness has yet to optimize as they do not have a global view of workflow application and scheduling decision is made nearsighted locally.   In this dissertation, as an effort toward practically scheduling workflow applications in cluster and Grid environments, a failure aware dynamic scheduling strategy for multiple workflow applications is proposed. The approach makes scheduling decision only when a task is ready, as traditional dynamic approach does, but leverages task dependency information, execution time estimation, failure prediction and queue wait time prediction. With preassigned priority for each task by the workflow Planner, the workflow Executor globally prioritizes all the ready to execute tasks in queue and schedules the individual task to the most suitable resource collection in order to minimize the overall workflow execution time. Furthermore, the algorithm is extended to a cluster of clusters environment, where each cluster has its own local workload management system. As a conclusion, the findings of the research is four folded: (1) With adaptability to dynamic resource change, the proposed strategy not only outperforms the purely dynamic ones but also improves over the traditional static ones. And it performs more efficiently with data intensive application of higher degree of parallelism. (2) When guided by the Planner, the proposed strategy can schedule multiple workflows dynamically without requiring merging the workflows a priori. It significantly outperforms two other traditional dynamic algorithms by 43.6% and 36.7% with respect to workflow makespan and turnaround time respectively, and it performs even better when the number of concurrent workflow applications increases and the resources are scarce. (3) We observer that the traditional failure prediction accuracy definitions impose different performance implications on different applications and fail to measure how that improves scheduling effectiveness, and propose two definitions on failure prediction accuracy from the perspectives of system and scheduling respectively. The comprehensive evaluation results using real failure traces show that the proposed strategy performs well with practically achievable prediction accuracy by reducing the average makespan, the loss time and the number of job rescheduling. (4) The proposed algorithm can be augmented to Grids in form multicluster where each cluster has its own workload management system. The proposed queue wait time aware algorithm leverages the advancement of queue wait time prediction techniques and empirically studies if the tunability of resource requirements helps scheduling. The extensive experiment with both real workload traces and test bench shows that the queue wait time aware algorithm improves workflow performance by 3 to 10 times in terms of average makespan with relatively very low cost of data movement.  Finally, the research studies how to benefit from existing researches and practices on both static and dynamic scheduling, introduces a hybrid scheduling scheme, i.e., a planner guided dynamic scheduling approach, targets on dynamic workload on cluster and Grid environment. A prototype is developed based on Condor platform to prove the concept of proposed algorithm.
	
approximation algorithms for power minimization of earliest deadline first and rate monotonic schedules	We address power minimization of earliest deadline first and rate monotonic schedules by voltage and frequency scaling. We prove that the problems are NP-hard, and present (1+∈) fully polynomial time approximation techniques that generate solutions which are guaranteed to be within a specified quality bound (QB= ∈) (say within 1% of the optimal). We demonstrate that our techniques can match optimal solutions when QB is set at 1%, out perform existing approaches [1] even when QB is set at 10%, generate solutions that are quite close to optimal (  5%) for large 100 node task sets.
	
	
	
	
	
a grid monitoring architecture	
	
on the design of online scheduling algorithms for advance reservations and qos in grids	We consider the problem of providing QoS guarantees to Grid users through advance reservation of resources. Advance reservation mechanisms provide the ability to allocate resources to users based on agreed-upon QoS requirements and increase the predictability of a Grid system, yet incorporating such mechanisms into current Grid environments has proven to be a challenging task due to the resulting resource fragmentation. We use concepts from computational geometry to present a framework for tackling the resource fragmentation, and for formulating a suite of scheduling strategies. We also develop efficient implementations of the scheduling algorithms that scale to large Grids. We conduct a comprehensive performance evaluation study using simulation, and we present numerical results to demonstrate that our strategies perform well across several metrics that reflect both user-and system-specific goals. Our main contribution is a timely, practical, and efficient solution to the problem of scheduling resources in emerging on-demand computing environments.
	
	
a short survey of commercial cluster batch schedulers	As high performance computing clusters are getting cheaper, they become more accessible. The various clusters are running a host of workload management software suites, which are getting more complex and offer cluster administrators numerous features, scheduling policies, job prioritization schemes, etc. In this paper we survey some of the common commercial workload managers on the market, covering their main features — specifically the scheduling policies and algorithms they support, their priority and queueing mechanisms, focusing on their default settings.
	
	
	
	
	
	
	
grid resource management and scheduling for data streaming applications	Data streaming applications bring new challenges to resource management and scheduling for grid computing. Since real-time data streaming is required as data processing is going on, integrated grid resource management becomes essential among processing, storage and networking resources. Traditional scheduling approaches may not be sufficient for such applications, since usually only one aspect of grid resource scheduling is focused. In this work, an integrated resource scheduling approach is proposed and coordinated resource allocation of CPU cycles, storage capability and network bandwidth is implemented. Resource allocation is performed periodically with updated information on resources and applications and heuristic search for optimal solutions is used to assign various resources for running applications simultaneously. Performance metrics considered in this work include data throughput and utilization of processors, storage, and bandwidth, which are actually tightly coupled with each other when applied for grid data streaming applications. Experimental results show dramatic improvement of performance and scalability using our implementation.
grid information services for distributed resource sharing	Grid technologies enable large-scale sharing of resources within formal or informal consortia of individuals and/or institutions: what are sometimes called virtual organizations. In these settings, the discovery, characterization, and monitoring of resources, services, and computations are challenging problems due to the considerable diversity; large numbers, dynamic behavior, and geographical distribution of the entities in which a user might be interested. Consequently, information services are a vital part of any Grid software infrastructure, providing fundamental mechanisms for discovery and monitoring, and hence for planning and adapting application behavior. We present an information services architecture that addresses performance, security, scalability, and robustness requirements. Our architecture defines simple low-level enquiry and registration protocols that make it easy to incorporate individual entities into various information structures, such as aggregate directories that support a variety of different query languages and discovery strategies. These protocols can also be combined with other Grid protocols to construct additional higher-level services and capabilities such as brokering, monitoring, fault detection, and troubleshooting. Our architecture has been implemented as MDS-2, which forms part of the Globus Grid toolkit and has been widely deployed and applied.
	
	
computational experience with approximation algorithms for the set covering problem	The Set Covering Problem (SCP) is a well known combinatorial optimization problem, which is NP-hard. We conducted a comparative study of eight different approximation algorithms for the SCP, including several greedy variants, fractional relaxations, randomized algorithms and a neural network algorithm. The algorithms were tested on a set of random-generated problems with up to 500 rows and 5000 columns, and on two sets of problems originating in combinatorial questions with up to 28160 rows and 11264 columns. On the random problems and on one set of combinatorial problems, the best algorithm among those we tested was the neural network algorithm, with greedy variants very close in second and third place. On the other set of combinatorial problems, the best algorithm was a greedy variant and the neural network performed quite poorly. The other algorithms we tested were always inferior to the ones mentioned above.
	
	
	
	
scheduling in grid environment	
a taxonomy and survey of grid resource management systems	The resource management system is the central component of network computing systems. There have been many projects focused on network computing that have designed and implemented resource management systems with a variety of architectures and services. In this paper, we develop a comprehensive taxonomy for describing resource management architectures. We use this taxonomy in identifying approaches followed in the implementation of real resource management systems for largescale network computing systems known as Grids. We use the taxonomy and the survey results to identify architectural approaches that have not been fully explored in the research.
	
	
efficient method for single machine total tardiness problem	Method for solving the problem of minimizing the total tardiness of jobs with due dates is considered as a problem of determining shortest Hamiltonian path in the graph. Computational results for random generated instances with up to 150 jobs for unweighted and weighted total tardiness problem show the good performance and the efficiency of the developed method and algorithms.
	
	
	
	
	
the physiology of the grid an open grid services architecture for distributed systems integration	In both e-business and e-science, we often need to integrate services across distributed, heterogeneous, dynamic “virtual organizations” formed from the disparate resources within a single enterprise and/or from external resource sharing and service provider relationships. This integration can be technically challenging because of the need to achieve various qualities of service when running on top of different native platforms. We present an Open Grid Services Architecture that addresses these challenges. Building on concepts and technologies from the Grid and Web services communities, this architecture defines a uniform exposed service semantics (the Grid service); defines standard mechanisms for creating, naming, and discovering transient Grid service instances; provides location transparency and multiple protocol bindings for service instances; and supports integration with underlying native platform facilities. The Open Grid Services Architecture also defines, in terms of Web Services Description Language (WSDL) interfaces and associated conventions, mechanisms required for creating and composing sophisticated distributed systems, including lifetime management, change management, and notification. Service bindings can support reliable invocation, authentication, authorization, and delegation, if required. Our presentation complements an earlier foundational article, “The Anatomy of the Grid,” by describing how Grid mechanisms can implement a service-oriented architecture, explaining how Grid functionality can be incorporated into a Web services framework, and illustrating how our architecture can be applied within commercial computing as a basis for distributed system integration—within and across organizational domains. This is a DRAFT document and continues to be revised. The latest version can be found at http://www.globus.org/research/papers/ogsa.pdf. Please send comments to foster@mcs.anl.gov, carl@isi.edu, jnick@us.ibm.com, tuecke@mcs.anl.gov Physiology of the Grid 2
	
	
	
	
qos based scheduling of workflow applications on service grids	
a taxonomy of workflow management systems for grid computing	With the advent of Grid and application technologies, scientists and engineers are building more and more complex applications to manage and process large data sets, and execute scientific experiments on distributed resources. Such application scenarios require means for composing and executing complex workflows. Therefore, many efforts have been made towards the development of workflow management systems for Grid computing. In this paper, we propose a taxonomy that characterizes and classifies various approaches for building and executing workflows on Grids. We also survey several representative Grid workflow systems developed by various projects world-wide to demonstrate the comprehensiveness of the taxonomy. The taxonomy not only highlights the design and engineering similarities and differences of state-of-the-art in Grid workflow systems, but also identifies the areas that need further research.
	
a performance study of monitoring and information services for distributed systems	Monitoring and information services form a key component of a distributed system, or Grid. A quantitative study of such services can aid in understanding the performance limitations, advise in the deployment of the monitoring system, and help evaluate future development work. To this end, we study the performance of three monitoring and information services for distributed systems: the Globus Toolkit/spl reg/ Monitoring and Discovery Service (MDS2), the European Data Grid Relational Grid Monitoring Architecture (R-GMA) and Hawkeye, part of the Condor project. We perform experiments to test their scalability with respect to number of users, number of resources and amount of data collected. Our study shows that each approach has different behaviors, often due to their different design goals. In the four sets of experiments we conducted to evaluate the performance of the service components under different circumstances, we found a strong advantage to caching or pre-fetching the data, as well as the need to have primary components at well-connected sites because of the high load seen by all systems.
scalability analysis of three monitoring and information systems mds2 r gma and hawkeye	Monitoring and information system (MIS) implementations provide data about available resources and services within a distributed system, or Grid. A comprehensive performance evaluation of an MIS can aid in detecting potential bottlenecks, advise in deployment, and help improve future system development. In this paper, we analyze and compare the performance of three implementations in a quantitative manner: the Globus Toolkit^(R) Monitoring and Discovery Service (MDS2), the European DataGrid Relational Grid Monitoring Architecture (R-GMA), and the Condor project's Hawkeye. We use the NetLogger toolkit to instrument the main service components of each MIS and conduct four sets of experiments to benchmark their scalability with respect to the number of users, the number of resources, and the amount of data collected. Our study provides quantitative measurements comparable across all systems. We also find performance bottlenecks and identify how they relate to the design goals, underlying architectures, and implementation technologies of the corresponding MIS, and we present guidelines for deploying MISs in practice.
