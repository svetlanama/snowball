2091856355	2015	improved mispronunciation detection with deep neural network trained acoustic models and transfer learning based logistic regression classifiers. Mispronunciation detection is an important part in a Computer-Aided Language Learning (CALL) system. By automatically pointing out where mispronunciations occur in an utterance, a language learner can receive informative and to-the-point feedbacks. In this paper, we improve mispronunciation detection performance with a Deep Neural Network (DNN) trained acoustic model and transfer learning based Logistic Regression (LR) classifiers. The acoustic model trained by the conventional GMM-HMM based approach is refined by the DNN training with enhanced discrimination. The corresponding Goodness Of Pronunciation (GOP) scores are revised to evaluate pronunciation quality of non-native language learners robustly. A Neural Network (NN) based, Logistic Regression (LR) classifier, where a general neural network with shared hidden layers for extracting useful speech features is pre-trained firstly with pooled, training data in the sense of transfer learning, and then phone-dependent, 2-class logistic regression classifiers are trained as phone specific output layer nodes, is proposed to mispronunciation detection. The new LR classifier streamlines training multiple individual classifiers separately by learning the common feature representation via the shared hidden layer. Experimental results on an isolated English word corpus recorded by non-native (L2) English learners show that the proposed GOP measure can improve the performance of GOP based mispronunciation detection approach, i.e., 7.4%7.4% of the precision and recall rate are both improved, compared with the conventional GOP estimated from GMM-HMM. The NN-based LR classifier improves the equal precision–recall rate by 25%25% over the best GOP based approach. It also outperforms the state-of-art Support Vector Machine (SVM) based classifier by 2.2%2.2% of equal precision–recall rate improvement. Our approaches also achieve similar results on a continuous read, L2 Mandarin language learning corpus.
2016114400	2009	an overview of spoken language technology for education. This paper reviews research in spoken language technology for education and more specifically for language learning. It traces the history of the domain and then groups main issues in the interaction with the student. It addresses the modalities of interaction and their implementation issues and algorithms. Then it discusses one user population - children - and an application for them. Finally it has a discussion of overall systems. It can be used as an introduction to the field and a source of reference materials.
2070133242	2000	automatic scoring of pronunciation quality. We present a paradigm for the automatic assessment of pronunciation quality by machine. In this scoring paradigm, both native and nonnative speech data is collected and a database of human-expert ratings is created to enable the development of a variety of machine scores. We first discuss issues related to the design of speech databases and the reliability of human ratings. We then address pronunciation evaluation as a prediction problem, trying to predict the grade a human expert would assign to a particular skill. Using the speech and the expert-ratings databases, we build statistical models and introduce different machine scores that can be used as predictor variables. We validate these machine scores on the Voice Interactive Language Training System (VILTS) corpus, evaluating the pronunciation of American speakers speaking French and we show that certain machine scores, like the log-posterior and the normalized duration, achieve a correlation with the targeted human grades that is comparable to the human-to-human correlation when a sufficient amount of speech data is available.
1931766939	1996	automatic text independent pronunciation scoring of foreign language student speech. SRI International is currently involved in the development of a new generation of software systems for automatic scoring of pronunciation as part of the Voice Interactive Language Training System (VILTS) project. This paper describes the goals of the VILTS system, the speech corpus and the algorithm development. The automatic grading system uses SRI's Decipher/sup TM/ continuous speech recognition system to generate phonetic segmentations that are used to produce pronunciation scores at the end of each lesson. The scores produced by the system are similar to those of expert human listeners. Unlike previous approaches, in which models were built for specific sentences or phrases, we present a new family of algorithms designed to perform well even when knowledge of the exact text to be used is not available.
1979364015	2009	automatic scoring of non native spontaneous speech in tests of spoken english. This paper presents the first version of the SpeechRater^S^M system for automatically scoring non-native spontaneous high-entropy speech in the context of an online practice test for prospective takers of the Test of English as a Foreign Language^(R) internet-based test (TOEFL^(R) iBT). The system consists of a speech recognizer trained on non-native English speech data, a feature computation module, using speech recognizer output to compute a set of mostly fluency based features, and a multiple regression scoring model which predicts a speaking proficiency score for every test item response, using a subset of the features generated by the previous component. Experiments with classification and regression trees (CART) complement those performed with multiple regression. We evaluate the system both on TOEFL Practice data [TOEFL Practice Online (TPO)] as well as on Field Study data collected before the introduction of the TOEFL iBT. Features are selected by test development experts based on both their empirical correlations with human scores as well as on their coverage of the concept of communicative competence. We conclude that while the correlation between machine scores and human scores on TPO (of 0.57) still differs by 0.17 from the inter-human correlation (of 0.74) on complete sets of six items (Pearson r correlation coefficients), the correlation of 0.57 is still high enough to warrant the deployment of the system in a low-stakes practice environment, given its coverage of several important aspects of communicative competence such as fluency, vocabulary diversity, grammar, and pronunciation. Another reason why the deployment of the system in a low-stakes practice environment is warranted is that this system is an initial version of a long-term research and development program where features related to vocabulary, grammar, and content will be added in a later stage when automatic speech recognition performance improves, which can then be easily achieved without a re-design of the system. Exact agreement on single TPO items between our system and human scores was 57.8%, essentially at par with inter-human agreement of 57.2%. Our system has been in operational use to score TOEFL Practice Online Speaking tests since the Fall of 2006 and has since scored tens of thousands of tests.
2091359957	2000	combination of machine scores for automatic grading of pronunciation quality. This work is part of an effort aimed at developing computer-based systems for language instruction; we address the task of grading the pronunciation quality of the speech of a student of a foreign language. The automatic grading system uses SRI's DecipherTM continuous speech recognition system to generate phonetic segmentations. Based on these segmentations and probabilistic models we produce different pronunciation scores for individual or groups of sentences that can be used as predictors of the pronunciation quality. Different types of these machine scores can be combined to obtain a better prediction of the overall pronunciation quality. In this paper we review some of the best-performing machine scores and discuss the application of several methods based on linear and nonlinear mapping and combination of individual machine scores to predict the pronunciation quality grade that a human expert would have given. We evaluate these methods in a database that consists of pronunciation-quality-graded speech from American students speaking French. With predictors based on spectral match and on durational characteristics, we find that the combination of scores improved the prediction of the human grades and that nonlinear mapping and combination methods performed better than linear ones. Characteristics of the different nonlinear methods studied are discussed.
334543181	1999	use of speech recognition in computer assisted language learning. 
290344559	2010	automatic derivation of phonological rules for mispronunciation detection in a computer assisted pronunciation training system. 
2160922902	1998	speech technology in computer assisted language learning strengths and limitations of a new call paradigm. We investigate the suitability of deploying speech technology in computer-based systems that can be used to teach foreign language skills. In reviewing the current state of speech recognition and speech processing technology and by examining a number of voice-interactive CALL applications, we suggest how to create robust interactive learning environments that exploit the strengths of speech technology while working around its limitations. In the conclusion, we draw on our review of these applications to identify directions of future research that might improve both the design and the overall performance of voice-interactive CALL systems.
2137268753	2007	deriving salient learners mispronunciations from cross language phonological comparisons. This work aims to derive salient mispronunciations made by Chinese (L1 being Cantonese) learners of English (L2 being American English) in order to support the design of pedagogical and remedial instructions. Our approach is grounded on the theory of language transfer and involves systematic phonological comparison between two languages to predict  possible   phonetic   confusions  that may lead to mispronunciations. We collect a corpus of speech recordings from some 21 Cantonese learners of English. We develop an automatic speech recognizer by training cross-word triphone models based on the TIMIT corpus. We also develop an "extended" pronunciation lexicon that incorporates the predicted phonetic confusions to generate additional, erroneous pronunciation variants for each word. The extended pronunciation lexicon is used to produce a confusion network in recognition of the English speech recordings of Cantonese learners. We refer to the statistics of the erroneous recognition outputs to derive salient mispronunciations that stipulates the predictions based on phonological comparison.
2030026461	2011	a three stage approach to the automated scoring of spontaneous spoken responses. This paper presents a description and evaluation of SpeechRater^S^M, a system for automated scoring of non-native speakers' spoken English proficiency, based on tasks which elicit spontaneous monologues on particular topics. This system builds on much previous work in the automated scoring of test responses, but differs from previous work in that the highly unpredictable nature of the responses to this task type makes the challenge of accurate scoring much more difficult. SpeechRater uses a three-stage architecture. Responses are first processed by a filtering model to ensure that no exceptional conditions exist which might prevent them from being scored by SpeechRater. Responses not filtered out at this stage are then processed by the scoring model to estimate the proficiency rating which a human might assign to them, on the basis of features related to fluency, pronunciation, vocabulary diversity, and grammar. Finally, an aggregation model combines an examinee's scores for multiple items to calculate a total score, as well as an interval in which the examinee's score is predicted to reside with high confidence. SpeechRater's current level of accuracy and construct representation have been deemed sufficient for low-stakes practice exercises, and it has been used in a practice exam for the TOEFL since late 2006. In such a practice environment, it offers a number of advantages compared to human raters, including system load management, and the facilitation of immediate feedback to students. However, it must be acknowledged that SpeechRater presently fails to measure many important aspects of speaking proficiency (such as intonation and appropriateness of topic development), and its agreement with human ratings of proficiency does not yet approach the level of agreement between two human raters.
2400818677	2009	implementation of an extended recognition network for mispronunciation detection and diagnosis in computer assisted pronunciation training. 
21911835	2004	practical use of english pronunciation system for japanese students in the call classroom. 
2169724247	2008	the effectiveness of computer based speech corrective feedback for improving segmental quality in l2 dutch. Although the success of automatic speech recognition (ASR)-based Computer Assisted Pronunciation Training (CAPT) systems is increasing, little is known about the pedagogical effectiveness of these systems. This is particularly regrettable because ASR technology still suffers from limitations that may result in the provision of erroneous feedback, possibly leading to learning breakdowns. To study the effectiveness of ASR-based feedback for improving pronunciation, we developed and tested a CAPT system providing automatic feedback on Dutch phonemes that are problematic for adult learners of Dutch. Thirty immigrants who were studying Dutch were assigned to three groups using either the ASR-based CAPT system with automatic feedback, a CAPT system without feedback, or no CAPT system. Pronunciation quality was assessed for each participant before and after the training by human experts who evaluated overall segmental quality and the quality of the phonemes addressed in the training. The participants' impressions of the CAPT system used were also studied through anonymous questionnaires. The results on global segmental quality show that the group receiving ASR-based feedback made the largest mean improvement, but the groups' mean improvements did not differ significantly. The group receiving ASR-based feedback showed a significantly larger improvement than the no-feedback group in the segmental quality of the problematic phonemes targeted.
2079136039	2007	pronunciation feedback from real and virtual language teachers. The aim of this paper is to summarise how pronunciation feedback on the phoneme level should be given in computer-assisted pronunciation training (CAPT) in order to be effective. The study contains a literature survey of feedback in the language classroom, interviews with language teachers and their students about their attitudes towards pronunciation feedback, and observations of how feedback is given in their classrooms. The study was carried out using focus group meetings, individual semi-structured interviews and classroom observations. The feedback strategies that were advocated and observed in the study on pronunciation feedback from human teachers were implemented in a computer-animated language tutor giving articulation feedback. The virtual tutor was subsequently tested in a user trial and evaluated with a questionnaire. The article proposes several feedback strategies that would improve the pedagogical soundness of CAPT systems.
105558132	2005	pronunciation error detection method based on error rule clustering using a decision tree. 
2121068632	2006	automatic speech recognition reliability and pedagogical implications for teaching pronunciation. This study examines the reliability of automatic speech recognition (ASR) software used to teach English pronunciation, focusing on one particular piece of software, FluSpeak, as a typical example. Thirty-six Korean English as a Foreign Language (EFL) college students participated in an experiment in which they listened to 15 sentences that appeared in FluSpeak and recorded their voices, repeating sentence by sentence. The ASR software analysis of their production was then compared to pronunciation scores determined by native English speaking (NES) instructors. Although the correlation coefficient for intonation was nearly zero, indicating that ASR technology is still not as accurate as human analysis, the software may be very useful for student practice with aspects of pronunciation. The paper suggests a lesson plan for teaching English pronunciation through ASR software.
2137230015	2006	on the use of phonological features for pronunciation scoring. It is acknowledged that in many medical and educational applications there is a great need for good objective assessments of the pronunciation proficiency of a speaker, either a non-native speaker of the language or a native speaker with a certain speech handicap (e.g. a deaf or dysarthric speaker). Most pronunciation scoring software developed thus far just measures an over-all proficiency. The system proposed here envisages the computation of more detailed information on the nature of the pronunciation deficiencies. To that end, it works with a phonological representation of the speech. Described is the development of the system as well as its first encouraging assessments of non-native speakers of American English.
2569692527	1997	language learning based on non native speech recognition. 
1506404588	1999	automatic localization and diagnosis of pronunciation errors for second language learners of english. An automatic system for detection of pronunciation errors by adult learners of English is embedded in a language–learning package. Four main features are: (1) a recognizer robust to non–native speech; (2) localization of phone– and word–level errors; (3) diagnosis of what sorts of phone–level errors took place; and (4) a lexical–stress detector. These tools together allow robust, consistent, and specific feedback on pronunciation errors, unlike many previous systems that provide feedbaconly at a more general level. The diagnosis technique searches for errors expected based on the student’s mother tongue and uses a separate bias for each error in order to maintain a particular desired global false alarm rate. Results are presented here for non–native recognition on tasks of differing complexity and for diagnosis, based on a data set of artificial errors, showing that this method can detect many contrasts with a high hit rate and a low false alarm rate.
2020203910	2000	slim prosodic automatic tools for self learning instruction. Abstract   We present the Prosodic Module of a courseware for computer-assisted foreign language learning called SLIM – an acronym for Multimedia Interactive Linguistic Software, developed at the University of Venice (see Delmonte et al., 1999a,b).  The Prosodic Module  has been created in order to deal with the problem of improving a student's performance both in the perception and production of prosodic aspects of spoken language activities. It is composed of two different sets of Learning Activities, the first one dealing with phonetic and prosodic problems at word level and at segmental level – where segmental refers to syllable-sized segments; the second one dealing with prosodic aspects at phonological phrase and utterance suprasegmental level. The main goal of Prosodic Activities is to ensure consistent and pedagogically sound feedback to the student intending to improve his/her pronunciation in a foreign language. We argue that the use of Automatic Speech Recognition (ASR) as Teaching Aid should be under-utilized and should be targeted to narrowly focussed spoken exercises, disallowing open-ended dialogues, in order to ensure consistency of evaluation. In addition, we argue that ASR alone cannot be used to gauge Goodness of Pronunciation (GOP), being inherently inadequate for that goal. On the contrary, we support the conjoined use of ASR technology and prosodic tools to produce GOP useable for linguistically consistent and adequate feedback to the student.
1481151678	2004	segmental errors in dutch as a second language how to establish priorities for capt. In this paper we report on a study that was carried out to obtain an inventory of segmental errors in the Dutch of adult learners with different mother tongues (L1s). The errors observed were subsequently examined in detail to select a number of errors that should receive priority in Computer Assisted Pronunciation Training (CAPT) for Dutch as L2.
2139008940	2000	Phone-level pronunciation scoring and assessment for interactive language learning. This paper investigates a method of automatic pronunciation scoring for use in computer-assisted language learning (CALL) systems. The method utilises a likelihood-based ‘Goodness of Pronunciation’ (GOP) measure which is extended to include individual thresholds for each phone based on both averaged native confidence scores and on rejection statistics provided by human judges. Further improvements are obtained by incorporating models of the subject’s native language and by augmenting the recognition networks to include expected pronunciation errors. The various GOP measures are assessed using a specially recorded database of non-native speakers which has been annotated to mark phone-level pronunciation errors. Since pronunciation assessment is highly subjective, a set of four performance measures has been designed, each of them measuring diAerent aspects of how well computer-derived phone-level scores agree with human scores. These performance measures are used to cross-validate the reference annotations and to assess the basic GOP algorithm and its refinements. The experimental results suggest that a likelihood-based pronunciation scoring metric can achieve usable performance, especially after applying the various enhancements
1988687075	2000	Quantitative assessment of second language learners' fluency by means of automatic speech recognition technology. To determine whether expert fluency ratings of read speech can be predicted on the basis of automatically calculated temporal measures of speech quality, an experiment was conducted with read speech of 20 native and 60 non-native speakers of Dutch. The speech material was scored for fluency by nine experts and was then analyzed by means of an automatic speech recognizer in terms of quantitative measures such as speech rate, articulation rate, number and length of pauses, number of dysfluencies, mean length of runs, and phonation/time ratio. The results show that expert ratings of fluency in read speech are reliable (Cronbach’s α varies between 0.90 and 0.96) and that these ratings can be predicted on the basis of quantitative measures: for six automatic measures the magnitude of the correlations with the fluency scores varies between 0.81 and 0.93. Rate of speech appears to be the best predictor: correlations vary between 0.90 and 0.93. Two other important determinants of reading fluency are the rate.
2404741191	2000	Towards an Automatic Oral Proficiency Test for Dutch as a Second Language: Automatic Pronunciation Assessment in Read and Spontaneous Speech. 
2690082738	2017	Shefce: A Cantonese-English bilingual speech corpus for pronunciation assessment. This paper introduces the development of ShefCE: a Cantonese-English bilingual speech corpus from L2 English speakers in Hong Kong. Bilingual parallel recording materials were chosen from TED online lectures. Script selection were carried out according to bilingual consistency (evaluated using a machine translation system) and the distribution balance of phonemes. 31 undergraduate to postgraduate students in Hong Kong aged 20–30 were recruited and recorded a 25-hour speech corpus (12 hours in Cantonese and 13 hours in English). Baseline phoneme/syllable recognition systems were trained on background data with and without the ShefCE training data. The final syllable error rate (SER) for Cantonese is 17.3% and final phoneme error rate (PER) for English is 34.5%. The automatic speech recognition performance on English showed a significant mismatch when applying L1 models on L2 data, suggesting the need for explicit accent adaptation. ShefCE and the corresponding baseline models will be made openly available for academic research.
125652930	2000	two experiments on automatic scoring of spoken language proficiency
1483590201	2009	dist=0.324984859918  ECC= 15  year= 2009  title= developing a call system for practicing oral proficiency how to design for speech technology pedagogy and learners
2120296657	2009	dist=0.183294837282  ECC= 7  year= 2009  title= sub structure based estimation of pronunciation proficiency and classification of learners
2129755070	2008	dist=0.199183443714  ECC= 6  year= 2008  title= decision fusion for improving mispronunciation detection using language transfer knowledge and phoneme dependent pronunciation scoring
2132245250	2008	dist=0.208211002038  ECC= 9  year= 2008  title= verifying pronunciation accuracy from speakers with neuromuscular disorders
2166223630	2007	dist=0.232500385382  ECC= 11  year= 2007  title= boosting of prosodic and pronunciation features to detect mispronunciations of non native children
2171177956	2009	dist=0.216836015556  ECC= 6  year= 2009  title= improving mispronunciation detection using machine learning
2171763273	2007	dist=0.22012847702  ECC= 9  year= 2007  title= automatic pronunciation assessment for mandarin chinese approaches and system overview
2152144447	2008	dist=0.3423532771  ECC= 7  year= 2008  title= mandarin vowel pronunciation quality evaluation by a novel formant classification method and its combination with traditional algorithms
2182927705	2009	dist=0.180148205323  ECC= 8  year= 2009  title= an svm based mandarin pronunciation quality assessment system
2235458433	2016	dist=0.207538054882  ECC= 4  year= 2016  title= dynamic time warping in phoneme modeling for fast pronunciation error detection
2251840254	2012	dist=0.224306378795  ECC= 6  year= 2012  title= using an asr database to design a pronunciation evaluation system in basque
2401896499	2016	dist=0.199051292038  ECC= 4  year= 2016  title= improving non native mispronunciation detection and enriching diagnostic feedback with dnn based speech attribute modeling
2405178423	0000	mispronunciation detection without nonnative training data	https://academic.microsoft.com/#/detail/2405178423	2015	Conventional mispronunciation detection systems that have the capability of providing corrective feedback typically require a set of common error patterns that are known beforehand, obtained either by consulting with experts, or from a humanannotated nonnative corpus. In this paper, we propose a mispronunciation detection framework that does not rely on nonnative training data. We first discover an individual learner’s possible pronunciation error patterns by analyzing the acoustic similarities across their utterances. With the discovered error candidates, we iteratively compute forced alignments and decode learner-specific context-dependent error patterns in a greedy manner. We evaluate the framework on a Chinese University of Hong Kong (CUHK) corpus containing both Cantonese and Mandarin speakers reading English. Experimental results show that the proposed framework effectively detects mispronunciations and also has a good ability to prioritize feedback. Index Terms: Computer-Assisted Pronunciation Training (CAPT), Gaussian mixture model (GMM), Extended Recognition Network (ERN)	2481769225@ann lee@63966007@massachusetts institute of technology;2154846939@james r glass@63966007@massachusetts institute of technology	204321447@natural language processing;28490314@speech recognition;119857082@machine learning;41008148@computer science	1524333225;144708831;2139008940;2016114400;2101174054;2134124280;2169883442;2119607964;2137268753;275138538;2151941172;103312509;2407623921;2067517679;2027993708;35168091;1486666175;2398753452;2185463204;2288490721;77825124	
2552635739	0000	mispronunciation detection and diagnosis in l2 english speech using multidistribution deep neural networks	https://academic.microsoft.com/#/detail/2552635739	2017	This paper investigates the use of multidistribution deep neural networks DNNs for mispronunciation detection and diagnosis MDD, to circumvent the difficulties encountered in an existing approach based on extended recognition networks ERNs. The ERNs leverage existing automatic speech recognition technology by constraining the search space via including the likely phonetic error patterns of the target words in addition to the canonical transcriptions. MDDs are achieved by comparing the recognized transcriptions with the canonical ones. Although this approach performs reasonably well, it has the following issues: 1 Learning the error patterns of the target words to generate the ERNs remains a challenging task. Phones or phone errors missing from the ERNs cannot be recognized even if we have well-trained acoustic models; and 2 acoustic models and phonological rules are trained independently, and hence, contextual information is lost. To address these issues, we propose an acoustic-graphemic-phonemic model AGPM using a multidistribution DNN, whose input features include acoustic features, as well as corresponding graphemes and canonical transcriptions encoded as binary vectors. The AGPM can implicitly model both grapheme-to-likely-pronunciation and phoneme-to-likely-pronunciation conversions, which are integrated into acoustic modeling. With the AGPM, we develop a unified MDD framework, which works much like free-phone recognition. Experiments show that our method achieves a phone error rate PER of 11.1%. The false rejection rate FRR, false acceptance rate FAR, and diagnostic error rate DER for MDD are 4.6%, 30.5%, and 13.5%, respectively. It outperforms the ERN approach using DNNs as acoustic models, whose PER, FRR, FAR, and DER are 16.8%, 11.0%, 43.6%, and 32.3%, respectively.	2311207066@kun li@177725633@the chinese university of hong kong;2162737707@xiaojun qian@177725633@the chinese university of hong kong;2284323627@helen m meng@177725633@the chinese university of hong kong	28490314@speech recognition;154945302@artificial intelligence;119857082@machine learning;41008148@computer science	2136922672;2100495367;1904365287;1498436455;2147768505;1993882792;2143612262;2153804780;2090755665;2155273149;2062164080;1922655562;1580142630;1513168562;2106051978;2077804127;2053154970;2139008940;2126203737;2016114400;2070133242;2171019095;27462273;101733563;2164810574;2036242736;1931766939;67332896;2087402357;120415783;2137268753;1986671983;2045158511;1965044932;70727784;2400818677;2103243174;2045956438;2008834750;275138538;2003890417;2091856355;2158513796;2395106899;290344559;42910856;204924188;29332114;2167642311;2049905800;2058412794;2402640444;1585763212;2067517679;2010768384;2398741870;2152334841;57885259;2054441760;2038466182;2317392553;2401916374;2027993708;1965370992;1967624650;1970870811;2185463204;323265179;2028234151;1564062815;2402812677;2402103843;2124138609;2154745686;2097400979;32469509;2295721380;2137286203;294692716;2579478650;1505400583;197194526;1992340436;1985084205;2140200493;2025693318;2148841122;2396796398;2404765346;1933699394;123054690;2295355464	
2408752745	2013	dist=0.13847915194  ECC= 8  year= 2013  title= automated speech scoring for non native middle school students with multiple task types
322814586	2000	dist=0.205439517762  ECC= 16  year= 2000  title= effects of speech recognition based pronunciation feedback on second language pronunciation ability
1571007647	2008	dist=0.361564284021  ECC= 8  year= 2008  title= analysis of pronunciation errors of saudi esl learners
1970870811	2013	dist=0.355529409625  ECC= 6  year= 2013  title= mispronunciation detection via dynamic time warping on deep belief network based posteriorgrams
105558132	2005	dist= 0.791154060819  ECC= 19  year= 2005  title= pronunciation error detection method based on error rule clustering using a decision tree
15874236	2008	dist=0.385726908012  ECC= 9  year= 2008  title= better nonnative intonation scores through prosodic theory
1592697577	2009	dist=0.230710610653  ECC= 10  year= 2009  title= islands of failure employing word accent information for pronunciation quality assessment of english l2 learners
1606774179	2006	dist=0.372278119434  ECC= 7  year= 2006  title= automatic detection of tone mispronunciation in mandarin
1878086946	2010	dist=0.367341394078  ECC= 8  year= 2010  title= towards using structural events to assess non native speech
1965370992	2014	dist=0.276768855455  ECC= 7  year= 2014  title= a new neural network based logistic regression classifier for improving mispronunciation detection of l2 language learners
1970870811	2013	dist=0.355529409625  ECC= 6  year= 2013  title= mispronunciation detection via dynamic time warping on deep belief network based posteriorgrams
1993193917	2010	dist=0.143272980822  ECC= 10  year= 2010  title= the use of speech technology in foreign language pronunciation training
2004362694	2013	dist=0.216054288186  ECC= 7  year= 2013  title= improving mispronunciation detection using adaptive frequency scale
2034866386	2011	dist=0.248229679463  ECC= 3  year= 2011  title= pca method for automated detection of mispronounced words
2035002366	2010	dist=0.228995714753  ECC= 3  year= 2010  title= statistical phone duration modeling to filter for intact utterances in a computer assisted pronunciation training system
2036074598	2012	dist=0.0976343842382  ECC= 10  year= 2012  title= automatic chinese pronunciation error detection using svm trained with structural features
2036864763	2009	dist=0.310513615878  ECC= 7  year= 2009  title= automatic scoring of children s read aloud text passages and word lists
2071401855	2012	dist=0.199822047068  ECC= 9  year= 2012  title= automatic analysis of mandarin accented english using phonological features
2112375231	2011	dist=0.18423360959  ECC= 8  year= 2011  title= pronunciation proficiency evaluation based on discriminatively refined acoustic models
2575689684	2016	computer assisted pronunciation training from pronunciation scoring towards spoken language learning	https://academic.microsoft.com/#/detail/2575689684	2016	This paper reviews the research approaches used in computer-assisted pronunciation training (CAPT), addresses the existing challenges, and discusses emerging trends and opportunities. To complement existing work, our analysis places more emphasis on pronunciation teaching and learning (as opposed to pronunciation assessment), prosodic error detection (as opposed to phonetic error detection), and research work from the past five years given the recent rapid development in spoken language technology.	2169633281@nancy f chen@115228651@agency for science technology and research;2096728398@haizhou li@115228651@agency for science technology and research	204321447@natural language processing;41895202@linguistics;28490314@speech recognition;41008148@computer science	2154278880;2139008940;2016114400;2032759346;1979364015;2104457544;2134124280;1988687075;2030026461;1977623709;70727784;2078617267;2400818677;21911835;2149709611;2091856355;2100109579;2397168380;1992910589;2025009046;2402640444;1585763212;2402113958;2051811941;2401896499;2032429609;2239499952;2293441309;2484174190;2401728495;2322133635;2132049498;12857174;2498863433;2407533274;2405178423;2406502879;1973657629;2398529454;2031023572;2403199234;2404113191;13842339;1537449681;2400832984;2408410119;2010800472;2560222437	
2370418772	2016	a two pass framework of mispronunciation detection and diagnosis for computer aided pronunciation training	https://academic.microsoft.com/#/detail/2370418772	2016	This paper presents a two-pass framework with discriminative acoustic modeling for mispronunciation detection and diagnoses (MD&D). The first pass of mispronunciation detection does not require explicit phonetic error pattern modeling. The framework instantiates a set of antiphones and a filler model to augment the original phone model for each canonical phone. This guarantees full coverage of all possible error patterns while maximally exploiting the phonetic information derived from the text prompt. The antiphones can be used to detect substitutions. The filler model can detect insertions, and phone skips are allowed to detect deletions. As such, there is no prior assumption on the possible error patterns that can occur. The second pass of mispronunciation diagnosis expands the detected insertions and substitutions into phone networks, and another recognition pass attempts to reveal the phonetic identities of the detected mispronunciation errors. Discriminative training (DT) is applied respectively to the acoustic models of the mispronunciation detection pass and the mispronunciation diagnosis pass. DT effectively separates the acoustic models of the canonical phones and the antiphones. Overall, with DT in both passes of MD&D, the error rate is reduced by 40.4% relative, compared with the maximum likelihood baseline. After DT, the error rates of the respective passes are also lower than those of a strong single-pass baseline with DT by 1.3% and 5.1% relative which are statistically significant.	2162737707@xiaojun qian@177725633@the chinese university of hong kong;2284323627@helen m meng@177725633@the chinese university of hong kong;2259525411@frank k soong@1290206253@microsoft	174576238@speech;52622490@feature extraction;61328038@speech processing;204321447@natural language processing;28490314@speech recognition;178980831@pattern recognition;119857082@machine learning;41008148@computer science	52327574;2034537249;2139008940;1931766939;2137268753;1965044932;1535086474;70727784;2008834750;290344559;103312509;1842528305;1506404588;2049905800;1739673028;2071650246;2067517679;1999845150;2093826182;1496430420;2027993708;2051811941;2063915318;323265179;2405178423;67753814;2403848074;2062516439;2026501739;1884048561;2400751463;2156178627	
2164810574	0000	automatic pronunciation scoring for language instruction
21911835	0000	practical use of english pronunciation system for japanese students in the call classroom
2395625153	0000	assessment of dutch pronunciation by means of automatic speech recognition technology
275138538	0000	improving mispronunciation detection and diagnosis of learners speech with context sensitive phonological rules based on language transfer
290344559	0000	automatic derivation of phonological rules for mispronunciation detection in a computer assisted pronunciation training system	https://academic.microsoft.com/#/detail/290344559	2010		2127817432@wai kit lo@177725633@the chinese university of hong kong;2442711725@shuang zhang@177725633@the chinese university of hong kong;2432636928@helen m meng@177725633@the chinese university of hong kong	204321447@natural language processing;41895202@linguistics;28490314@speech recognition;41008148@computer science	118501394;2137268753;2400818677;21911835;275138538	
323265179	0000	a method for measuring the intelligibility and nonnativeness of phone quality in foreign language pronunciation training	https://academic.microsoft.com/#/detail/323265179	1998		2132729723@goh kawai@74801974@university of tokyo;1983837166@keikichi hirose@74801974@university of tokyo	204321447@natural language processing;41895202@linguistics;28490314@speech recognition	88081813;2165076144;132631823;1564189039;193460978	
334543181	0000	use of speech recognition in computer assisted language learning
42910856	0000	automatic detection of mispronunciation for language instruction
66698146	0000	automatic evaluation and training in english pronunciation
70727784	0000	automatic pronunciation scoring of specific phone segments for language instruction	https://academic.microsoft.com/#/detail/70727784	1997		2319894527@yoon kim@1298353152@sri international;2130387140@horacio franco@1298353152@sri international;2342400288@leonardo neumeyer@1298353152@sri international	204321447@natural language processing;41895202@linguistics;28490314@speech recognition;41008148@computer science	2164810574;1931766939;2126597185;66698146;42910856;103591337;118308466	
2149709611	0000	using automatic speech processing for foreign language pronunciation tutoring some issues and a prototype
2152334841	0000	improved approaches of modeling and detecting error patterns with empirical analysis for computer aided pronunciation training
2134124280	0000	comparing different approaches for automatic pronunciation error detection
2137230015	0000	on the use of phonological features for pronunciation scoring	https://academic.microsoft.com/#/detail/2137230015	2006	It is acknowledged that in many medical and educational applications there is a great need for good objective assessments of the pronunciation proficiency of a speaker, either a non-native speaker of the language or a native speaker with a certain speech handicap (e.g. a deaf or dysarthric speaker). Most pronunciation scoring software developed thus far just measures an over-all proficiency. The system proposed here envisages the computation of more detailed information on the nature of the pronunciation deficiencies. To that end, it works with a phonological representation of the speech. Described is the development of the system as well as its first encouraging assessments of non-native speakers of American English.	1994204444@frederik stouten@32597200@ghent university;2137723762@jeanpierre martens@32597200@ghent university	99055596@non native pronunciations of english;15145288@intelligibility;171041071@first language;529173508@software development;133892786@speaker recognition;61328038@speech processing;204321447@natural language processing;28490314@speech recognition;41008148@computer science	2077804127;2164810574;1931766939;1598851216;1490506669;2151311453;2143493821;112280295;2101859041;2124810955;1585763212;2106199056;2147624457;2159740987;2006775235;2395625153;2404765346;2010800472	
2137268753	0000	deriving salient learners mispronunciations from cross language phonological comparisons
2137469438	0000	automatic mispronunciation detection for mandarin
2139008940	0000	phone level pronunciation scoring and assessment for interactive language learning	https://academic.microsoft.com/#/detail/2139008940	2000	This paper investigates a method of automatic pronunciation scoring for use in computer-assisted language learning (CALL) systems. The method utilises a likelihood-based ‘Goodness of Pronunciation’ (GOP) measure which is extended to include individual thresholds for each phone based on both averaged native confidence scores and on rejection statistics provided by human judges. Further improvements are obtained by incorporating models of the subject’s native language and by augmenting the recognition networks to include expected pronunciation errors. The various GOP measures are assessed using a specially recorded database of non-native speakers which has been annotated to mark phone-level pronunciation errors. Since pronunciation assessment is highly subjective, a set of four performance measures has been designed, each of them measuring diAerent aspects of how well computer-derived phone-level scores agree with human scores. These performance measures are used to cross-validate the reference annotations and to assess the basic GOP algorithm and its refinements. The experimental results suggest that a likelihood-based pronunciation scoring metric can achieve usable performance, especially after applying the various enhancements. ” 2000 Elsevier Science B.V. All rights reserved.	2220639533@silke m witt@241749@university of cambridge;2125228453@steve j young@241749@university of cambridge	171041071@first language;27181475@cross validation;106432739@education;204321447@natural language processing;41895202@linguistics;28490314@speech recognition;41008148@computer science	88081813;70727784;1601032495;622461482;42910856;1842528305;188328253;2101231039;2119243469;14635080;2043403177;165009135;2038666810;1563276533;1567526008	
2139565824	0000	comparing classifiers for pronunciation error detection
103312509	0000	automatic detection of phone level mispronunciation for language learning
105558132	0000	pronunciation error detection method based on error rule clustering using a decision tree	https://academic.microsoft.com/#/detail/105558132	2005		2287124405@akinori ito@201537933@tohoku university;2330545181@yenling lim@201537933@tohoku university;2130532201@motoyuki suzuki@201537933@tohoku university;2109998011@shozo makino@201537933@tohoku university	10229987@incremental decision tree;183931066@id3 algorithm;5481197@decision tree learning;84525736@decision tree;103088060@error detection and correction;28490314@speech recognition;178980831@pattern recognition;119857082@machine learning;41008148@computer science		
1420090963	0000	error patterns for automatic error detection in computer assisted pronunciation training systems	https://academic.microsoft.com/#/detail/1420090963	2014	This paper presents error patterns built on the basis of our comparative analysis of American English and Mexican Spanish phonemes and allophones which can be applied in designing the error detection module of a Computer Assisted Pronunciation Training (CAPT) System for teaching American English pronunciation to Mexican Spanish speakers. Error identification is important for an adequate choice of correcting techniques which improves English pronunciation acquisition and helps learners to develop less accented speech. Since automatic individual error detection remains a highly complex computational task, error patterns can enhance the system performance and improve its precision. To the best of our knowledge, error patterns in American English speech generated by Mexican Spanish speakers has not been defined in previous work which was done mainly for Castilian- originated standard Spanish.	2585011246@olga kolesnikova@107640659@south ural state university	204321447@natural language processing;28490314@speech recognition;46312422@communication;41008148@computer science	2016114400;2040380014;1605258438;334543181;2134124280;2119419436;2046166264;2068512280;105558132;1739673028;1585763212;2036074598;12857174;2089887411;2024624636;601151541;1540116543;1824298124;2178704931;2164242120;1522701191	
1482162963	1997	using speech recognition technology to assess foreign speakers pronunciation of dutch	https://academic.microsoft.com/#/detail/1482162963	1997		2460281135@c cucchiarini@145872427@radboud university nijmegen;2148590377@helmer strik@145872427@radboud university nijmegen;2174045948@l w j boves@145872427@radboud university nijmegen	91863865@speech corpus;204321447@natural language processing;41895202@linguistics;28490314@speech recognition;41008148@computer science	2164810574;1931766939;1995193944;66698146;1504344060;1842528305;2073357787;2054579521;1990780898	
1496430420	0000	automatic pronunciation error detection in dutch as a second language an acoustic phonetic approach	https://academic.microsoft.com/#/detail/1496430420	2006		2105274186@khiet p truong@94624287@university of twente	204321447@natural language processing;41895202@linguistics;28490314@speech recognition	2070696251;2139008940;2070133242;2169879729;1562705272;2164810574;1564039035;1931766939;334543181;2091359957;2043199434;2141720691;2119607964;1988687075;1986671983;70727784;1995193944;2149768999;1504344060;622461482;1979921636;42910856;2014410914;103312509;1997141060;116129933;1977369679;1481151678;1491767415;1739673028;181056519;2032625358;2051401856;1544450126;2171637847;1574415896;1990780898;2170734687;2056133372;1976779136;2000100543;2504939451;2121647670;2129335137;2023243382;2570769664;2335014220;7951086;184613729;2039157728;2526133016;2087172142;2137387078	
1505400583	0000	automatic assessment of english learner pronunciation using discriminative classifiers	https://academic.microsoft.com/#/detail/1505400583	2015	This paper presents a novel system for automatic assessment of pronunciation quality of English learner speech, based on deep neural network (DNN) features and phoneme specific discriminative classifiers. DNNs trained on a large corpus of native and non-native learner speech are used to extract phoneme posterior probabilities. A part of the corpus includes per phone teacher annotations, which allows training of two Gaussian Mixture Models (GMM), representing correct pronunciations and typical error patterns. The likelihood ratio is then obtained for each observed phone. Several models were evaluated on a large corpus of English-learning students, with a variety of skill levels, and aged 13 upwards. The cross-correlation of the best system and average human annotator reference scores is 0.72, with miss and false alarm rate around 19%. Automatic assessment is 81.6% correct with a high degree of confidence. The new approach significantly outperforms spectral distance based baseline systems.	2158997210@mauro nicolao@91136226@university of sheffield;2225696257@amy v beeston@91136226@university of sheffield;2140737305@thomas hain@91136226@university of sheffield	174576238@speech;504270822@nickel;52622490@feature extraction;50644808@artificial neural network;204321447@natural language processing;28490314@speech recognition;178980831@pattern recognition;119857082@machine learning;41008148@computer science	2139008940;2016114400;2130722890;2017743450;2115915165;2067517679;2398423749;1970870811	
1506404588	1999	automatic localization and diagnosis of pronunciation errors for second language learners of english	https://academic.microsoft.com/#/detail/1506404588	1999	An automatic system for detection of pronunciation errors by adult learners of English is embedded in a language–learning package. Four main features are: (1) a recognizer robust to non–native speech; (2) localization of phone– and word–level errors; (3) diagnosis of what sorts of phone–level errors took place; and (4) a lexical–stress detector. These tools together allow robust, consistent, and specific feedback on pronunciation errors, unlike many previous systems that provide feedbaconly at a more general level. The diagnosis technique searches for errors expected based on the student’s mother tongue and uses a separate bias for each error in order to maintain a particular desired global false alarm rate. Results are presented here for non–native recognition on tasks of differing complexity and for diagnosis, based on a data set of artificial errors, showing that this method can detect many contrasts with a high hit rate and a low false alarm rate.	2157962885@daniel herron@1290206253@microsoft;2024447061@wolfgang menzel@159176309@university of hamburg;2098126988@eric atwell@130828816@university of leeds;320991546@roberto bisiani@189158943@university of milan;2173268183@fabio daneluzzi@@;2092928325@r morton@1290206253@microsoft;2614787689@juergen schmidt@68956291@martin luther university of halle wittenberg	204321447@natural language processing;28490314@speech recognition;46312422@communication;41008148@computer science	2569692527;108096903;2086705963	
1524577339	2002	feedback in computer assisted pronunciation training technology push or demand pull	https://academic.microsoft.com/#/detail/1524577339	2002		2139590113@a neri@145872427@radboud university nijmegen;2460281135@c cucchiarini@145872427@radboud university nijmegen;2148590377@helmer strik@145872427@radboud university nijmegen	204321447@natural language processing;49774154@multimedia;28490314@speech recognition;41008148@computer science	2152615458;2075509776;2109530700;2049831997;1994657794;2084614868;2091359957;2141720691;1995193944;2146484157;2149709611;2037790694;2130994140;116129933;1974527503;2126930309;1739673028;1750883178;2046682270;2118799448;1544450126;2170947378;322814586;2074913905;302693779	
1535086474	2006	asr based corrective feedback on pronunciation does it really work	https://academic.microsoft.com/#/detail/1535086474	2006	We studied a group of immigrants who were following regular, teacher-fronted Dutch classes, and who were assigned to three groups using either a) Dutch CAPT, an ASR-based Computer Assisted Pronunciation Training (CAPT) system that provides feedback on a number of Dutch speech sounds that are problematic for L2 learners b) a CAPT system without feedback c) no CAPT system. Participants were tested before and after the training. The results show that the ASR-based feedback was effective in correcting the errors addressed in the training. Index Terms: CALL, CAPT, pronunciation, feedback, ASR	2139590113@a neri@145872427@radboud university nijmegen;2460281135@c cucchiarini@145872427@radboud university nijmegen;2148590377@helmer strik@145872427@radboud university nijmegen	204321447@natural language processing;28490314@speech recognition;41008148@computer science	2119607964;1988687075;1986671983;2091675326;1481151678	
1585763212	2004	automatic pronunciation error detection an acoustic phonetic approach	https://academic.microsoft.com/#/detail/1585763212	2004	In this paper, we present an acoustic-phonetic approach to automatic pronunciation error detection. Classifiers using techniques such as Linear Discriminant Analysis or a decision tree were developed for three sounds that are frequently pronounced incorrectly by L2-learners of Dutch: /A/, /Y/ and /x/. The acoustic properties of these pronunciation errors were examined so as to define a number of discriminative acoustic features to be used to train and test the classifiers. Experiments showed that the classifiers are able to discriminate correct sounds from incorrect sounds in both native and nonnative speech, and therefore can be used to detect pronunciation errors in non-native speech.	2105274186@khiet p truong@94624287@university of twente;2139590113@a neri@145872427@radboud university nijmegen;2460281135@c cucchiarini@145872427@radboud university nijmegen;2148590377@helmer strik@145872427@radboud university nijmegen	204321447@natural language processing;28490314@speech recognition;178980831@pattern recognition;41008148@computer science	1988687075;70727784;1481151678	
1739673028	2000	automatic detection and correction of non native english pronunciations	https://academic.microsoft.com/#/detail/1739673028	2000		2024447061@wolfgang menzel@196349391@university of ulm;2157962885@daniel herron@1290206253@microsoft;2039971913@patrizia bonaventura@159176309@university of hamburg;2092928325@r morton@1290206253@microsoft	28490314@speech recognition	1532217933;108096903;1506404588;2086705963;1753200545	
1830834526	2013	using a computer in foreign language pronunciation training what advantages	https://academic.microsoft.com/#/detail/1830834526	2013	This paper looks at how speech-interactive CALL can help the classroom  teacher carry out recommendations from immersion-based approaches to  language instruction. Emerging methods for pronunciation tutoring are  demonstrated from Carnegie Mellon University's FLUENCY project,  addressing not only phone articulation but also speech prosody,  responsible for the intonation and rhythm of utterances. New techniques  are suggested for eliciting freely constructed yet specifically targeted  utterances in speech-interactive CALL. In addition, pilot experiments  are reported that demonstrate new methods for detecting and correcting  errors by mining the speech signal for information about learners'  deviations from native speakers' pronunciation.	1479332637@maxine eskenazi@74973139@carnegie mellon university	204321447@natural language processing;41895202@linguistics;28490314@speech recognition;41008148@computer science	2060765064;2597248837;2044275064;1501187080;622461482;1842528305;1545801944;2067615606;1934143074;644325765;1504393453;2020809652;650328826;2084085532;2028838132;213535256;1965385571;1966541225;6079687	
1842528305	1996	detection of foreign speakers pronunciation errors for second language training preliminary results	https://academic.microsoft.com/#/detail/1842528305	1996	With the present generation of speech recognizers dealing with speaker-independent continuous speech and medium-sized vocabularies, the possibilities for their application are becoming larger, and yet some applications have not yet been tried, or have been tried with heavy constraints on the user, due to the expected poor recognition performance, and the lack of results to date in the domain of prosody has severely limited the use of that information. The author thinks that researchers may be overly pessimistic. She explores the possibility of using Carnegie Mellon University's SPHINX II recognizer and of obtaining correct prosody information in order to implement it in a system to aid in foreign language learning.	1479332637@maxine eskenazi@74973139@carnegie mellon university	204321447@natural language processing;41895202@linguistics;28490314@speech recognition;41008148@computer science	2038666810;2020809652;2089417502;1988669809;2028838132	
188328253	1997	a call system using speech recognition to train the pronunciation of japanese long vowels the mora nasal and mora obstruents
1931766939	1996	automatic text independent pronunciation scoring of foreign language student speech	https://academic.microsoft.com/#/detail/1931766939	1996	SRI International is currently involved in the development of a new generation of software systems for automatic scoring of pronunciation as part of the Voice Interactive Language Training System (VILTS) project. This paper describes the goals of the VILTS system, the speech corpus and the algorithm development. The automatic grading system uses SRI's Decipher/sup TM/ continuous speech recognition system to generate phonetic segmentations that are used to produce pronunciation scores at the end of each lesson. The scores produced by the system are similar to those of expert human listeners. Unlike previous approaches, in which models were built for specific sentences or phrases, we present a new family of algorithms designed to perform well even when knowledge of the exact text to be used is not available.	2342400288@leonardo neumeyer@1298353152@sri international;2130387140@horacio franco@1298353152@sri international;1993980736@mitchel weintraub@1298353152@sri international;2102238887@patti price@1298353152@sri international	204321447@natural language processing;41895202@linguistics;28490314@speech recognition;41008148@computer science	2126597185;66698146;103591337	
1965044932	2010	eduspeak a speech recognition and pronunciation scoring toolkit for computer aided language learning applications	https://academic.microsoft.com/#/detail/1965044932	2010		2130387140@horacio franco@1298353152@sri international;2170494551@harry bratt@1298353152@sri international;2026762216@romain rossier@1298353152@sri international;2027748413@venkata ramana rao gadde@1298353152@sri international;2000023593@elizabeth shriberg@1298353152@sri international;220641829@victor abrash@1298353152@sri international;189628767@kristin precoda@1298353152@sri international	504749915@speech technology;155092808@computational linguistics;41895202@linguistics;28490314@speech recognition;33923547@mathematics	2100969003;2070133242;2098773974;2091359957;2484208911	
2008834750	2009	a new method for mispronunciation detection using support vector machine based on pronunciation space models	https://academic.microsoft.com/#/detail/2008834750	2009	This paper presents two new ideas for text dependent mispronunciation detection. Firstly, mispronunciation detection is formulated as a classification problem to integrate various predictive features. A Support Vector Machine (SVM) is used as the classifier and the log-likelihood ratios between all the acoustic models and the model corresponding to the given text are employed as features for the classifier. Secondly, Pronunciation Space Models (PSMs) are proposed to enhance the discriminative capability of the acoustic models for pronunciation variations. In PSMs, each phone is modeled with several parallel acoustic models to represent pronunciation variations of that phone at different proficiency levels, and an unsupervised method is proposed for the construction of the PSMs. Experiments on a database consisting of more than 500,000 Mandarin syllables collected from 1335 Chinese speakers show that the proposed methods can significantly outperform the traditional posterior probability based method. The overall recall rates for the 13 most frequently mispronounced phones increase from 17.2%, 7.6% and 0% to 58.3%, 44.3% and 29.5% at three precision levels of 60%, 70% and 80%, respectively. The improvement is also demonstrated by a subjective experiment with 30 subjects, in which 53.3% of the subjects think the proposed method is better than the traditional one and 23.3% of them think that the two methods are comparable.	2098518535@si wei@126520041@university of science and technology of china;2291850366@guoping hu@126520041@university of science and technology of china;2297528911@yu hu@126520041@university of science and technology of china;2138415479@renhua wang@126520041@university of science and technology of china	9483764@likelihood ratio test;61328038@speech processing;41895202@linguistics;28490314@speech recognition;178980831@pattern recognition;41008148@computer science	2156909104;2134659216;2034537249;2139008940;2070133242;2106119541;2164931619;2104663520;334543181;1508594724;2091359957;2050693797;103312509;2139565824;2137469438;105558132;2089894727;1496430420;2274685338;270455168;1996545497;2395625153	
2017742648	2009	foreign accent conversion in computer assisted pronunciation training	https://academic.microsoft.com/#/detail/2017742648	2009	Learners of a second language practice their pronunciation by listening to and imitating utterances from native speakers. Recent research has shown that choosing a well-matched native speaker to imitate can have a positive impact on pronunciation training. Here we propose a voice-transformation technique that can be used to generate the (arguably) ideal voice to imitate: the own voice of the learner with a native accent. Our work extends previous research, which suggests that providing learners with prosodically corrected versions of their utterances can be a suitable form of feedback in computer assisted pronunciation training. Our technique provides a conversion of both prosodic and segmental characteristics by means of a pitch-synchronous decomposition of speech into glottal excitation and spectral envelope. We apply the technique to a corpus containing parallel recordings of foreign-accented and native-accented utterances, and validate the resulting accent conversions through a series of perceptual experiments. Our results indicate that the technique can reduce foreign accentedness without significantly altering the voice quality properties of the foreign speaker. Finally, we propose a pedagogical strategy for integrating accent conversion as a form of behavioral shaping in computer assisted pronunciation training.	2065928861@daniel felps@91045830@texas a m university;2037121070@heather bortfeld@91045830@texas a m university;2032259955@ricardo gutierrezosuna@91045830@texas a m university	542774811@prosody;167310288@sound quality;171041071@first language;173988693@phonation;89600930@segmentation;41895202@linguistics;28490314@speech recognition;41008148@computer science	2001141328;1525711547;2428180336;2339961160;2123003832;1993900335;2048861677;1999473075;222076935;2120847449;2280326949;2168473804;2110420312;1994657794;2169528473;2118850452;2119419436;2119607964;2055870134;2100048758;2160024630;2166754847;1991402032;2149709611;2091675326;2111550316;1528839011;2141761826;53458212;2130994140;1978986151;108096903;1976126081;1491767415;2126930309;1739673028;2150684916;181056519;2167341025;2112407627;2122364000;599692643;2017233597;2118799448;2022241205;1970792913;1490975927;2157259375;2046382036;90124316;2125504809;146348127;2098470763;2032988466;1576602419;2056990804;1999405202;2102133697;2184314534;2006075850;250398514;1568035797;2038416017;2073910673;1989046126;2507083698;2044897876;93060608;2166827277;2028533508	
2039568842	2014	machine learning approaches to improving pronunciation error detection on an imbalanced corpus	https://academic.microsoft.com/#/detail/2039568842	2014	In this paper, we investigate the task of phone-level pronunciation error detection as a binary classification problem, the performance of which is heavily affected by the imbalanced distribution of the classes in a manually annotated data set of non-native English. In order to address problems caused by this extreme class imbalance, methods for cost-sensitive learning (weighting inversely proportional to class frequencies) and over-sampling of synthetic instances (SMOTE) are investigated in order to improve classification performance. Experiments using classifiers consisting of features based on acoustic phonetics and word identity demonstrate that these machine learning approaches lead to performance improvements over the baseline system based on the extremely imbalanced data. In addition, several different types of classifiers were compared. Finally, the paper analyzes the robustness of classifier performance across different phones.	2496002160@xuesong yang@157725225@university of illinois at urbana champaign;970005740@anastassia loukina@20089843@princeton university;323850375@keelan evanini@20089843@princeton university	117765406@generalization error;90842384@sampling;204321447@natural language processing;28490314@speech recognition;178980831@pattern recognition;119857082@machine learning;105795698@statistics;41008148@computer science	2148143831;2118978333;2129018774;2139008940;2029996593;2163667253;2134124280;2017743450;1965044932;2008834750;2148007421;2402113958;2093826182;2170234362;2408752745;2404722202;92590757	
2049905800	2008	using articulatory representations to detect segmental errors in nonnative pronunciation	https://academic.microsoft.com/#/detail/2049905800	2008	Motivated by potential applications in second-language pedagogy, we present a novel approach to using articulatory information to improve automatic detection of typical phone-level errors made by nonnative speakers of English-a difficult task that involves discrimination between close pronunciations. We describe a reformulation of the hidden-articulator Markov model (HAMM) framework that is appropriate for the pronunciation evaluation domain. Model training requires no direct articulatory measurement, but rather involves a constrained and interpolated mapping from phone-level transcriptions to a set of physically and numerically meaningful articulatory representations. Here, we define two new methods of deriving articulatory-based features for classification: one, by concatenating articulatory recognition results over eight streams representative of the vocal tract's constituents; the other, by calculating multidimensional articulatory confidence scores within these representations based on general linguistic knowledge of articulatory variants. After adding these articulatory features to traditional phone-level confidence scores, our results demonstrate absolute reductions in combined error rates for verification of segment-level pronunciations produced by nonnative speakers in the ISLE corpus by as much as 16%-17% for some target segments, and a 3%-4% absolute improvement overall.	2027275778@joseph tepperman@1174212@university of southern california;2171036777@shrikanth narayanan@1174212@university of southern california	47401133@vocal tract;92548554@domain model;513492790@discrimination;163836022@markov model;174576238@speech;89600930@segmentation;170810435@english;98239658@direct method;17378031@interpolation;89279210@stress;147673038@reliability;133892786@speaker recognition;61328038@speech processing;204321447@natural language processing;41895202@linguistics;28490314@speech recognition;41008148@computer science	2129244720;2003890417;2160130475;1970996882;2167642311;2159596372;2106125881;102979914;57619689;2134824793;2118511662;1821592834;93767964;2152663231;183467496;162591155;1967701321;1515154287;2122407890;2134562561;135108420;2136848358;2023414836	
2067517679	2012	a comparison based approach to mispronunciation detection	https://academic.microsoft.com/#/detail/2067517679	2012	The task of mispronunciation detection for language learning is typically accomplished via automatic speech recognition (ASR). Unfortunately, less than 2% of the world's languages have an ASR capability, and the conventional process of creating an ASR system requires large quantities of expensive, annotated data. In this paper we report on our efforts to develop a comparison-based framework for detecting word-level mispronunciations in nonnative speech. Dynamic time warping (DTW) is carried out between a student's (non-native speaker) utterance and a teacher's (native speaker) utterance, and we focus on extracting word-level and phone-level features that describe the degree of mis-alignment in the warping path and the distance matrix. Experimental results on a Chinese University of Hong Kong (CUHK) nonnative corpus show that the proposed framework improves the relative performance on a mispronounced word detection task by nearly 50% compared to an approach that only considers DTW alignment scores.	2481769225@ann lee@63966007@massachusetts institute of technology;2154846939@james r glass@63966007@massachusetts institute of technology	88516994@dynamic time warping;52622490@feature extraction;204321447@natural language processing;28490314@speech recognition;178980831@pattern recognition;41008148@computer science	2153635508;2161969291;273093436;2139008940;2126203737;2171019095;2134124280;2137268753;2095514769;275138538;2114492809;2154093685;103312509;2152334841;2118474530;2147229100	
2070133242	2000	automatic scoring of pronunciation quality
2091675326	2003	speech technologies for pronunciation feedback and evaluation
2093826182	2009	asr based pronunciation evaluation with automatically generated competing vocabulary and classifier fusion	https://academic.microsoft.com/#/detail/2093826182	2009	In this paper, the application of automatic speech recognition (ASR) technology in computer aided pronunciation training (CAPT) is addressed. A method to automatically generate the competitive lexicon, required by an ASR engine to compare the pronunciation of a target word with its correct and wrong phonetic realizations, is proposed. In order to enable the efficient deployment of CAPT applications, the generation of this competitive lexicon does not require any human assistance or a priori information of mother language dependent error rules. Moreover, a Bayes based multi-classifier fusion approach to map ASR objective confidence scores to subjective evaluations in pronunciation assessment is presented. The method proposed here to generate a competitive lexicon given a target word leads to averaged subjective-objective score correlation equal to 0.67 and 0.82 with five and two levels of pronunciation quality, respectively. Finally, multi-classifier systems (MCS) provide a promising formal framework to combine poorly correlated scores in CAPT. When applied to ASR confidence metrics, MCS can lead to an increase of 2.4% and a reduction of 10.2% in subjective-objective score correlation and classification error, respectively, with two pronunciation quality levels.	2099033291@carlos molina@69737025@university of chile;1934821052@nestor becerra yoma@69737025@university of chile;2307372321@jorge wuth@69737025@university of chile;2141319837@hiram vivanco@69737025@university of chile	189722922@open market operation;33954974@sensor fusion;205617318@metric;147673038@reliability;137584468@phonetics;61328038@speech processing;87868495@information processing;204321447@natural language processing;28490314@speech recognition;41008148@computer science	2158275940;2084134149;2002342963;2164568552;2016648380;2160767978;2168847089;2122558050;2164810574;1931766939;2119419436;2077155272;2056933203;83182205;73900594;48881744;2152709821;3243259;67753814;1549300081;2921871	
2119607964	2002	the pedagogy technology interface in computer assisted pronunciation training	https://academic.microsoft.com/#/detail/2119607964	2002	In this paper, we examine the relationship between pedagogy and technology in Computer Assisted Pronunciation Training (CAPT) courseware. First, we will analyse available literature on second language pronunciation teaching and learning in order to derive some general guidelines for effective training. Second, we will present an appraisal of various CAPT systems with a view to establishing whether they meet pedagogical requirements. In this respect, we will show that many commercial systems tend to prefer technological novelties to the detriment of pedagogical criteria that could benefit the learner more. While examining the limitations of today's technology, we will consider possible ways to deal with these shortcomings. Finally, we will combine the information thus gathered to suggest some recommendations for future CAPT.	2139590113@a neri@145872427@radboud university nijmegen;2460281135@c cucchiarini@145872427@radboud university nijmegen;2148590377@helmer strik@145872427@radboud university nijmegen;2052844438@lou boves@145872427@radboud university nijmegen	41895202@linguistics;28490314@speech recognition;154945302@artificial intelligence;144024400@sociology;15744967@psychology;41008148@computer science	34578900;2070696251;2152615458;2075509776;2109530700;1993900335;2049072322;2049831997;2124015027;1976285019;1995706466;2089728281;2010110136;2168473804;1493910332;1994657794;2084614868;1999328446;1577671117;275495156;2091359957;2141720691;1967421919;1995193944;2146484157;1049766;2149709611;1988819670;2037790694;2130994140;2142908500;116129933;1977369679;1974527503;1491767415;2126930309;1739673028;1750883178;1976867462;2015302001;2038047181;2143456682;1544450126;2170947378;322814586;2074913905;1983249150;2622482026;2027871256;1946893940;1839336196;2105418090;2071585964;2103520797;302693779;2038416017;2056052115;2048762813;93060608;2137387078	
2130689396	2015	automatic pronunciation error detection and feedback generation for call applications	https://academic.microsoft.com/#/detail/2130689396	2015		2278598925@renlong ai@@	204321447@natural language processing;28490314@speech recognition;46312422@communication;41008148@computer science	1585763212;39776430;2251239961;1522107279	
2690082738	2017	Shefce: A Cantonese-English bilingual speech corpus for pronunciation assessment
2608319664	2017	Automatic detection of syllable stress using sonority based prominence features for pronunciation evaluation
2615061381	2017	Sparse Pronunciation Codes for Perceptual Phonetic Information Assessment
2608319664	2017	Automatic detection of syllable stress using sonority based prominence features for pronunciation evaluation
1530222548	2017	Innovative use of mobile technologies in EAP oral assessment: a pilot study from The Open University
2727401124	2017	Speech/pause detection algorithm based on the adaptive method of complementary decomposition and energy assessment of intrinsic mode functions
2727401124	2017	Developing classroom language assessment benchmarks for Japanese teachers of English as a foreign language
2571838890	2017	Automatic pronunciation assessment of Korean spoken by L2 learners using best feature set selection
2517552251	2017	Pronunciation Assessment of Japanese Learners of French with GOP Scores and Phonetic Information
2575689684	2017	Computer-assisted pronunciation training: From pronunciation scoring towards spoken language learning
2617997528	2016	On the Assessment of Computer-assisted Pronunciation Training Tools
2514754990	2016	Vowel Characteristics in the Assessment of L2 English Pronunciation
2515321869	2016	Context Aware Mispronunciation Detection for Mandarin Pronunciation Training
2515576076	2016	Pronunciation Error Detection for New Language Learners
2584745181	2016	Measuring Pronunciation Improvement in Users of CAPT Tool TipTopTalk!
2612760192	2016	The correlation between signal distance and consonant pronunciation in Mandarin words
2613249667	2016	Senone log-likelihood ratios based articulatory features in pronunciation erroneous tendency detecting
2512743763	2016	Automatic Pronunciation Evaluation of Non-Native Mandarin Tone by Using Multi-Level Confidence Measures
2502436735	2016	A Novel Application System of Assessing the Pronunciation Differences Between Chinese Children and Adults
2613090068	2016	Pronunciation error detection using DNN articulatory model based on multi-lingual and multi-task learning
1523004151	2016	Learning Speaker-specific Pronunciations of Disordered Speech Learning Speaker-specific Pronunciations of Disordered Speech
2502847729	2016	Automatic Assessment of Speech Intelligibility for Individuals With Aphasia
2565056043	2016	Towards Using Conversations with Spoken Dialogue Systems in the Automated Assessment of Non-Native Speakers of English
2515679259	2016	Deep Neural Networks for Voice Quality Assessment Based on the GRBAS Scale
2510063686	2016	Self-Adaptive DNN for Improving Spoken Language Proficiency Assessment
2509052352	2016	Automatic Assessment and Error Detection of Shadowing Speech: Case of English Spoken by Japanese Learners
2610458980	2016	Towards automatic assessment of aphasia speech using automatic speech recognition techniques
2176713451	2016	HMM-Based Non-Native Accent Assessment Using Posterior Features
2572179590	2016	Multi-lingual and multi-task DNN learning for articulatory error detection
2406502879	2016	Personalized mispronunciation detection and diagnosis based on unsupervised error pattern discovery
2401896499	2016	Improving non-native mispronunciation detection and enriching diagnostic feedback with DNN-based speech attribute modeling
